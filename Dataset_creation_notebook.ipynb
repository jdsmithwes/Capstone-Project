{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8idLC0ams5zc"
   },
   "source": [
    "## Objective\n",
    "\n",
    "For the purpose of this analysis, I will attempt to measure the sentiment of tweets to learn whether tweets impact the number of Covid-19 cases and deaths in the United States. This study is important as the reopening of our society, from going to get an ice cream cone to being able to earn a living, hinges on our ability to lower the rate of infection in our country. With so many individuals receiving their news and information through social media, being able to predict how COVID cases will either increase or decrease based on tweets can inform public policy. Should we be able to predict the future number of COVID cases based on the text of tweets; public officials, business leaders and concerned citizens can alter their tweeting practices to promote improved COVID outcomes.\n",
    "\n",
    "To create the dataset, I utilized the TWINT library to collect all tweets from January 1,2020 until July 10th. I then made various subsets of the tweets. For example, to measure the impact of tweets by public leaders viewed as polar opposites regarding their response to the pandemic, I collected tweets by President Trump and the Governor of New York, Andrew Cuomo. Another subset of tweets that I labeled as baseline consists of tweets by the New York Times and Washington Post - two of America's leading journalism outlets.\n",
    "\n",
    "The purpose of creating these subsets is that the baseline tweets can be considered to be those that communicate mainly fact. While they might have op-ed columnists, we can assume that most tweets from the news reporting divisions will provide factual updates on the Covid response. By considering the two polar opposites, Trump and Cuomo, we can measure Covid outcomes, in terms of cases, after the tweets have been consumed by the public. Finally, the main Covid collection will allow us to see whether more individuals subscribed to the Trump/Cuomo tweets and how Covid cases changed, for the positive or negative, in their region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Obtaining Tweet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "For the notebooks that contain the queries for the tweets gathered on TWINT, please refer to the Covid Data Queries notebook in the repo. The JSON files for these queries were used to create DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('tweets/Covid_tweets4.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('tweets/Trump_Covid_tweets4.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('tweets/Cuomo_Covid_tweets4.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('tweets/Nytimes_Covid_tweets4.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('tweets/Washpost_tweets4.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['date'] = pd.to_datetime(All_Covid_tweets['date'], format='%Y%m%d')\n",
    "Trump_Covid_tweets['date'] = pd.to_datetime(Trump_Covid_tweets['date'], format='%Y%m%d')\n",
    "Cuomo_Covid_tweets['date'] = pd.to_datetime(Cuomo_Covid_tweets['date'], format='%Y%m%d')\n",
    "Baseline_tweets['date'] = pd.to_datetime(Baseline_tweets['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets in the dataset is: 17659\n"
     ]
    }
   ],
   "source": [
    "#Combining all Tweet DFs into one\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets,Trump_Covid_tweets,\n",
    "                             Cuomo_Covid_tweets,Baseline_tweets],axis=0)\n",
    "\n",
    "number_of_tweets = len(Master_Tweet_df)\n",
    "print('The number of tweets in the dataset is:',number_of_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "Data for Covid Cases and Deaths was collected from The COVID Tracking Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "covid_data = pd.read_excel('covid data/data.8.08.2020.xls')\n",
    "\n",
    "# formatting the date column to datetime\n",
    "covid_data['date'] = pd.to_datetime(covid_data['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>4913663</td>\n",
       "      <td>152816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>4797959</td>\n",
       "      <td>150232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>4745694</td>\n",
       "      <td>148807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>4694126</td>\n",
       "      <td>147631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  positive     death\n",
       "0 2020-08-07   4913663  152816.0\n",
       "1 2020-08-06   4852143  151483.0\n",
       "2 2020-08-05   4797959  150232.0\n",
       "3 2020-08-04   4745694  148807.0\n",
       "4 2020-08-03   4694126  147631.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data = covid_data[['date','positive','death']]\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>2020-08-06 23:56:20</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:56:20</td>\n",
       "      <td>EDT</td>\n",
       "      <td>228022886</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>Angelo Wijdh</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '228022886', 'username': 'ACAI_W'}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291522763233071105</td>\n",
       "      <td>1291451746724741120</td>\n",
       "      <td>2020-08-06 23:53:16</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:53:16</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1134860643528577026</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Britta Swenson</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1134860643528577026', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>2020-08-06 23:45:35</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:45:35</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1080245442732974081</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Sally Wong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1080245442732974081', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291520253357326338</td>\n",
       "      <td>1291520253357326336</td>\n",
       "      <td>2020-08-06 23:43:18</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:43:18</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2431027482</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>DENSMORE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2431027482', 'username': 'ultima...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291519814339629059</td>\n",
       "      <td>1291518619197874176</td>\n",
       "      <td>2020-08-06 23:41:33</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:41:33</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2974733727</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>Rob Chappell</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2974733727', 'username': 'taffyg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1291523532363636736  1291523532363636736 2020-08-06 23:56:20 2020-08-06   \n",
       "1  1291522763233071105  1291451746724741120 2020-08-06 23:53:16 2020-08-06   \n",
       "2  1291520828148871168  1291520828148871168 2020-08-06 23:45:35 2020-08-06   \n",
       "3  1291520253357326338  1291520253357326336 2020-08-06 23:43:18 2020-08-06   \n",
       "4  1291519814339629059  1291518619197874176 2020-08-06 23:41:33 2020-08-06   \n",
       "\n",
       "       time timezone              user_id         username            name  \\\n",
       "0  19:56:20      EDT            228022886           acai_w    Angelo Wijdh   \n",
       "1  19:53:16      EDT  1134860643528577026    brittaswenson  Britta Swenson   \n",
       "2  19:45:35      EDT  1080245442732974081  sallywo42411402      Sally Wong   \n",
       "3  19:43:18      EDT           2431027482      ultimate1us        DENSMORE   \n",
       "4  19:41:33      EDT           2974733727        taffygeek    Rob Chappell   \n",
       "\n",
       "  place  ... user_rt_id user_rt retweet_id  \\\n",
       "0        ...                                 \n",
       "1        ...                                 \n",
       "2        ...                                 \n",
       "3        ...                                 \n",
       "4        ...                                 \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0   [{'user_id': '228022886', 'username': 'ACAI_W'}]                            \n",
       "1  [{'user_id': '1134860643528577026', 'username'...                            \n",
       "2  [{'user_id': '1080245442732974081', 'username'...                            \n",
       "3  [{'user_id': '2431027482', 'username': 'ultima...                            \n",
       "4  [{'user_id': '2974733727', 'username': 'taffyg...                            \n",
       "\n",
       "   trans_src trans_dest positive     death  \n",
       "0                        4852143  151483.0  \n",
       "1                        4852143  151483.0  \n",
       "2                        4852143  151483.0  \n",
       "3                        4852143  151483.0  \n",
       "4                        4852143  151483.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the two datasets for all Covid data in one place\n",
    "Master_Tweet_dataset = pd.merge(Master_Tweet_df,covid_data,on='date')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['cashtags', 'conversation_id', 'hashtags',\n",
    "       'id','link', 'mentions', 'name', 'near', 'photos',\n",
    "       'place', 'quote_url','reply_to', 'retweet',\n",
    "       'retweet_date', 'retweet_id','source', 'time',\n",
    "       'timezone', 'trans_dest', 'trans_src', 'translate','urls',\n",
    "       'user_id', 'user_rt', 'user_rt_id',],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jamaalsmith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'date', 'username', 'tweet', 'replies_count',\n",
       "       'retweets_count', 'likes_count', 'video', 'geo', 'positive', 'death'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install textfeatures\n",
    "import textfeatures as tf\n",
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>2020-08-06 23:56:20</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:56:20</td>\n",
       "      <td>EDT</td>\n",
       "      <td>228022886</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>Angelo Wijdh</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '228022886', 'username': 'ACAI_W'}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291522763233071105</td>\n",
       "      <td>1291451746724741120</td>\n",
       "      <td>2020-08-06 23:53:16</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:53:16</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1134860643528577026</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Britta Swenson</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1134860643528577026', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>2020-08-06 23:45:35</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:45:35</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1080245442732974081</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Sally Wong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1080245442732974081', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291520253357326338</td>\n",
       "      <td>1291520253357326336</td>\n",
       "      <td>2020-08-06 23:43:18</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:43:18</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2431027482</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>DENSMORE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2431027482', 'username': 'ultima...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291519814339629059</td>\n",
       "      <td>1291518619197874176</td>\n",
       "      <td>2020-08-06 23:41:33</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:41:33</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2974733727</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>Rob Chappell</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2974733727', 'username': 'taffyg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1291523532363636736  1291523532363636736 2020-08-06 23:56:20 2020-08-06   \n",
       "1  1291522763233071105  1291451746724741120 2020-08-06 23:53:16 2020-08-06   \n",
       "2  1291520828148871168  1291520828148871168 2020-08-06 23:45:35 2020-08-06   \n",
       "3  1291520253357326338  1291520253357326336 2020-08-06 23:43:18 2020-08-06   \n",
       "4  1291519814339629059  1291518619197874176 2020-08-06 23:41:33 2020-08-06   \n",
       "\n",
       "       time timezone              user_id         username            name  \\\n",
       "0  19:56:20      EDT            228022886           acai_w    Angelo Wijdh   \n",
       "1  19:53:16      EDT  1134860643528577026    brittaswenson  Britta Swenson   \n",
       "2  19:45:35      EDT  1080245442732974081  sallywo42411402      Sally Wong   \n",
       "3  19:43:18      EDT           2431027482      ultimate1us        DENSMORE   \n",
       "4  19:41:33      EDT           2974733727        taffygeek    Rob Chappell   \n",
       "\n",
       "  place  ... geo source user_rt_id user_rt  retweet_id  \\\n",
       "0        ...                                             \n",
       "1        ...                                             \n",
       "2        ...                                             \n",
       "3        ...                                             \n",
       "4        ...                                             \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0   [{'user_id': '228022886', 'username': 'ACAI_W'}]                           \n",
       "1  [{'user_id': '1134860643528577026', 'username'...                           \n",
       "2  [{'user_id': '1080245442732974081', 'username'...                           \n",
       "3  [{'user_id': '2431027482', 'username': 'ultima...                           \n",
       "4  [{'user_id': '2974733727', 'username': 'taffyg...                           \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset=Master_Tweet_dataset.drop('created_at',axis=1)\n",
    "Master_Tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>WoW, such a bold and honest statement and brou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>55</td>\n",
       "      <td>4.781818</td>\n",
       "      <td>27</td>\n",
       "      <td>318</td>\n",
       "      <td>[such, a, and, and, to, you, with, a, of, an, ...</td>\n",
       "      <td>bold honest statement brought integrity please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Trump lift the ban so he won’t be to blame for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>43</td>\n",
       "      <td>4.395349</td>\n",
       "      <td>23</td>\n",
       "      <td>231</td>\n",
       "      <td>[the, so, he, be, to, for, the, and, from, in,...</td>\n",
       "      <td>trump lift wont blame coming bankruptcies majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Proves Narvarro right and Dr. Fauci wrong, rig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>46</td>\n",
       "      <td>5.854167</td>\n",
       "      <td>13</td>\n",
       "      <td>331</td>\n",
       "      <td>[and, was, in, had, with, in, the, of, on, wha...</td>\n",
       "      <td>proves narvarro right fauci wrong right fauci ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>In 2017 the USA became the victim of a systemi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>53</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>17</td>\n",
       "      <td>296</td>\n",
       "      <td>[the, the, of, a, in, and, is, very, of, have,...</td>\n",
       "      <td>became victim systemic brain cancer cancer sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>How is the Dow still rising. Just looking at t...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>[is, the, at, that, and, only, of, the, with, ...</td>\n",
       "      <td>still rising looking screen covid deaths covid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date         username  \\\n",
       "0 2020-08-06           acai_w   \n",
       "1 2020-08-06    brittaswenson   \n",
       "2 2020-08-06  sallywo42411402   \n",
       "3 2020-08-06      ultimate1us   \n",
       "4 2020-08-06        taffygeek   \n",
       "\n",
       "                                               tweet  replies_count  \\\n",
       "0  WoW, such a bold and honest statement and brou...              0   \n",
       "1  Trump lift the ban so he won’t be to blame for...              0   \n",
       "2  Proves Narvarro right and Dr. Fauci wrong, rig...              0   \n",
       "3  In 2017 the USA became the victim of a systemi...              0   \n",
       "4  How is the Dow still rising. Just looking at t...              7   \n",
       "\n",
       "   retweets_count  likes_count  video geo  positive     death  word_count  \\\n",
       "0               0            0      0       4852143  151483.0          55   \n",
       "1               0            0      0       4852143  151483.0          43   \n",
       "2               0            1      0       4852143  151483.0          46   \n",
       "3               0            0      1       4852143  151483.0          53   \n",
       "4               0            1      0       4852143  151483.0          36   \n",
       "\n",
       "   avg_word_length  stopwords_count  char_count  \\\n",
       "0         4.781818               27         318   \n",
       "1         4.395349               23         231   \n",
       "2         5.854167               13         331   \n",
       "3         4.692308               17         296   \n",
       "4         4.583333               15         200   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  [such, a, and, and, to, you, with, a, of, an, ...   \n",
       "1  [the, so, he, be, to, for, the, and, from, in,...   \n",
       "2  [and, was, in, had, with, in, the, of, on, wha...   \n",
       "3  [the, the, of, a, in, and, is, very, of, have,...   \n",
       "4  [is, the, at, that, and, only, of, the, with, ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  bold honest statement brought integrity please...  \n",
       "1  trump lift wont blame coming bankruptcies majo...  \n",
       "2  proves narvarro right fauci wrong right fauci ...  \n",
       "3  became victim systemic brain cancer cancer sta...  \n",
       "4  still rising looking screen covid deaths covid...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using textfeatures library for some text preprocessing\n",
    "tf.word_count(Master_Tweet_dataset,\"tweet\",'word_count')\n",
    "tf.avg_word_length(Master_Tweet_dataset,'tweet','avg_word_length')\n",
    "tf.stopwords_count(Master_Tweet_dataset,'tweet','stopwords_count')\n",
    "tf.char_count(Master_Tweet_dataset,'tweet','char_count')\n",
    "tf.stopwords(Master_Tweet_dataset,'tweet','stopwords')\n",
    "tf.clean(Master_Tweet_dataset,'tweet','clean_text')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and punctuation\n",
    "\n",
    "clean_tweet = Master_Tweet_dataset['clean_text']\n",
    "#Tweet Tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "#corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "#corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in clean_tweet:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tok list or later use\n",
    "\n",
    "with open('tok_corp_8_8.pickle','wb') as f:\n",
    "    pickle.dump(tok_corp,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis \n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import PatternAnalyzer, NaiveBayesAnalyzer\n",
    "#from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "tweets = Master_Tweet_dataset['clean_text']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "    #Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "    #sentiment = Classifier.predict_proba(tweet)\n",
    "    blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "    rating = blob.sentiment.polarity\n",
    "    Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_dataset['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fit12P9FHnHD",
    "outputId": "1c50c4c5-7eef-4a42-9e67-35b71e045df6"
   },
   "outputs": [],
   "source": [
    "#Saving as CSV for later uploads to different notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_dataset_textprocessing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Poll Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Poll data\n",
    "poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "poll_data = poll_data.dropna()\n",
    "\n",
    "#Converting Date columns to integer so merge will work\n",
    "Master_Tweet_dataset['date'] = pd.to_datetime(Master_Tweet_dataset['date'])\n",
    "Master_Tweet_dataset['date'] = Master_Tweet_dataset['date'].astype(int)\n",
    "poll_data['date'] = pd.to_datetime(poll_data['date'])\n",
    "poll_data['date'] = poll_data['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging with Poll Data\n",
    "\n",
    "#poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "#pd.to_datetime(poll_data['Date']) #converting to datetime object for merge purposes\n",
    "#pd.to_datetime(Master_Tweet_df['Date']) #converting to datetime object for merge purposes\n",
    "\n",
    "left = Master_Tweet_dataset.sort_values(by='date')\n",
    "right = poll_data.sort_values(by='date')\n",
    "\n",
    "Master_Tweet_dataset = pd.merge_asof(left,right,on='date',allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>2020-08-06 23:56:20</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:56:20</td>\n",
       "      <td>EDT</td>\n",
       "      <td>228022886</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>Angelo Wijdh</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '228022886', 'username': 'ACAI_W'}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291522763233071105</td>\n",
       "      <td>1291451746724741120</td>\n",
       "      <td>2020-08-06 23:53:16</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:53:16</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1134860643528577026</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Britta Swenson</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1134860643528577026', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>2020-08-06 23:45:35</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:45:35</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1080245442732974081</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Sally Wong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1080245442732974081', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291520253357326338</td>\n",
       "      <td>1291520253357326336</td>\n",
       "      <td>2020-08-06 23:43:18</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:43:18</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2431027482</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>DENSMORE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2431027482', 'username': 'ultima...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291519814339629059</td>\n",
       "      <td>1291518619197874176</td>\n",
       "      <td>2020-08-06 23:41:33</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:41:33</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2974733727</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>Rob Chappell</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2974733727', 'username': 'taffyg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1291523532363636736  1291523532363636736 2020-08-06 23:56:20 2020-08-06   \n",
       "1  1291522763233071105  1291451746724741120 2020-08-06 23:53:16 2020-08-06   \n",
       "2  1291520828148871168  1291520828148871168 2020-08-06 23:45:35 2020-08-06   \n",
       "3  1291520253357326338  1291520253357326336 2020-08-06 23:43:18 2020-08-06   \n",
       "4  1291519814339629059  1291518619197874176 2020-08-06 23:41:33 2020-08-06   \n",
       "\n",
       "       time timezone              user_id         username            name  \\\n",
       "0  19:56:20      EDT            228022886           acai_w    Angelo Wijdh   \n",
       "1  19:53:16      EDT  1134860643528577026    brittaswenson  Britta Swenson   \n",
       "2  19:45:35      EDT  1080245442732974081  sallywo42411402      Sally Wong   \n",
       "3  19:43:18      EDT           2431027482      ultimate1us        DENSMORE   \n",
       "4  19:41:33      EDT           2974733727        taffygeek    Rob Chappell   \n",
       "\n",
       "  place  ... geo source user_rt_id user_rt  retweet_id  \\\n",
       "0        ...                                             \n",
       "1        ...                                             \n",
       "2        ...                                             \n",
       "3        ...                                             \n",
       "4        ...                                             \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0   [{'user_id': '228022886', 'username': 'ACAI_W'}]                           \n",
       "1  [{'user_id': '1134860643528577026', 'username'...                           \n",
       "2  [{'user_id': '1080245442732974081', 'username'...                           \n",
       "3  [{'user_id': '2431027482', 'username': 'ultima...                           \n",
       "4  [{'user_id': '2974733727', 'username': 'taffyg...                           \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Master_Tweet_df = Master_Tweet_df.drop('Date')\n",
    "#Master_Tweet_df = Master_Tweet_df.drop('Date',axis=1)\n",
    "Master_Tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Victory Spread dataframe is Trump poll figure subtracted from Biden poll figure. If spread is positive, that indicates how much Biden is leading by. Should it be negative, that represents how much Trump is ahead by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Victory Spread\n",
    "Master_Tweet_dataset['Spread'] = Master_Tweet_dataset['Biden (D)'] - Master_Tweet_dataset['Trump (R)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiging topics to each tweet  -code inspired by stackabuse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Vectorizing docs\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(clean_tweet)\n",
    "\n",
    "#fitting LDA Model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "#transforming to get topic numbers\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape\n",
    "\n",
    "#creating column of Topics\n",
    "Master_Tweet_dataset['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['countries', 'death', 'amazon', 'rate', 'country', 'world', 'brazil', 'cases', 'india', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['international', 'medical', 'rate', 'virus', 'pandemic', 'doctors', 'patients', 'economy', 'death', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['second', 'strong', 'france', 'endorsement', 'military', 'total', 'italy', 'spain', 'complete', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['death', 'like', 'need', 'dont', 'country', 'americans', 'trump', 'world', 'people', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['wear', 'mask', 'masks', 'businesses', 'today', 'home', 'stay', 'safe', 'vaccine', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['countries', 'number', 'population', 'world', 'coronavirus', 'trump', 'million', 'cases', 'deaths', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['biden', 'america', 'fake', 'people', 'president', 'news', 'thank', 'covid', 'trump', 'great']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['doesnt', 'economy', 'pandemic', 'virus', 'distancing', 'wearing', 'mask', 'social', 'time', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['control', 'president', 'dont', 'countries', 'people', 'like', 'virus', 'trump', 'china', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['china', 'peak', 'canada', 'like', 'country', 'dont', 'trump', 'people', 'cases', 'covid']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top words for each topic\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to create Target Column\n",
    "category_dict = {}\n",
    "for key in [0,4,5,8,1,3]:\n",
    "    category_dict[key] = 'Bad Response'\n",
    "for key in [10,6,2,7,9]:\n",
    "    category_dict[key] = 'Good Response'\n",
    "    \n",
    "#Creation of Target Column\n",
    "Master_Tweet_dataset['Target'] = Master_Tweet_dataset['Topic'].map(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>9465</td>\n",
       "      <td>17624</td>\n",
       "      <td>88225</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>7</td>\n",
       "      <td>141</td>\n",
       "      <td>[in, of, will, be, or, to, the]</td>\n",
       "      <td>making great progress davos tremendous numbers...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>8643</td>\n",
       "      <td>24619</td>\n",
       "      <td>98960</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>[if, you, you, will, be]</td>\n",
       "      <td>sorry come immediately sent back</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>7035</td>\n",
       "      <td>24342</td>\n",
       "      <td>97513</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>[you, on]</td>\n",
       "      <td>fridaybig crowd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>3436</td>\n",
       "      <td>12031</td>\n",
       "      <td>50605</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>[]</td>\n",
       "      <td>true</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>9</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>18086</td>\n",
       "      <td>19899</td>\n",
       "      <td>122408</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>pressure</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2228</td>\n",
       "      <td>8103</td>\n",
       "      <td>39527</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>[be]</td>\n",
       "      <td>great</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>1777</td>\n",
       "      <td>7588</td>\n",
       "      <td>36498</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>[with, you]</td>\n",
       "      <td>great working maria</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>8460</td>\n",
       "      <td>19473</td>\n",
       "      <td>102575</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48</td>\n",
       "      <td>4.229167</td>\n",
       "      <td>21</td>\n",
       "      <td>250</td>\n",
       "      <td>[of, the, about, our, just, with, is, that, it...</td>\n",
       "      <td>many great things signed giant trade deal chin...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2116</td>\n",
       "      <td>4824</td>\n",
       "      <td>23572</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>[be, at, by, on, at, the, in]</td>\n",
       "      <td>interviewed eastern joesquawk cnbc world econo...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>10559</td>\n",
       "      <td>21869</td>\n",
       "      <td>89693</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31</td>\n",
       "      <td>4.354839</td>\n",
       "      <td>14</td>\n",
       "      <td>165</td>\n",
       "      <td>[the, to, up, the, in, the, by, the, that, he,...</td>\n",
       "      <td>senates mess made house democrats biden admitt...</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2617</td>\n",
       "      <td>6239</td>\n",
       "      <td>27197</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>[]</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>4755</td>\n",
       "      <td>10359</td>\n",
       "      <td>40194</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7.263158</td>\n",
       "      <td>8</td>\n",
       "      <td>156</td>\n",
       "      <td>[was, so, in, the, that, they, in, the]</td>\n",
       "      <td>case overwhelming house need demand witnesses ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2289</td>\n",
       "      <td>8881</td>\n",
       "      <td>31536</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>[]</td>\n",
       "      <td>story hope fake news covers</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>6259</td>\n",
       "      <td>11829</td>\n",
       "      <td>61355</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>5.615385</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>[to, from]</td>\n",
       "      <td>heading back washington davos switzerland succ...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>12348</td>\n",
       "      <td>21748</td>\n",
       "      <td>133992</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4.769231</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>[are, the, from, for, a]</td>\n",
       "      <td>taking nomination away bernie second time rigged</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>8165</td>\n",
       "      <td>19490</td>\n",
       "      <td>70200</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>[]</td>\n",
       "      <td>thank pictwittercomrqwbqjyza</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2929</td>\n",
       "      <td>6794</td>\n",
       "      <td>31873</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7.117647</td>\n",
       "      <td>4</td>\n",
       "      <td>137</td>\n",
       "      <td>[is, a, is, with]</td>\n",
       "      <td>steyer major loser doesnt second time bernie</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2994</td>\n",
       "      <td>12568</td>\n",
       "      <td>51964</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>7.428571</td>\n",
       "      <td>7</td>\n",
       "      <td>176</td>\n",
       "      <td>[will, very, for, for, has, my, and]</td>\n",
       "      <td>carlos exciting great florida great complete t...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>5158</td>\n",
       "      <td>13673</td>\n",
       "      <td>55496</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>[]</td>\n",
       "      <td>true</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>6</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>15560</td>\n",
       "      <td>42121</td>\n",
       "      <td>237442</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>[is, a]</td>\n",
       "      <td>real thank pictwittercomjwyoyiidw</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>2649</td>\n",
       "      <td>9500</td>\n",
       "      <td>42060</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>[my, you]</td>\n",
       "      <td>soon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>16216</td>\n",
       "      <td>20835</td>\n",
       "      <td>116190</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>16</td>\n",
       "      <td>188</td>\n",
       "      <td>[the, in, the, but, it, is, more, and, more, t...</td>\n",
       "      <td>crazy bernie takes lead democrat primaries loo...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>8</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>24475</td>\n",
       "      <td>24477</td>\n",
       "      <td>113809</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>8</td>\n",
       "      <td>113</td>\n",
       "      <td>[are, to, your, have, it, as, and, will]</td>\n",
       "      <td>democrats going destroy social security totall...</td>\n",
       "      <td>-0.055556</td>\n",
       "      <td>7</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>7362</td>\n",
       "      <td>11788</td>\n",
       "      <td>46213</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>111</td>\n",
       "      <td>[of, just, out, in]</td>\n",
       "      <td>poll radical left nothing democrats came flori...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>3196</td>\n",
       "      <td>8448</td>\n",
       "      <td>36188</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>[]</td>\n",
       "      <td>love alabama pictwittercomzdlbdehhvn</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>1274</td>\n",
       "      <td>5863</td>\n",
       "      <td>22503</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>[in]</td>\n",
       "      <td>interesting poll texas pictwittercomusvapgp</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>4443</td>\n",
       "      <td>8744</td>\n",
       "      <td>35776</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12.133333</td>\n",
       "      <td>5</td>\n",
       "      <td>196</td>\n",
       "      <td>[that, is, no, for, by]</td>\n",
       "      <td>president trump shows electability match elect...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>12878</td>\n",
       "      <td>20638</td>\n",
       "      <td>89765</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>[have, now, that, has, not, a]</td>\n",
       "      <td>democrats conceded president trump committed c...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>997</td>\n",
       "      <td>5532</td>\n",
       "      <td>21288</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>[in]</td>\n",
       "      <td>close race kansas pictwittercommexfvhku</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>18848</td>\n",
       "      <td>23820</td>\n",
       "      <td>95806</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>5.690476</td>\n",
       "      <td>13</td>\n",
       "      <td>280</td>\n",
       "      <td>[a, because, the, the, his, the, after, the, t...</td>\n",
       "      <td>democrats dont want witness trade shifty schif...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date         username  replies_count  retweets_count  \\\n",
       "0   1579651200000000000  realdonaldtrump           9465           17624   \n",
       "1   1579651200000000000  realdonaldtrump           8643           24619   \n",
       "2   1579651200000000000  realdonaldtrump           7035           24342   \n",
       "3   1579651200000000000  realdonaldtrump           3436           12031   \n",
       "4   1579651200000000000  realdonaldtrump          18086           19899   \n",
       "5   1579651200000000000  realdonaldtrump           2228            8103   \n",
       "6   1579651200000000000  realdonaldtrump           1777            7588   \n",
       "7   1579651200000000000  realdonaldtrump           8460           19473   \n",
       "8   1579651200000000000  realdonaldtrump           2116            4824   \n",
       "9   1579651200000000000  realdonaldtrump          10559           21869   \n",
       "10  1579651200000000000  realdonaldtrump           2617            6239   \n",
       "11  1579651200000000000  realdonaldtrump           4755           10359   \n",
       "12  1579651200000000000  realdonaldtrump           2289            8881   \n",
       "13  1579651200000000000  realdonaldtrump           6259           11829   \n",
       "14  1579651200000000000  realdonaldtrump          12348           21748   \n",
       "15  1579651200000000000  realdonaldtrump           8165           19490   \n",
       "16  1579651200000000000  realdonaldtrump           2929            6794   \n",
       "17  1579737600000000000  realdonaldtrump           2994           12568   \n",
       "18  1579737600000000000  realdonaldtrump           5158           13673   \n",
       "19  1579737600000000000  realdonaldtrump          15560           42121   \n",
       "20  1579737600000000000  realdonaldtrump           2649            9500   \n",
       "21  1579737600000000000  realdonaldtrump          16216           20835   \n",
       "22  1579737600000000000  realdonaldtrump          24475           24477   \n",
       "23  1579737600000000000  realdonaldtrump           7362           11788   \n",
       "24  1579737600000000000  realdonaldtrump           3196            8448   \n",
       "25  1579737600000000000  realdonaldtrump           1274            5863   \n",
       "26  1579737600000000000  realdonaldtrump           4443            8744   \n",
       "27  1579737600000000000  realdonaldtrump          12878           20638   \n",
       "28  1579737600000000000  realdonaldtrump            997            5532   \n",
       "29  1579737600000000000  realdonaldtrump          18848           23820   \n",
       "\n",
       "    likes_count  video geo  positive  death  word_count  avg_word_length  \\\n",
       "0         88225      0             2    2.0          22         5.454545   \n",
       "1         98960      0             2    2.0          11         8.166667   \n",
       "2         97513      0             2    2.0           6        12.571429   \n",
       "3         50605      0             2    2.0           2        20.333333   \n",
       "4        122408      0             2    2.0           2         6.000000   \n",
       "5         39527      0             2    2.0           4        14.000000   \n",
       "6         36498      0             2    2.0           6        12.428571   \n",
       "7        102575      0             2    2.0          48         4.229167   \n",
       "8         23572      0             2    2.0          20         5.100000   \n",
       "9         89693      0             2    2.0          31         4.354839   \n",
       "10        27197      0             2    2.0           2        22.666667   \n",
       "11        40194      0             2    2.0          18         7.263158   \n",
       "12        31536      0             2    2.0           8        10.111111   \n",
       "13        61355      0             2    2.0          13         5.615385   \n",
       "14       133992      0             2    2.0          13         4.769231   \n",
       "15        70200      1             2    2.0           4         9.750000   \n",
       "16        31873      0             2    2.0          16         7.117647   \n",
       "17        51964      0             2    2.0          20         7.428571   \n",
       "18        55496      0             2    2.0           2        20.000000   \n",
       "19       237442      0             2    2.0           8         6.250000   \n",
       "20        42060      0             2    2.0           7        10.250000   \n",
       "21       116190      0             2    2.0          36         4.250000   \n",
       "22       113809      0             2    2.0          20         4.700000   \n",
       "23        46213      0             2    2.0          16         6.000000   \n",
       "24        36188      0             2    2.0           4         9.750000   \n",
       "25        22503      0             2    2.0           6         9.500000   \n",
       "26        35776      0             2    2.0          14        12.133333   \n",
       "27        89765      0             2    2.0          14         5.857143   \n",
       "28        21288      0             2    2.0           5         8.800000   \n",
       "29        95806      0             2    2.0          42         5.690476   \n",
       "\n",
       "    stopwords_count  char_count  \\\n",
       "0                 7         141   \n",
       "1                 5         109   \n",
       "2                 2          94   \n",
       "3                 0          63   \n",
       "4                 0          13   \n",
       "5                 1          74   \n",
       "6                 2          93   \n",
       "7                21         250   \n",
       "8                 7         121   \n",
       "9                14         165   \n",
       "10                0          70   \n",
       "11                8         156   \n",
       "12                0          99   \n",
       "13                2          85   \n",
       "14                5          74   \n",
       "15                0          42   \n",
       "16                4         137   \n",
       "17                7         176   \n",
       "18                0          62   \n",
       "19                2          57   \n",
       "20                2          89   \n",
       "21               16         188   \n",
       "22                8         113   \n",
       "23                4         111   \n",
       "24                0          42   \n",
       "25                1          62   \n",
       "26                5         196   \n",
       "27                6          95   \n",
       "28                1          48   \n",
       "29               13         280   \n",
       "\n",
       "                                            stopwords  \\\n",
       "0                     [in, of, will, be, or, to, the]   \n",
       "1                            [if, you, you, will, be]   \n",
       "2                                           [you, on]   \n",
       "3                                                  []   \n",
       "4                                                  []   \n",
       "5                                                [be]   \n",
       "6                                         [with, you]   \n",
       "7   [of, the, about, our, just, with, is, that, it...   \n",
       "8                       [be, at, by, on, at, the, in]   \n",
       "9   [the, to, up, the, in, the, by, the, that, he,...   \n",
       "10                                                 []   \n",
       "11            [was, so, in, the, that, they, in, the]   \n",
       "12                                                 []   \n",
       "13                                         [to, from]   \n",
       "14                           [are, the, from, for, a]   \n",
       "15                                                 []   \n",
       "16                                  [is, a, is, with]   \n",
       "17               [will, very, for, for, has, my, and]   \n",
       "18                                                 []   \n",
       "19                                            [is, a]   \n",
       "20                                          [my, you]   \n",
       "21  [the, in, the, but, it, is, more, and, more, t...   \n",
       "22           [are, to, your, have, it, as, and, will]   \n",
       "23                                [of, just, out, in]   \n",
       "24                                                 []   \n",
       "25                                               [in]   \n",
       "26                            [that, is, no, for, by]   \n",
       "27                     [have, now, that, has, not, a]   \n",
       "28                                               [in]   \n",
       "29  [a, because, the, the, his, the, after, the, t...   \n",
       "\n",
       "                                           clean_text  Sentiment  Topic  \\\n",
       "0   making great progress davos tremendous numbers...   0.566667      0   \n",
       "1                    sorry come immediately sent back  -0.250000      3   \n",
       "2                                     fridaybig crowd   0.000000      0   \n",
       "3                                                true   0.350000      9   \n",
       "4                                            pressure   0.000000      5   \n",
       "5                                               great   0.800000      3   \n",
       "6                                 great working maria   0.800000      1   \n",
       "7   many great things signed giant trade deal chin...   0.333333      5   \n",
       "8   interviewed eastern joesquawk cnbc world econo...   0.300000      5   \n",
       "9   senates mess made house democrats biden admitt...  -0.175000      5   \n",
       "10                                              enjoy   0.400000      5   \n",
       "11  case overwhelming house need demand witnesses ...   0.500000      3   \n",
       "12                        story hope fake news covers  -0.500000      8   \n",
       "13  heading back washington davos switzerland succ...   0.375000      8   \n",
       "14   taking nomination away bernie second time rigged   0.000000      6   \n",
       "15                       thank pictwittercomrqwbqjyza   0.000000      6   \n",
       "16       steyer major loser doesnt second time bernie   0.031250      8   \n",
       "17  carlos exciting great florida great complete t...   0.400000      1   \n",
       "18                                               true   0.350000      6   \n",
       "19                  real thank pictwittercomjwyoyiidw   0.200000      8   \n",
       "20                                               soon   0.000000      5   \n",
       "21  crazy bernie takes lead democrat primaries loo...  -0.050000      8   \n",
       "22  democrats going destroy social security totall...  -0.055556      7   \n",
       "23  poll radical left nothing democrats came flori...   0.300000      3   \n",
       "24               love alabama pictwittercomzdlbdehhvn   0.500000      5   \n",
       "25        interesting poll texas pictwittercomusvapgp   0.500000      9   \n",
       "26  president trump shows electability match elect...   0.000000      9   \n",
       "27  democrats conceded president trump committed c...   0.000000      0   \n",
       "28            close race kansas pictwittercommexfvhku   0.000000      0   \n",
       "29  democrats dont want witness trade shifty schif...   0.000000      3   \n",
       "\n",
       "           Target  \n",
       "0    Bad Response  \n",
       "1    Bad Response  \n",
       "2    Bad Response  \n",
       "3   Good Response  \n",
       "4    Bad Response  \n",
       "5    Bad Response  \n",
       "6    Bad Response  \n",
       "7    Bad Response  \n",
       "8    Bad Response  \n",
       "9    Bad Response  \n",
       "10   Bad Response  \n",
       "11   Bad Response  \n",
       "12   Bad Response  \n",
       "13   Bad Response  \n",
       "14  Good Response  \n",
       "15  Good Response  \n",
       "16   Bad Response  \n",
       "17   Bad Response  \n",
       "18  Good Response  \n",
       "19   Bad Response  \n",
       "20   Bad Response  \n",
       "21   Bad Response  \n",
       "22  Good Response  \n",
       "23   Bad Response  \n",
       "24   Bad Response  \n",
       "25  Good Response  \n",
       "26  Good Response  \n",
       "27   Bad Response  \n",
       "28   Bad Response  \n",
       "29   Bad Response  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DF Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'tweet', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'video', 'geo', 'positive', 'death', 'word_count',\n",
       "       'avg_word_length', 'stopwords_count', 'char_count', 'stopwords',\n",
       "       'clean_text', 'Sentiment', 'Poll', 'Start Date', 'End Date', 'Sample',\n",
       "       'MoE', 'Biden (D)', 'Trump (R)', 'Spread', 'Topic', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_df = Master_Tweet_dataset.copy()\n",
    "EDA_df.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe for just text data\n",
    "#Tweet_df = Master_Tweet_dataset[['date','tweet','stopwords','clean_text']]\n",
    "#creating dataframe for poll data \n",
    "#Poll_df = Master_Tweet_dataset[['Start Date','End Date','Sample','MoE','Poll','Biden (D)', 'Trump (R)']]\n",
    "\n",
    "\n",
    "# couldn't find any value from these columns\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['tweet','Poll',\n",
    "       'Start Date', 'End Date', 'Sample', 'MoE', 'Biden (D)', 'Trump (R)',\n",
    "       'Spread'],axis=1)\n",
    "\n",
    "#converting date column to integer for modeling purposes\n",
    "#def datetime_to_int(dt):\n",
    "    #return int(dt.strftime(\"%Y%m%d\"))\n",
    "\n",
    "#Master_Tweet_dataset['date'] = Master_Tweet_df['date'].apply(lambda x: datetime_to_int(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'replies_count', 'retweets_count', 'likes_count',\n",
       "       'video', 'geo', 'positive', 'death', 'word_count', 'avg_word_length',\n",
       "       'stopwords_count', 'char_count', 'stopwords', 'clean_text', 'Sentiment',\n",
       "       'Topic', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making sure datatype is ok for modeling\n",
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "Master_Tweet_dataset.isnull().sum()\n",
    "Master_Tweet_dataset['death'] = Master_Tweet_dataset['death'].fillna(method='backfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master_Tweet_dataset.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df to csv for upload in other notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_modelready.csv')\n",
    "#Tweet_df.to_csv('data/Tweet_text_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17481"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Master_Tweet_dataset['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
