{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8idLC0ams5zc"
   },
   "source": [
    "## Objective\n",
    "\n",
    "For the purpose of this analysis, I will attempt to measure the sentiment of tweets to learn whether tweets impact the number of Covid-19 cases and deaths in the United States. This study is important as the reopening of our society, from going to get an ice cream cone to being able to earn a living, hinges on our ability to lower the rate of infection in our country. With so many individuals receiving their news and information through social media, being able to predict how COVID cases will either increase or decrease based on tweets can inform public policy. Should we be able to predict the future number of COVID cases based on the text of tweets; public officials, business leaders and concerned citizens can alter their tweeting practices to promote improved COVID outcomes.\n",
    "\n",
    "To create the dataset, I utilized the TWINT library to collect all tweets from January 1,2020 until July 10th. I then made various subsets of the tweets. For example, to measure the impact of tweets by public leaders viewed as polar opposites regarding their response to the pandemic, I collected tweets by President Trump and the Governor of New York, Andrew Cuomo. Another subset of tweets that I labeled as baseline consists of tweets by the New York Times and Washington Post - two of America's leading journalism outlets.\n",
    "\n",
    "The purpose of creating these subsets is that the baseline tweets can be considered to be those that communicate mainly fact. While they might have op-ed columnists, we can assume that most tweets from the news reporting divisions will provide factual updates on the Covid response. By considering the two polar opposites, Trump and Cuomo, we can measure Covid outcomes, in terms of cases, after the tweets have been consumed by the public. Finally, the main Covid collection will allow us to see whether more individuals subscribed to the Trump/Cuomo tweets and how Covid cases changed, for the positive or negative, in their region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Obtaining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "For the notebooks that contain the queries for the tweets gathered on TWINT, please refer to the Covid Data Queries notebook in the repo. The JSON files for these queries were used to create DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('tweets/Covid_tweets3.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('tweets/Trump_Covid_tweets3.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('tweets/Cuomo_Covid_tweets3.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('tweets/Nytimes_Covid_tweets3.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('tweets/Washpost_tweets3.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['Date'] = All_Covid_tweets['date']\n",
    "Trump_Covid_tweets['Date'] = Trump_Covid_tweets['date']\n",
    "Cuomo_Covid_tweets['Date'] = Cuomo_Covid_tweets['date']\n",
    "Baseline_tweets['Date'] = Baseline_tweets['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "Data for Covid Cases and Deaths was collected from The COVID Tracking Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "\n",
    "covid_cases = pd.read_csv('covid data/time_series_covid_19_confirmed.csv')\n",
    "\n",
    "#Getting US data - confirmed cases\n",
    "covid_cases = covid_cases[covid_cases['Country/Region'] == 'US']\n",
    "#covid_cases = covid_cases.transpose()\n",
    "\n",
    "# Covid death data set\n",
    "\n",
    "covid_deaths = pd.read_csv('covid data/time_series_covid_19_deaths.csv')\n",
    "\n",
    "\n",
    "#Getting US data - confirmed cases\n",
    "\n",
    "#covid_deaths = covid_deaths.transpose()\n",
    "covid_deaths = covid_deaths[covid_deaths['Country/Region'] == 'US']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oRKml9Cs5zl"
   },
   "outputs": [],
   "source": [
    "#Covid cases and deaths (still need to rename columns, from left to right = cases then deaths)\n",
    "covid_data = pd.concat([covid_cases,covid_deaths],axis=0)\n",
    "covid_data = covid_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vb5bh9Gs5zq"
   },
   "outputs": [],
   "source": [
    "covid_data = covid_data.drop(['Province/State','Country/Region','Lat','Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4AKkXwKPs5zu",
    "outputId": "d3bde4d5-bd0f-4d73-98e5-d2a634a36133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>225</th>\n",
       "      <th>225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/22/20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/23/20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/24/20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/25/20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/26/20</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        225 225\n",
       "1/22/20   1   0\n",
       "1/23/20   1   0\n",
       "1/24/20   2   0\n",
       "1/25/20   2   0\n",
       "1/26/20   5   0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "tLy93bv3s5zy",
    "outputId": "730324d9-1f09-48f7-dc54-a0e29b917be0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date  Cases  Deaths\n",
       "0  1/22/20      1       0\n",
       "1  1/23/20      1       0\n",
       "2  1/24/20      2       0\n",
       "3  1/25/20      2       0\n",
       "4  1/26/20      5       0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Edited column names in Excel for Merge\n",
    "covid_data_formatted = pd.read_excel('covid data/covid_data_date.xlsx')\n",
    "covid_data_formatted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKVwUotFs5z2"
   },
   "outputs": [],
   "source": [
    "#Converting all Date columns to datetime for Merge\n",
    "covid_data_formatted['Date'] = pd.to_datetime(covid_data_formatted['Date'])\n",
    "All_Covid_tweets['Date'] = pd.to_datetime(All_Covid_tweets['Date'])\n",
    "Trump_Covid_tweets['Date'] = pd.to_datetime(Trump_Covid_tweets['Date'])\n",
    "Cuomo_Covid_tweets['Date'] = pd.to_datetime(Cuomo_Covid_tweets['Date'])\n",
    "Baseline_tweets['Date'] = pd.to_datetime(Baseline_tweets['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [],
   "source": [
    "#All Tweet Data with corresponding case/death information\n",
    "All_Covid_tweets_case_data = pd.merge(All_Covid_tweets,covid_data_formatted,on='Date')\n",
    "#Trump Tweet Data with corresponding case/death information\n",
    "Trump_Covid_tweets_case_data = pd.merge(Trump_Covid_tweets,covid_data_formatted,on='Date')\n",
    "#Cuomo Tweet Data with corresponding case/death information\n",
    "Cuomo_Covid_tweets_case_data = pd.merge(Cuomo_Covid_tweets,covid_data_formatted, on='Date')\n",
    "#Baseline Tweet Data with corresponding case/death information\n",
    "Baseline_tweets_case_data = pd.merge(Baseline_tweets,covid_data_formatted,on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VU19K6Bss5z7"
   },
   "source": [
    "### Adding case/death data for two weeks after original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgQEpVVQs5z7"
   },
   "outputs": [],
   "source": [
    "#Getting date two weeks from now for Covid case/death reaction to Tweets\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "N = 14\n",
    "days_N_from_now = All_Covid_tweets['Date'] + timedelta(days=N)\n",
    "\n",
    "All_Covid_tweets_case_data['14 days'] = (All_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Trump_Covid_tweets_case_data['14 days'] = (Trump_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Cuomo_Covid_tweets_case_data['14 days'] = (Cuomo_Covid_tweets_case_data['Date'] +timedelta(days=N))\n",
    "Baseline_tweets_case_data['14 days'] = (Baseline_tweets_case_data['Date'] + timedelta(days=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dtrDv-Z3s5z-",
    "outputId": "c848bcd8-253c-4769-f52a-a66f65599725"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   14 days  Cases  Deaths\n",
       "0  1/22/20      1       0\n",
       "1  1/23/20      1       0\n",
       "2  1/24/20      2       0\n",
       "3  1/25/20      2       0\n",
       "4  1/26/20      5       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data_two_week = pd.read_excel('covid data/covid_data_14days.xlsx')\n",
    "covid_data_two_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt7wqyBDs50B"
   },
   "outputs": [],
   "source": [
    "#Converting all Date columns to datetime for Merge\n",
    "covid_data_two_week['14 days'] = pd.to_datetime(covid_data_two_week['14 days'])\n",
    "All_Covid_tweets_case_data['14 days'] = pd.to_datetime(All_Covid_tweets_case_data['14 days'])\n",
    "Trump_Covid_tweets_case_data['14 days'] = pd.to_datetime(Trump_Covid_tweets_case_data['14 days'])\n",
    "Cuomo_Covid_tweets_case_data['14 days'] = pd.to_datetime(Cuomo_Covid_tweets_case_data['14 days'])\n",
    "Baseline_tweets_case_data['14 days'] = pd.to_datetime(Baseline_tweets_case_data['14 days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZg-y80ks50D"
   },
   "outputs": [],
   "source": [
    "#All Tweet Data with corresponding case/death information\n",
    "All_Covid_tweets_case_data = pd.merge(All_Covid_tweets_case_data,covid_data_two_week,on='14 days')\n",
    "#Trump Tweet Data with corresponding case/death information\n",
    "Trump_Covid_tweets_case_data = pd.merge(Trump_Covid_tweets_case_data,covid_data_two_week,on='14 days')\n",
    "#Cuomo Tweet Data with corresponding case/death information\n",
    "Cuomo_Covid_tweets_case_data = pd.merge(Cuomo_Covid_tweets_case_data,covid_data_two_week, on='14 days')\n",
    "#Baseline Tweet Data with corresponding case/death information\n",
    "Baseline_tweets_case_data = pd.merge(Baseline_tweets_case_data,covid_data_two_week,on='14 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZYqxwBBs50F"
   },
   "source": [
    "### Adding Case/Death Data for four weeks after original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lR8d_K6Vs50G",
    "outputId": "103cedb8-28bf-4f74-bf8b-c7235558a44c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   28 days  Cases  Deaths\n",
       "0  1/22/20      1       0\n",
       "1  1/23/20      1       0\n",
       "2  1/24/20      2       0\n",
       "3  1/25/20      2       0\n",
       "4  1/26/20      5       0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data_four_week = pd.read_excel('covid data/covid_data_28days.xlsx')\n",
    "covid_data_four_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Dates and COVID Data for two weeks after Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDBDBj6is50K"
   },
   "outputs": [],
   "source": [
    "#Getting date two weeks from now for Covid case/death reaction to Tweets\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "N = 28\n",
    "days_N_from_now = All_Covid_tweets['Date'] + timedelta(days=N)\n",
    "\n",
    "All_Covid_tweets_case_data['28 days'] = (All_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Trump_Covid_tweets_case_data['28 days'] = (Trump_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Cuomo_Covid_tweets_case_data['28 days'] = (Cuomo_Covid_tweets_case_data['Date'] +timedelta(days=N))\n",
    "Baseline_tweets_case_data['28 days'] = (Baseline_tweets_case_data['Date'] + timedelta(days=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJcO0yP3s50M"
   },
   "outputs": [],
   "source": [
    "#Converting all Date columns to datetime for Merge\n",
    "covid_data_four_week['28 days'] = pd.to_datetime(covid_data_four_week['28 days'])\n",
    "All_Covid_tweets_case_data['28 days'] = pd.to_datetime(All_Covid_tweets_case_data['28 days'])\n",
    "Trump_Covid_tweets_case_data['28 days'] = pd.to_datetime(Trump_Covid_tweets_case_data['28 days'])\n",
    "Cuomo_Covid_tweets_case_data['28 days'] = pd.to_datetime(Cuomo_Covid_tweets_case_data['28 days'])\n",
    "Baseline_tweets_case_data['28 days'] = pd.to_datetime(Baseline_tweets_case_data['28 days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nz5ts71ws50O"
   },
   "outputs": [],
   "source": [
    "#All Tweet Data with corresponding case/death information\n",
    "All_Covid_tweets_case_data = pd.merge(All_Covid_tweets_case_data,covid_data_four_week,on='28 days')\n",
    "#Trump Tweet Data with corresponding case/death information\n",
    "Trump_Covid_tweets_case_data = pd.merge(Trump_Covid_tweets_case_data,covid_data_four_week,on='28 days')\n",
    "#Cuomo Tweet Data with corresponding case/death information\n",
    "Cuomo_Covid_tweets_case_data = pd.merge(Cuomo_Covid_tweets_case_data,covid_data_four_week, on='28 days')\n",
    "#Baseline Tweet Data with corresponding case/death information\n",
    "Baseline_tweets_case_data = pd.merge(Baseline_tweets_case_data,covid_data_four_week,on='28 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "EwN_4RC8s50R",
    "outputId": "e7ef582c-cbac-4f2f-bfc1-01f3171ac4af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtags</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>geo</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>link</th>\n",
       "      <th>mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>video</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases_x</th>\n",
       "      <th>Deaths_x</th>\n",
       "      <th>14 days</th>\n",
       "      <th>Cases_y</th>\n",
       "      <th>Deaths_y</th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270707306578264064</td>\n",
       "      <td>2020-06-10 13:20:05</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270707306578264065</td>\n",
       "      <td>209</td>\n",
       "      <td>https://twitter.com/nytimes/status/12707073065...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2000702</td>\n",
       "      <td>113631</td>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>2382426</td>\n",
       "      <td>122604</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>3054699</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270636833555308544</td>\n",
       "      <td>2020-06-10 08:40:03</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270636833555308544</td>\n",
       "      <td>857</td>\n",
       "      <td>https://twitter.com/nytimes/status/12706368335...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2000702</td>\n",
       "      <td>113631</td>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>2382426</td>\n",
       "      <td>122604</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>3054699</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270815442173603840</td>\n",
       "      <td>2020-06-10 20:29:46</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270815442173603841</td>\n",
       "      <td>159</td>\n",
       "      <td>https://twitter.com/washingtonpost/status/1270...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2000702</td>\n",
       "      <td>113631</td>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>2382426</td>\n",
       "      <td>122604</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>3054699</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270541216308957184</td>\n",
       "      <td>2020-06-10 02:20:06</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270541216308957184</td>\n",
       "      <td>382</td>\n",
       "      <td>https://twitter.com/nytimes/status/12705412163...</td>\n",
       "      <td>[nytmag]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2996098</td>\n",
       "      <td>131480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270470755889840128</td>\n",
       "      <td>2020-06-09 21:40:07</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270470755889840134</td>\n",
       "      <td>404</td>\n",
       "      <td>https://twitter.com/nytimes/status/12704707558...</td>\n",
       "      <td>[nytmag]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2996098</td>\n",
       "      <td>131480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtags      conversation_id          created_at       date geo hashtags  \\\n",
       "0       []  1270707306578264064 2020-06-10 13:20:05 2020-06-10           []   \n",
       "1       []  1270636833555308544 2020-06-10 08:40:03 2020-06-10           []   \n",
       "2       []  1270815442173603840 2020-06-10 20:29:46 2020-06-10           []   \n",
       "3       []  1270541216308957184 2020-06-10 02:20:06 2020-06-09           []   \n",
       "4       []  1270470755889840128 2020-06-09 21:40:07 2020-06-09           []   \n",
       "\n",
       "                    id  likes_count  \\\n",
       "0  1270707306578264065          209   \n",
       "1  1270636833555308544          857   \n",
       "2  1270815442173603841          159   \n",
       "3  1270541216308957184          382   \n",
       "4  1270470755889840134          404   \n",
       "\n",
       "                                                link  mentions  ... video  \\\n",
       "0  https://twitter.com/nytimes/status/12707073065...        []  ...     0   \n",
       "1  https://twitter.com/nytimes/status/12706368335...        []  ...     0   \n",
       "2  https://twitter.com/washingtonpost/status/1270...        []  ...     0   \n",
       "3  https://twitter.com/nytimes/status/12705412163...  [nytmag]  ...     0   \n",
       "4  https://twitter.com/nytimes/status/12704707558...  [nytmag]  ...     0   \n",
       "\n",
       "        Date  Cases_x Deaths_x    14 days  Cases_y Deaths_y    28 days  \\\n",
       "0 2020-06-10  2000702   113631 2020-06-24  2382426   122604 2020-07-08   \n",
       "1 2020-06-10  2000702   113631 2020-06-24  2382426   122604 2020-07-08   \n",
       "2 2020-06-10  2000702   113631 2020-06-24  2382426   122604 2020-07-08   \n",
       "3 2020-06-09  1979908   112714 2020-06-23  2347491   121847 2020-07-07   \n",
       "4 2020-06-09  1979908   112714 2020-06-23  2347491   121847 2020-07-07   \n",
       "\n",
       "     Cases  Deaths  \n",
       "0  3054699  132300  \n",
       "1  3054699  132300  \n",
       "2  3054699  132300  \n",
       "3  2996098  131480  \n",
       "4  2996098  131480  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baseline_tweets_case_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7M1Xrmj6s50T"
   },
   "source": [
    "### Combined Tweet DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSKxZ74ys50T"
   },
   "outputs": [],
   "source": [
    "#Tweet dataframes combined\n",
    "\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets_case_data,Trump_Covid_tweets_case_data,Cuomo_Covid_tweets_case_data,Baseline_tweets_case_data])\n",
    "#Master_Tweet_df.to_csv('raw_tweet_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing US State Data from NYTimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NYTimes manages a github repo that tracks state by state COVID Data. This data can be useful later in the analysis when we track how certain localities have fared dealing with the COVID pandemic. Tracking state COVID details will allow for examination of whether states that are classified as subscribing to the tenets of the Trump administrtion respond better/worse than states that might align more with the politics of NY governor Andrew Cuomo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data from CSV\n",
    "state_case_df = pd.read_csv('covid data/us-states.csv')\n",
    "\n",
    "#Groupby to get states by state\n",
    "state_case_df.groupby('state')\n",
    "\n",
    "state_case_df = state_case_df.sort_values(['state','date'],ascending=[True,True])\n",
    "#state_case_df = state_case_df.sort_values('date',ascending=True)\n",
    "state_case_df.reset_index(drop=True,inplace=True)\n",
    "#state_case_df = state_case_df.sort_values('date',ascending=True)\n",
    "#state_case_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['cashtags' 'conversation_id' 'geo' 'hashtags' 'id' 'link' 'mentions'\\n 'name' 'near' 'photos' 'place' 'quote_url' 'reply_to' 'retweet'\\n 'retweet_date' 'retweet_id' 'source' 'time' 'timezone' 'trans_dest'\\n 'trans_src' 'translate' 'urls' 'user_id' 'user_rt' 'user_rt_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b7baa41177ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m        \u001b[0;34m'retweet_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'retweet_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m        \u001b[0;34m'timezone'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trans_dest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trans_src'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'translate'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'urls'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m        'user_id', 'user_rt', 'user_rt_id','date'],axis=1)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4964\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4965\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4966\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['cashtags' 'conversation_id' 'geo' 'hashtags' 'id' 'link' 'mentions'\\n 'name' 'near' 'photos' 'place' 'quote_url' 'reply_to' 'retweet'\\n 'retweet_date' 'retweet_id' 'source' 'time' 'timezone' 'trans_dest'\\n 'trans_src' 'translate' 'urls' 'user_id' 'user_rt' 'user_rt_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#dropping unnecessary columns\n",
    "\n",
    "Master_Tweet_df = Master_Tweet_df.drop(['cashtags', 'conversation_id','geo', 'hashtags',\n",
    "       'id','link', 'mentions', 'name', 'near', 'photos',\n",
    "       'place', 'quote_url','reply_to', 'retweet',\n",
    "       'retweet_date', 'retweet_id','source', 'time',\n",
    "       'timezone', 'trans_dest', 'trans_src', 'translate','urls',\n",
    "       'user_id', 'user_rt', 'user_rt_id',],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'date', 'likes_count', 'replies_count', 'retweets_count',\n",
       "       'tweet', 'username', 'video', 'Date', 'Cases_x', 'Deaths_x', '14 days',\n",
       "       'Cases_y', 'Deaths_y', '28 days', 'Cases', 'Deaths', 'word_count',\n",
       "       'avg_word_length', 'stopwords_count', 'clean_text', 'char_count',\n",
       "       'stopwords', 'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install textfeatures\n",
    "import textfeatures as tf\n",
    "Master_Tweet_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>video</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases_x</th>\n",
       "      <th>Deaths_x</th>\n",
       "      <th>...</th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two of the United States leading news sources,...</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>26</td>\n",
       "      <td>10.821429</td>\n",
       "      <td>7</td>\n",
       "      <td>united states leading news sources time today ...</td>\n",
       "      <td>332</td>\n",
       "      <td>[of, the, and, these, do, not, or]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two of the United States leading news sources,...</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>26</td>\n",
       "      <td>10.821429</td>\n",
       "      <td>7</td>\n",
       "      <td>united states leading news sources time today ...</td>\n",
       "      <td>332</td>\n",
       "      <td>[of, the, and, these, do, not, or]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>…Unless U’re a physician or a nurse in a surgi...</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>36</td>\n",
       "      <td>6.216216</td>\n",
       "      <td>16</td>\n",
       "      <td>unless physician nurse surgical room business ...</td>\n",
       "      <td>267</td>\n",
       "      <td>[a, or, a, in, a, you, have, no, a, in, the, o...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-26 23:00:14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>The reality is that Andy Beshear didn't create...</td>\n",
       "      <td>nealhead</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>47</td>\n",
       "      <td>4.872340</td>\n",
       "      <td>21</td>\n",
       "      <td>reality andy beshear didnt create covid didnt ...</td>\n",
       "      <td>277</td>\n",
       "      <td>[is, that, didn't, he, didn't, it, in, the, an...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-26 22:34:09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In large countries such as the United States, ...</td>\n",
       "      <td>6121el</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>43</td>\n",
       "      <td>5.395349</td>\n",
       "      <td>14</td>\n",
       "      <td>large countries united states russia brazil in...</td>\n",
       "      <td>275</td>\n",
       "      <td>[such, as, the, and, the, of, the, is, to, or,...</td>\n",
       "      <td>0.026984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at  likes_count  replies_count  retweets_count  \\\n",
       "0 2020-05-27 01:57:20            0              0               0   \n",
       "1 2020-05-27 01:57:20            0              0               0   \n",
       "2 2020-05-26 23:18:19            0              0               0   \n",
       "3 2020-05-26 23:00:14            0              2               0   \n",
       "4 2020-05-26 22:34:09            1              0               1   \n",
       "\n",
       "                                               tweet         username  video  \\\n",
       "0  Two of the United States leading news sources,...  whitewindlandon      0   \n",
       "1  Two of the United States leading news sources,...  whitewindlandon      0   \n",
       "2  …Unless U’re a physician or a nurse in a surgi...          rescon1      0   \n",
       "3  The reality is that Andy Beshear didn't create...         nealhead      0   \n",
       "4  In large countries such as the United States, ...           6121el      0   \n",
       "\n",
       "        Date  Cases_x  Deaths_x  ...    28 days    Cases  Deaths word_count  \\\n",
       "0 2020-05-26  1689162     99952  ... 2020-06-23  2347491  121847         26   \n",
       "1 2020-05-26  1689162     99952  ... 2020-06-23  2347491  121847         26   \n",
       "2 2020-05-26  1689162     99952  ... 2020-06-23  2347491  121847         36   \n",
       "3 2020-05-26  1689162     99952  ... 2020-06-23  2347491  121847         47   \n",
       "4 2020-05-26  1689162     99952  ... 2020-06-23  2347491  121847         43   \n",
       "\n",
       "   avg_word_length  stopwords_count  \\\n",
       "0        10.821429                7   \n",
       "1        10.821429                7   \n",
       "2         6.216216               16   \n",
       "3         4.872340               21   \n",
       "4         5.395349               14   \n",
       "\n",
       "                                          clean_text  char_count  \\\n",
       "0  united states leading news sources time today ...         332   \n",
       "1  united states leading news sources time today ...         332   \n",
       "2  unless physician nurse surgical room business ...         267   \n",
       "3  reality andy beshear didnt create covid didnt ...         277   \n",
       "4  large countries united states russia brazil in...         275   \n",
       "\n",
       "                                           stopwords Sentiment  \n",
       "0                 [of, the, and, these, do, not, or]  0.000000  \n",
       "1                 [of, the, and, these, do, not, or]  0.000000  \n",
       "2  [a, or, a, in, a, you, have, no, a, in, the, o...  0.000000  \n",
       "3  [is, that, didn't, he, didn't, it, in, the, an...  0.000000  \n",
       "4  [such, as, the, and, the, of, the, is, to, or,...  0.026984  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Master_Tweet_df=Master_Tweet_df.drop('date',axis=1)\n",
    "Master_Tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>username</th>\n",
       "      <th>video</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Deaths_y</th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two of the United States leading news sources,...</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>26</td>\n",
       "      <td>10.821429</td>\n",
       "      <td>7</td>\n",
       "      <td>united states leading news sources time today ...</td>\n",
       "      <td>332</td>\n",
       "      <td>[of, the, and, these, do, not, or]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two of the United States leading news sources,...</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>26</td>\n",
       "      <td>10.821429</td>\n",
       "      <td>7</td>\n",
       "      <td>united states leading news sources time today ...</td>\n",
       "      <td>332</td>\n",
       "      <td>[of, the, and, these, do, not, or]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>…Unless U’re a physician or a nurse in a surgi...</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>36</td>\n",
       "      <td>6.216216</td>\n",
       "      <td>16</td>\n",
       "      <td>unless physician nurse surgical room business ...</td>\n",
       "      <td>267</td>\n",
       "      <td>[a, or, a, in, a, you, have, no, a, in, the, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-26 23:00:14</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>The reality is that Andy Beshear didn't create...</td>\n",
       "      <td>nealhead</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>47</td>\n",
       "      <td>4.872340</td>\n",
       "      <td>21</td>\n",
       "      <td>reality andy beshear didnt create covid didnt ...</td>\n",
       "      <td>277</td>\n",
       "      <td>[is, that, didn't, he, didn't, it, in, the, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-26 22:34:09</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In large countries such as the United States, ...</td>\n",
       "      <td>6121el</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>43</td>\n",
       "      <td>5.395349</td>\n",
       "      <td>14</td>\n",
       "      <td>large countries united states russia brazil in...</td>\n",
       "      <td>275</td>\n",
       "      <td>[such, as, the, and, the, of, the, is, to, or,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-26 22:22:16</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Right now, it's a very Good look for a Preside...</td>\n",
       "      <td>roswell32</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>38</td>\n",
       "      <td>4.976190</td>\n",
       "      <td>16</td>\n",
       "      <td>right good look president united states leadin...</td>\n",
       "      <td>250</td>\n",
       "      <td>[it's, a, very, for, a, of, the, by, is, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-26 21:57:10</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>United States has officially surpassed the gri...</td>\n",
       "      <td>gary_lyman</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>44</td>\n",
       "      <td>5.295455</td>\n",
       "      <td>18</td>\n",
       "      <td>united states officially surpassed grim milest...</td>\n",
       "      <td>276</td>\n",
       "      <td>[has, the, of, over, from, is, that, this, is,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-26 21:13:57</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The United States has more confirmed COVID-19 ...</td>\n",
       "      <td>oldnavy1968</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>40</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>13</td>\n",
       "      <td>united states confirmed covid cases next count...</td>\n",
       "      <td>249</td>\n",
       "      <td>[has, more, than, the, have, more, than, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-05-26 20:45:24</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The average age of deceased and COVID-19 posit...</td>\n",
       "      <td>dablazinjr</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>37</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>12</td>\n",
       "      <td>average deceased covid positive patients years...</td>\n",
       "      <td>235</td>\n",
       "      <td>[of, and, is, it, is, not, all, the, is, it, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-05-26 18:15:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You are some of the stupidest people how do yo...</td>\n",
       "      <td>smartpe53402672</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>56</td>\n",
       "      <td>4.150943</td>\n",
       "      <td>25</td>\n",
       "      <td>stupidest people paid stupidity choosing votin...</td>\n",
       "      <td>275</td>\n",
       "      <td>[are, some, of, the, how, do, you, for, is, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-05-26 16:32:14</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How come South Korea and the United States saw...</td>\n",
       "      <td>craving_filled</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>50</td>\n",
       "      <td>4.560000</td>\n",
       "      <td>23</td>\n",
       "      <td>come south korea united states first covid cas...</td>\n",
       "      <td>279</td>\n",
       "      <td>[and, the, their, the, same, but, they, have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-05-26 12:45:53</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Says he who said the United States had \"one\", ...</td>\n",
       "      <td>hsquared_studio</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>49</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>18</td>\n",
       "      <td>says said united states fifteen covid cases al...</td>\n",
       "      <td>327</td>\n",
       "      <td>[he, who, the, had, and, then, only, which, he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-05-26 12:41:10</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am not making this political. The studies ha...</td>\n",
       "      <td>jimmyfalco2</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>41</td>\n",
       "      <td>5.170732</td>\n",
       "      <td>16</td>\n",
       "      <td>making political studies shown effective covid...</td>\n",
       "      <td>252</td>\n",
       "      <td>[am, not, this, have, that, is, against, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-05-26 12:28:42</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>while the United States is still puzzling over...</td>\n",
       "      <td>ralfstein3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>38</td>\n",
       "      <td>4.289474</td>\n",
       "      <td>15</td>\n",
       "      <td>united states still puzzling whether masks wor...</td>\n",
       "      <td>200</td>\n",
       "      <td>[while, the, is, over, or, the, of, the, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-26 12:00:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>It is likely that today we will reach 100,000 ...</td>\n",
       "      <td>crawfordstuff</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>51</td>\n",
       "      <td>4.740000</td>\n",
       "      <td>20</td>\n",
       "      <td>likely today reach deaths united states covid ...</td>\n",
       "      <td>291</td>\n",
       "      <td>[is, that, we, will, in, the, from, you, to, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-05-26 10:54:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>And now this guy running the World Health Orga...</td>\n",
       "      <td>sallybeatty6</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>47</td>\n",
       "      <td>4.782609</td>\n",
       "      <td>22</td>\n",
       "      <td>running world health organization wants believ...</td>\n",
       "      <td>266</td>\n",
       "      <td>[now, this, the, all, to, the, not, the, or, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-05-26 10:54:05</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contribute a rapid review or request one for \"...</td>\n",
       "      <td>outbreaksci</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>32</td>\n",
       "      <td>8.468750</td>\n",
       "      <td>9</td>\n",
       "      <td>contribute rapid review request geographical s...</td>\n",
       "      <td>304</td>\n",
       "      <td>[a, or, for, of, and, in, the, or, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-05-26 06:58:42</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>*Japan - Only part of regions of Tokyo and Osa...</td>\n",
       "      <td>natsumugikezine</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>43</td>\n",
       "      <td>4.086957</td>\n",
       "      <td>13</td>\n",
       "      <td>japan part regions tokyo osaka accepts delay m...</td>\n",
       "      <td>234</td>\n",
       "      <td>[of, of, and, or, can, be, for, a, or, more, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-05-26 04:06:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Let's assume the worst here for a moment. COVi...</td>\n",
       "      <td>wadetheleopard</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>43</td>\n",
       "      <td>4.813953</td>\n",
       "      <td>16</td>\n",
       "      <td>lets assume worst moment covid hits time worst...</td>\n",
       "      <td>249</td>\n",
       "      <td>[the, here, for, a, it's, all, and, the, a, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>…Unless U’re a physician or a nurse in a surgi...</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>36</td>\n",
       "      <td>6.216216</td>\n",
       "      <td>16</td>\n",
       "      <td>unless physician nurse surgical room business ...</td>\n",
       "      <td>267</td>\n",
       "      <td>[a, or, a, in, a, you, have, no, a, in, the, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-05-26 22:22:16</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Right now, it's a very Good look for a Preside...</td>\n",
       "      <td>roswell32</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>38</td>\n",
       "      <td>4.976190</td>\n",
       "      <td>16</td>\n",
       "      <td>right good look president united states leadin...</td>\n",
       "      <td>250</td>\n",
       "      <td>[it's, a, very, for, a, of, the, by, is, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-05-26 18:15:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>You are some of the stupidest people how do yo...</td>\n",
       "      <td>smartpe53402672</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>56</td>\n",
       "      <td>4.150943</td>\n",
       "      <td>25</td>\n",
       "      <td>stupidest people paid stupidity choosing votin...</td>\n",
       "      <td>275</td>\n",
       "      <td>[are, some, of, the, how, do, you, for, is, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-05-27 03:27:48</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Well, #COVID__19 or not, people still behaving...</td>\n",
       "      <td>parkerrobertda1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>37</td>\n",
       "      <td>5.731707</td>\n",
       "      <td>8</td>\n",
       "      <td>well covid__ people still behaving badly newyo...</td>\n",
       "      <td>278</td>\n",
       "      <td>[or, into, each, at, all, of, and, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-05-27 02:23:48</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>How can people be so ignorant, rude and nasty ...</td>\n",
       "      <td>gregggraison</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>48</td>\n",
       "      <td>4.770833</td>\n",
       "      <td>19</td>\n",
       "      <td>people ignorant rude nasty knowing fact medica...</td>\n",
       "      <td>276</td>\n",
       "      <td>[can, be, so, and, for, a, from, that, in, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-05-27 02:01:55</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I’m heartbroken about America. So much racism,...</td>\n",
       "      <td>dianepaul</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>46</td>\n",
       "      <td>5.086957</td>\n",
       "      <td>14</td>\n",
       "      <td>heartbroken america much racism much exploitat...</td>\n",
       "      <td>279</td>\n",
       "      <td>[about, so, am, about, in, and, who, have, no,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-05-27 01:58:29</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I don’t understand how people can be biased to...</td>\n",
       "      <td>art_muela</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>45</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>19</td>\n",
       "      <td>dont understand people biased towards russia b...</td>\n",
       "      <td>263</td>\n",
       "      <td>[how, can, be, out, of, or, being, the, of, be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-05-27 01:05:41</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[en]#Covid19 #TCGNRG #Map : 5/26/2020\\nDespite...</td>\n",
       "      <td>jfdorville</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>36</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>10</td>\n",
       "      <td>encovid tcgnrg despite confirmed covid cases a...</td>\n",
       "      <td>246</td>\n",
       "      <td>[the, and, the, is, from, the, or, the, of, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-05-26 23:44:03</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spent some today with @JoeBiden who talked COV...</td>\n",
       "      <td>thesteveholzer</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>41</td>\n",
       "      <td>6.525000</td>\n",
       "      <td>9</td>\n",
       "      <td>spent today joebiden talked covid response lac...</td>\n",
       "      <td>301</td>\n",
       "      <td>[some, with, who, by, of, and, not, be, more]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-05-26 23:32:53</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Do not desert the #NavajoNation America in #CO...</td>\n",
       "      <td>b1louder</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>35</td>\n",
       "      <td>7.171429</td>\n",
       "      <td>14</td>\n",
       "      <td>desert navajonation america covid__ times anyt...</td>\n",
       "      <td>286</td>\n",
       "      <td>[not, the, in, or, at, your, and, the, of, on,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>…Unless U’re a physician or a nurse in a surgi...</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>1689162</td>\n",
       "      <td>...</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>36</td>\n",
       "      <td>6.216216</td>\n",
       "      <td>16</td>\n",
       "      <td>unless physician nurse surgical room business ...</td>\n",
       "      <td>267</td>\n",
       "      <td>[a, or, a, in, a, you, have, no, a, in, the, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2020-03-19 10:28:18</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>1431</td>\n",
       "      <td>861</td>\n",
       "      <td>624</td>\n",
       "      <td>\"If I get corona, I get corona\": Miami spring ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>14157</td>\n",
       "      <td>...</td>\n",
       "      <td>8432</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>669272</td>\n",
       "      <td>35442</td>\n",
       "      <td>19</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>corona corona miami spring breakers covid hasn...</td>\n",
       "      <td>127</td>\n",
       "      <td>[them, from]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>2020-03-18 17:21:07</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>212</td>\n",
       "      <td>12</td>\n",
       "      <td>79</td>\n",
       "      <td>How the world’s political artists are depictin...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>8917</td>\n",
       "      <td>...</td>\n",
       "      <td>6846</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>637974</td>\n",
       "      <td>33329</td>\n",
       "      <td>12</td>\n",
       "      <td>7.545455</td>\n",
       "      <td>3</td>\n",
       "      <td>worlds political artists depicting covid pandemic</td>\n",
       "      <td>95</td>\n",
       "      <td>[the, are, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>2020-03-17 03:25:59</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>183</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>Opinion: Life in the Time of Covid-19 is total...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>...</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>12</td>\n",
       "      <td>6.909091</td>\n",
       "      <td>4</td>\n",
       "      <td>opinion life time covid totally unprecedented</td>\n",
       "      <td>88</td>\n",
       "      <td>[in, the, of, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>2020-03-16 17:51:04</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>525</td>\n",
       "      <td>29</td>\n",
       "      <td>238</td>\n",
       "      <td>Additionally, scientists still don’t know for ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>...</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>37</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>13</td>\n",
       "      <td>additionally scientists still dont know sure s...</td>\n",
       "      <td>237</td>\n",
       "      <td>[for, if, a, you, if, for, how, is, about, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>2020-03-16 17:44:10</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>189</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>It depends on unknown characteristics of the v...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>...</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>44</td>\n",
       "      <td>5.395349</td>\n",
       "      <td>18</td>\n",
       "      <td>depends unknown characteristics virus expresse...</td>\n",
       "      <td>278</td>\n",
       "      <td>[on, of, the, have, that, the, will, be, by, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>2020-03-16 15:22:37</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>133</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>One last party, one last dance, then goodbye: ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>...</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>18</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>4</td>\n",
       "      <td>last party last dance goodbye college students...</td>\n",
       "      <td>118</td>\n",
       "      <td>[then, in, the, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2020-03-16 14:07:56</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>114</td>\n",
       "      <td>Nursing home with the biggest cluster of covid...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>...</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>26</td>\n",
       "      <td>5.520000</td>\n",
       "      <td>10</td>\n",
       "      <td>nursing home biggest cluster covid deaths date...</td>\n",
       "      <td>164</td>\n",
       "      <td>[with, the, of, to, in, the, it, was, an, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2020-03-15 20:11:01</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>166</td>\n",
       "      <td>21</td>\n",
       "      <td>45</td>\n",
       "      <td>One last party, one last dance, then goodbye: ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2968</td>\n",
       "      <td>...</td>\n",
       "      <td>3561</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>556522</td>\n",
       "      <td>26548</td>\n",
       "      <td>18</td>\n",
       "      <td>5.882353</td>\n",
       "      <td>4</td>\n",
       "      <td>last party last dance goodbye college students...</td>\n",
       "      <td>118</td>\n",
       "      <td>[then, in, the, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2020-03-15 14:53:50</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>89</td>\n",
       "      <td>25</td>\n",
       "      <td>87</td>\n",
       "      <td>Federal vaccine development sites ill-suited t...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>2968</td>\n",
       "      <td>...</td>\n",
       "      <td>3561</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>556522</td>\n",
       "      <td>26548</td>\n",
       "      <td>11</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>federal vaccine development sites illsuited co...</td>\n",
       "      <td>99</td>\n",
       "      <td>[to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2020-03-13 17:45:06</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>294</td>\n",
       "      <td>56</td>\n",
       "      <td>167</td>\n",
       "      <td>Analysis: The U.S. may already be in a recessi...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2157</td>\n",
       "      <td>...</td>\n",
       "      <td>2300</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>497943</td>\n",
       "      <td>22731</td>\n",
       "      <td>22</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>analysis already recession could linger even c...</td>\n",
       "      <td>134</td>\n",
       "      <td>[be, in, a, and, it, after, the, is, over]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2020-03-13 15:09:02</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>221</td>\n",
       "      <td>17</td>\n",
       "      <td>94</td>\n",
       "      <td>Five states, D.C. order all schools closed in ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2157</td>\n",
       "      <td>...</td>\n",
       "      <td>2300</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>497943</td>\n",
       "      <td>22731</td>\n",
       "      <td>16</td>\n",
       "      <td>6.133333</td>\n",
       "      <td>4</td>\n",
       "      <td>five states order schools closed effort preven...</td>\n",
       "      <td>108</td>\n",
       "      <td>[all, in, to, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2020-03-13 15:03:03</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>1254</td>\n",
       "      <td>122</td>\n",
       "      <td>883</td>\n",
       "      <td>The number of Covid-19 cases in the D.C. regio...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>2157</td>\n",
       "      <td>...</td>\n",
       "      <td>2300</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>497943</td>\n",
       "      <td>22731</td>\n",
       "      <td>16</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>4</td>\n",
       "      <td>number covid cases region doubling every hours</td>\n",
       "      <td>100</td>\n",
       "      <td>[of, in, the, is]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2020-03-12 23:31:03</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>153</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>Opinion: Quarantining cities isn’t needed. But...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>1561</td>\n",
       "      <td>...</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>27</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>opinion quarantining cities isnt needed fast c...</td>\n",
       "      <td>209</td>\n",
       "      <td>[a, to, is, and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>2020-03-12 15:41:45</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>384</td>\n",
       "      <td>26</td>\n",
       "      <td>196</td>\n",
       "      <td>\"I’m done. I am absolutely done. Test me, don’...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>1561</td>\n",
       "      <td>...</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>30</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>5</td>\n",
       "      <td>done absolutely done test dont test dont care ...</td>\n",
       "      <td>175</td>\n",
       "      <td>[am, she, had, after, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2020-03-12 14:49:37</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>112</td>\n",
       "      <td>14</td>\n",
       "      <td>71</td>\n",
       "      <td>Confusion helped speed the spread of the coron...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>1561</td>\n",
       "      <td>...</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>37</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>confusion helped speed spread coronavirus near...</td>\n",
       "      <td>269</td>\n",
       "      <td>[the, of, the, to, a, at, the, of, the, as, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2020-03-12 11:07:32</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>616</td>\n",
       "      <td>83</td>\n",
       "      <td>402</td>\n",
       "      <td>Coronavirus arrives on Capitol Hill: First Sen...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>1561</td>\n",
       "      <td>...</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>13</td>\n",
       "      <td>7.833333</td>\n",
       "      <td>2</td>\n",
       "      <td>coronavirus arrives capitol hill first senate ...</td>\n",
       "      <td>107</td>\n",
       "      <td>[on, with]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2020-03-12 03:28:04</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>195</td>\n",
       "      <td>28</td>\n",
       "      <td>76</td>\n",
       "      <td>Opinion: For useful covid-19 testing, we need ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1109</td>\n",
       "      <td>...</td>\n",
       "      <td>1333</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>429686</td>\n",
       "      <td>18563</td>\n",
       "      <td>19</td>\n",
       "      <td>5.444444</td>\n",
       "      <td>5</td>\n",
       "      <td>opinion useful covid testing need think outsid...</td>\n",
       "      <td>117</td>\n",
       "      <td>[we, to, the, and, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2020-03-11 17:55:35</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>308</td>\n",
       "      <td>40</td>\n",
       "      <td>217</td>\n",
       "      <td>WHO declares a pandemic of coronavirus disease...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>1109</td>\n",
       "      <td>...</td>\n",
       "      <td>1333</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>429686</td>\n",
       "      <td>18563</td>\n",
       "      <td>10</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>2</td>\n",
       "      <td>declares pandemic coronavirus disease covid</td>\n",
       "      <td>81</td>\n",
       "      <td>[a, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2020-03-09 17:10:35</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>257</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>FDA, FTC crack down on companies selling produ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>519</td>\n",
       "      <td>...</td>\n",
       "      <td>784</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>367215</td>\n",
       "      <td>14138</td>\n",
       "      <td>18</td>\n",
       "      <td>6.058824</td>\n",
       "      <td>5</td>\n",
       "      <td>crack companies selling products claim prevent...</td>\n",
       "      <td>121</td>\n",
       "      <td>[down, on, that, to, or]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2020-03-09 15:12:56</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>205</td>\n",
       "      <td>10</td>\n",
       "      <td>112</td>\n",
       "      <td>Princeton requires lectures and seminars to go...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>519</td>\n",
       "      <td>...</td>\n",
       "      <td>784</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>367215</td>\n",
       "      <td>14138</td>\n",
       "      <td>16</td>\n",
       "      <td>7.266667</td>\n",
       "      <td>3</td>\n",
       "      <td>princeton requires lectures seminars onlineonl...</td>\n",
       "      <td>125</td>\n",
       "      <td>[and, to, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2020-03-06 20:10:03</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>654</td>\n",
       "      <td>18</td>\n",
       "      <td>372</td>\n",
       "      <td>University of Washington switches to virtual c...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>276547</td>\n",
       "      <td>9747</td>\n",
       "      <td>16</td>\n",
       "      <td>7.266667</td>\n",
       "      <td>4</td>\n",
       "      <td>university washington switches virtual classes...</td>\n",
       "      <td>125</td>\n",
       "      <td>[of, to, after, for]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2020-03-05 16:44:03</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>122</td>\n",
       "      <td>21</td>\n",
       "      <td>58</td>\n",
       "      <td>A dog has a \"low-level\" coronavirus infection....</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>17</td>\n",
       "      <td>6.294118</td>\n",
       "      <td>4</td>\n",
       "      <td>lowlevel coronavirus infection dont panic covi...</td>\n",
       "      <td>126</td>\n",
       "      <td>[has, a, about, in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2020-03-05 15:54:01</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>Two more people hospitalized with covid-19 in ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>13</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>3</td>\n",
       "      <td>people hospitalized covid york city live updates</td>\n",
       "      <td>101</td>\n",
       "      <td>[more, with, in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2020-03-05 13:52:03</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>107</td>\n",
       "      <td>South Africa confirms first covid-19 case in t...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>13</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>2</td>\n",
       "      <td>south africa confirms first covid case souther...</td>\n",
       "      <td>98</td>\n",
       "      <td>[in, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2020-03-02 22:17:51</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>65</td>\n",
       "      <td>Covid-19 spreads more easily than SARS and is ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>40</td>\n",
       "      <td>5.923077</td>\n",
       "      <td>15</td>\n",
       "      <td>covid spreads easily sars similar coronaviruse...</td>\n",
       "      <td>271</td>\n",
       "      <td>[more, than, and, is, to, other, that, to, be,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2020-03-02 22:13:28</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "      <td>Public health officials say the novel coronavi...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>43</td>\n",
       "      <td>5.511628</td>\n",
       "      <td>12</td>\n",
       "      <td>public health officials novel coronavirus less...</td>\n",
       "      <td>282</td>\n",
       "      <td>[the, is, than, are, to, how, of, have, been, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2020-03-02 22:04:54</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>628</td>\n",
       "      <td>78</td>\n",
       "      <td>431</td>\n",
       "      <td>What began at a wholesale food market in a cen...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>44</td>\n",
       "      <td>5.255814</td>\n",
       "      <td>19</td>\n",
       "      <td>began wholesale food market central china city...</td>\n",
       "      <td>272</td>\n",
       "      <td>[at, a, in, a, has, now, the, from, to, and, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2020-02-29 21:01:04</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>169</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>Covid-19 patient died at Washington hospital a...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>122069</td>\n",
       "      <td>2934</td>\n",
       "      <td>15</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>covid patient died washington hospital coming ...</td>\n",
       "      <td>120</td>\n",
       "      <td>[at, after, in, with]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2020-02-24 17:26:12</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>Analysis: China’s early warning system didn’t ...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>43850</td>\n",
       "      <td>784</td>\n",
       "      <td>14</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>2</td>\n",
       "      <td>analysis chinas early warning system didnt wor...</td>\n",
       "      <td>107</td>\n",
       "      <td>[on, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2020-02-20 01:37:02</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>How epidemics like COVID-19 end (and how to en...</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>8917</td>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>6.083333</td>\n",
       "      <td>3</td>\n",
       "      <td>epidemics like covid faster</td>\n",
       "      <td>86</td>\n",
       "      <td>[how, to, them]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8514 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at       date  likes_count  replies_count  \\\n",
       "0   2020-05-27 01:57:20 2020-05-26            0              0   \n",
       "1   2020-05-27 01:57:20 2020-05-26            0              0   \n",
       "2   2020-05-26 23:18:19 2020-05-26            0              0   \n",
       "3   2020-05-26 23:00:14 2020-05-26            0              2   \n",
       "4   2020-05-26 22:34:09 2020-05-26            1              0   \n",
       "5   2020-05-26 22:22:16 2020-05-26            0              0   \n",
       "6   2020-05-26 21:57:10 2020-05-26           13              3   \n",
       "7   2020-05-26 21:13:57 2020-05-26            0              0   \n",
       "8   2020-05-26 20:45:24 2020-05-26            0              0   \n",
       "9   2020-05-26 18:15:33 2020-05-26            0              0   \n",
       "10  2020-05-26 16:32:14 2020-05-26            1              0   \n",
       "11  2020-05-26 12:45:53 2020-05-26            0              0   \n",
       "12  2020-05-26 12:41:10 2020-05-26            0              1   \n",
       "13  2020-05-26 12:28:42 2020-05-26            0              0   \n",
       "14  2020-05-26 12:00:19 2020-05-26            2              0   \n",
       "15  2020-05-26 10:54:19 2020-05-26            1              1   \n",
       "16  2020-05-26 10:54:05 2020-05-26            1              0   \n",
       "17  2020-05-26 06:58:42 2020-05-26            0              1   \n",
       "18  2020-05-26 04:06:33 2020-05-26            2              0   \n",
       "19  2020-05-26 23:18:19 2020-05-26            0              0   \n",
       "20  2020-05-26 22:22:16 2020-05-26            0              0   \n",
       "21  2020-05-26 18:15:33 2020-05-26            0              0   \n",
       "22  2020-05-27 03:27:48 2020-05-26            0              0   \n",
       "23  2020-05-27 02:23:48 2020-05-26            1              0   \n",
       "24  2020-05-27 02:01:55 2020-05-26            1              0   \n",
       "25  2020-05-27 01:58:29 2020-05-26            0              1   \n",
       "26  2020-05-27 01:05:41 2020-05-26            0              1   \n",
       "27  2020-05-26 23:44:03 2020-05-26            5              0   \n",
       "28  2020-05-26 23:32:53 2020-05-26            0              0   \n",
       "29  2020-05-26 23:18:19 2020-05-26            0              0   \n",
       "..                  ...        ...          ...            ...   \n",
       "553 2020-03-19 10:28:18 2020-03-19         1431            861   \n",
       "554 2020-03-18 17:21:07 2020-03-18          212             12   \n",
       "555 2020-03-17 03:25:59 2020-03-16          183             31   \n",
       "556 2020-03-16 17:51:04 2020-03-16          525             29   \n",
       "557 2020-03-16 17:44:10 2020-03-16          189             16   \n",
       "558 2020-03-16 15:22:37 2020-03-16          133             14   \n",
       "559 2020-03-16 14:07:56 2020-03-16          213             13   \n",
       "560 2020-03-15 20:11:01 2020-03-15          166             21   \n",
       "561 2020-03-15 14:53:50 2020-03-15           89             25   \n",
       "562 2020-03-13 17:45:06 2020-03-13          294             56   \n",
       "563 2020-03-13 15:09:02 2020-03-13          221             17   \n",
       "564 2020-03-13 15:03:03 2020-03-13         1254            122   \n",
       "565 2020-03-12 23:31:03 2020-03-12          153             13   \n",
       "566 2020-03-12 15:41:45 2020-03-12          384             26   \n",
       "567 2020-03-12 14:49:37 2020-03-12          112             14   \n",
       "568 2020-03-12 11:07:32 2020-03-12          616             83   \n",
       "569 2020-03-12 03:28:04 2020-03-11          195             28   \n",
       "570 2020-03-11 17:55:35 2020-03-11          308             40   \n",
       "571 2020-03-09 17:10:35 2020-03-09          257             29   \n",
       "572 2020-03-09 15:12:56 2020-03-09          205             10   \n",
       "573 2020-03-06 20:10:03 2020-03-06          654             18   \n",
       "574 2020-03-05 16:44:03 2020-03-05          122             21   \n",
       "575 2020-03-05 15:54:01 2020-03-05           93              6   \n",
       "576 2020-03-05 13:52:03 2020-03-05          140             15   \n",
       "577 2020-03-02 22:17:51 2020-03-02           92             12   \n",
       "578 2020-03-02 22:13:28 2020-03-02          100              9   \n",
       "579 2020-03-02 22:04:54 2020-03-02          628             78   \n",
       "580 2020-02-29 21:01:04 2020-02-29          169             21   \n",
       "581 2020-02-24 17:26:12 2020-02-24           75             11   \n",
       "582 2020-02-20 01:37:02 2020-02-19           88              5   \n",
       "\n",
       "     retweets_count                                              tweet  \\\n",
       "0                 0  Two of the United States leading news sources,...   \n",
       "1                 0  Two of the United States leading news sources,...   \n",
       "2                 0  …Unless U’re a physician or a nurse in a surgi...   \n",
       "3                 0  The reality is that Andy Beshear didn't create...   \n",
       "4                 1  In large countries such as the United States, ...   \n",
       "5                 0  Right now, it's a very Good look for a Preside...   \n",
       "6                 6  United States has officially surpassed the gri...   \n",
       "7                 0  The United States has more confirmed COVID-19 ...   \n",
       "8                 0  The average age of deceased and COVID-19 posit...   \n",
       "9                 0  You are some of the stupidest people how do yo...   \n",
       "10                0  How come South Korea and the United States saw...   \n",
       "11                0  Says he who said the United States had \"one\", ...   \n",
       "12                0  I am not making this political. The studies ha...   \n",
       "13                0  while the United States is still puzzling over...   \n",
       "14                1  It is likely that today we will reach 100,000 ...   \n",
       "15                0  And now this guy running the World Health Orga...   \n",
       "16                0  Contribute a rapid review or request one for \"...   \n",
       "17                0  *Japan - Only part of regions of Tokyo and Osa...   \n",
       "18                0  Let's assume the worst here for a moment. COVi...   \n",
       "19                0  …Unless U’re a physician or a nurse in a surgi...   \n",
       "20                0  Right now, it's a very Good look for a Preside...   \n",
       "21                0  You are some of the stupidest people how do yo...   \n",
       "22                0  Well, #COVID__19 or not, people still behaving...   \n",
       "23                1  How can people be so ignorant, rude and nasty ...   \n",
       "24                1  I’m heartbroken about America. So much racism,...   \n",
       "25                0  I don’t understand how people can be biased to...   \n",
       "26                0  [en]#Covid19 #TCGNRG #Map : 5/26/2020\\nDespite...   \n",
       "27                0  Spent some today with @JoeBiden who talked COV...   \n",
       "28                1  Do not desert the #NavajoNation America in #CO...   \n",
       "29                0  …Unless U’re a physician or a nurse in a surgi...   \n",
       "..              ...                                                ...   \n",
       "553             624  \"If I get corona, I get corona\": Miami spring ...   \n",
       "554              79  How the world’s political artists are depictin...   \n",
       "555              64  Opinion: Life in the Time of Covid-19 is total...   \n",
       "556             238  Additionally, scientists still don’t know for ...   \n",
       "557              76  It depends on unknown characteristics of the v...   \n",
       "558              36  One last party, one last dance, then goodbye: ...   \n",
       "559             114  Nursing home with the biggest cluster of covid...   \n",
       "560              45  One last party, one last dance, then goodbye: ...   \n",
       "561              87  Federal vaccine development sites ill-suited t...   \n",
       "562             167  Analysis: The U.S. may already be in a recessi...   \n",
       "563              94  Five states, D.C. order all schools closed in ...   \n",
       "564             883  The number of Covid-19 cases in the D.C. regio...   \n",
       "565              72  Opinion: Quarantining cities isn’t needed. But...   \n",
       "566             196  \"I’m done. I am absolutely done. Test me, don’...   \n",
       "567              71  Confusion helped speed the spread of the coron...   \n",
       "568             402  Coronavirus arrives on Capitol Hill: First Sen...   \n",
       "569              76  Opinion: For useful covid-19 testing, we need ...   \n",
       "570             217  WHO declares a pandemic of coronavirus disease...   \n",
       "571              89  FDA, FTC crack down on companies selling produ...   \n",
       "572             112  Princeton requires lectures and seminars to go...   \n",
       "573             372  University of Washington switches to virtual c...   \n",
       "574              58  A dog has a \"low-level\" coronavirus infection....   \n",
       "575              69  Two more people hospitalized with covid-19 in ...   \n",
       "576             107  South Africa confirms first covid-19 case in t...   \n",
       "577              65  Covid-19 spreads more easily than SARS and is ...   \n",
       "578              55  Public health officials say the novel coronavi...   \n",
       "579             431  What began at a wholesale food market in a cen...   \n",
       "580              98  Covid-19 patient died at Washington hospital a...   \n",
       "581              49  Analysis: China’s early warning system didn’t ...   \n",
       "582              47  How epidemics like COVID-19 end (and how to en...   \n",
       "\n",
       "            username  video       Date  Cases_x  ...  Deaths_y    28 days  \\\n",
       "0    whitewindlandon      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "1    whitewindlandon      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "2            rescon1      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "3           nealhead      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "4             6121el      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "5          roswell32      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "6         gary_lyman      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "7        oldnavy1968      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "8         dablazinjr      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "9    smartpe53402672      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "10    craving_filled      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "11   hsquared_studio      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "12       jimmyfalco2      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "13        ralfstein3      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "14     crawfordstuff      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "15      sallybeatty6      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "16       outbreaksci      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "17   natsumugikezine      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "18    wadetheleopard      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "19           rescon1      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "20         roswell32      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "21   smartpe53402672      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "22   parkerrobertda1      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "23      gregggraison      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "24         dianepaul      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "25         art_muela      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "26        jfdorville      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "27    thesteveholzer      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "28          b1louder      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "29           rescon1      0 2020-05-26  1689162  ...    112714 2020-06-23   \n",
       "..               ...    ...        ...      ...  ...       ...        ...   \n",
       "553   washingtonpost      0 2020-03-19    14157  ...      8432 2020-04-16   \n",
       "554   washingtonpost      0 2020-03-18     8917  ...      6846 2020-04-15   \n",
       "555   washingtonpost      0 2020-03-16     4360  ...      4381 2020-04-13   \n",
       "556   washingtonpost      0 2020-03-16     4360  ...      4381 2020-04-13   \n",
       "557   washingtonpost      0 2020-03-16     4360  ...      4381 2020-04-13   \n",
       "558   washingtonpost      0 2020-03-16     4360  ...      4381 2020-04-13   \n",
       "559   washingtonpost      0 2020-03-16     4360  ...      4381 2020-04-13   \n",
       "560   washingtonpost      0 2020-03-15     2968  ...      3561 2020-04-12   \n",
       "561   washingtonpost      0 2020-03-15     2968  ...      3561 2020-04-12   \n",
       "562   washingtonpost      0 2020-03-13     2157  ...      2300 2020-04-10   \n",
       "563   washingtonpost      0 2020-03-13     2157  ...      2300 2020-04-10   \n",
       "564   washingtonpost      0 2020-03-13     2157  ...      2300 2020-04-10   \n",
       "565   washingtonpost      0 2020-03-12     1561  ...      1746 2020-04-09   \n",
       "566   washingtonpost      0 2020-03-12     1561  ...      1746 2020-04-09   \n",
       "567   washingtonpost      0 2020-03-12     1561  ...      1746 2020-04-09   \n",
       "568   washingtonpost      0 2020-03-12     1561  ...      1746 2020-04-09   \n",
       "569   washingtonpost      0 2020-03-11     1109  ...      1333 2020-04-08   \n",
       "570   washingtonpost      0 2020-03-11     1109  ...      1333 2020-04-08   \n",
       "571   washingtonpost      0 2020-03-09      519  ...       784 2020-04-06   \n",
       "572   washingtonpost      0 2020-03-09      519  ...       784 2020-04-06   \n",
       "573   washingtonpost      0 2020-03-06      222  ...       362 2020-04-03   \n",
       "574   washingtonpost      0 2020-03-05      174  ...       265 2020-04-02   \n",
       "575   washingtonpost      0 2020-03-05      174  ...       265 2020-04-02   \n",
       "576   washingtonpost      0 2020-03-05      174  ...       265 2020-04-02   \n",
       "577   washingtonpost      0 2020-03-02       53  ...        97 2020-03-30   \n",
       "578   washingtonpost      0 2020-03-02       53  ...        97 2020-03-30   \n",
       "579   washingtonpost      0 2020-03-02       53  ...        97 2020-03-30   \n",
       "580   washingtonpost      0 2020-02-29       24  ...        58 2020-03-28   \n",
       "581   washingtonpost      0 2020-02-24       15  ...        22 2020-03-23   \n",
       "582   washingtonpost      0 2020-02-19       13  ...        11 2020-03-18   \n",
       "\n",
       "       Cases  Deaths word_count  avg_word_length  stopwords_count  \\\n",
       "0    2347491  121847         26        10.821429                7   \n",
       "1    2347491  121847         26        10.821429                7   \n",
       "2    2347491  121847         36         6.216216               16   \n",
       "3    2347491  121847         47         4.872340               21   \n",
       "4    2347491  121847         43         5.395349               14   \n",
       "5    2347491  121847         38         4.976190               16   \n",
       "6    2347491  121847         44         5.295455               18   \n",
       "7    2347491  121847         40         5.250000               13   \n",
       "8    2347491  121847         37         4.800000               12   \n",
       "9    2347491  121847         56         4.150943               25   \n",
       "10   2347491  121847         50         4.560000               23   \n",
       "11   2347491  121847         49         5.520000               18   \n",
       "12   2347491  121847         41         5.170732               16   \n",
       "13   2347491  121847         38         4.289474               15   \n",
       "14   2347491  121847         51         4.740000               20   \n",
       "15   2347491  121847         47         4.782609               22   \n",
       "16   2347491  121847         32         8.468750                9   \n",
       "17   2347491  121847         43         4.086957               13   \n",
       "18   2347491  121847         43         4.813953               16   \n",
       "19   2347491  121847         36         6.216216               16   \n",
       "20   2347491  121847         38         4.976190               16   \n",
       "21   2347491  121847         56         4.150943               25   \n",
       "22   2347491  121847         37         5.731707                8   \n",
       "23   2347491  121847         48         4.770833               19   \n",
       "24   2347491  121847         46         5.086957               14   \n",
       "25   2347491  121847         45         4.866667               19   \n",
       "26   2347491  121847         36         5.833333               10   \n",
       "27   2347491  121847         41         6.525000                9   \n",
       "28   2347491  121847         35         7.171429               14   \n",
       "29   2347491  121847         36         6.216216               16   \n",
       "..       ...     ...        ...              ...              ...   \n",
       "553   669272   35442         19         6.000000                2   \n",
       "554   637974   33329         12         7.545455                3   \n",
       "555   581813   28376         12         6.909091                4   \n",
       "556   581813   28376         37         5.500000               13   \n",
       "557   581813   28376         44         5.395349               18   \n",
       "558   581813   28376         18         5.882353                4   \n",
       "559   581813   28376         26         5.520000               10   \n",
       "560   556522   26548         18         5.882353                4   \n",
       "561   556522   26548         11         8.800000                1   \n",
       "562   497943   22731         22         5.333333                9   \n",
       "563   497943   22731         16         6.133333                4   \n",
       "564   497943   22731         16         5.600000                4   \n",
       "565   464442   20638         27         7.000000                4   \n",
       "566   464442   20638         30         4.766667                5   \n",
       "567   464442   20638         37         6.000000               13   \n",
       "568   464442   20638         13         7.833333                2   \n",
       "569   429686   18563         19         5.444444                5   \n",
       "570   429686   18563         10         7.888889                2   \n",
       "571   367215   14138         18         6.058824                5   \n",
       "572   367215   14138         16         7.266667                3   \n",
       "573   276547    9747         16         7.266667                4   \n",
       "574   244610    8432         17         6.294118                4   \n",
       "575   244610    8432         13         6.615385                3   \n",
       "576   244610    8432         13         7.083333                2   \n",
       "577   162707    4381         40         5.923077               15   \n",
       "578   162707    4381         43         5.511628               12   \n",
       "579   162707    4381         44         5.255814               19   \n",
       "580   122069    2934         15         7.500000                4   \n",
       "581    43850     784         14         7.153846                2   \n",
       "582     8917     188         13         6.083333                3   \n",
       "\n",
       "                                            clean_text  char_count  \\\n",
       "0    united states leading news sources time today ...         332   \n",
       "1    united states leading news sources time today ...         332   \n",
       "2    unless physician nurse surgical room business ...         267   \n",
       "3    reality andy beshear didnt create covid didnt ...         277   \n",
       "4    large countries united states russia brazil in...         275   \n",
       "5    right good look president united states leadin...         250   \n",
       "6    united states officially surpassed grim milest...         276   \n",
       "7    united states confirmed covid cases next count...         249   \n",
       "8    average deceased covid positive patients years...         235   \n",
       "9    stupidest people paid stupidity choosing votin...         275   \n",
       "10   come south korea united states first covid cas...         279   \n",
       "11   says said united states fifteen covid cases al...         327   \n",
       "12   making political studies shown effective covid...         252   \n",
       "13   united states still puzzling whether masks wor...         200   \n",
       "14   likely today reach deaths united states covid ...         291   \n",
       "15   running world health organization wants believ...         266   \n",
       "16   contribute rapid review request geographical s...         304   \n",
       "17   japan part regions tokyo osaka accepts delay m...         234   \n",
       "18   lets assume worst moment covid hits time worst...         249   \n",
       "19   unless physician nurse surgical room business ...         267   \n",
       "20   right good look president united states leadin...         250   \n",
       "21   stupidest people paid stupidity choosing votin...         275   \n",
       "22   well covid__ people still behaving badly newyo...         278   \n",
       "23   people ignorant rude nasty knowing fact medica...         276   \n",
       "24   heartbroken america much racism much exploitat...         279   \n",
       "25   dont understand people biased towards russia b...         263   \n",
       "26   encovid tcgnrg despite confirmed covid cases a...         246   \n",
       "27   spent today joebiden talked covid response lac...         301   \n",
       "28   desert navajonation america covid__ times anyt...         286   \n",
       "29   unless physician nurse surgical room business ...         267   \n",
       "..                                                 ...         ...   \n",
       "553  corona corona miami spring breakers covid hasn...         127   \n",
       "554  worlds political artists depicting covid pandemic          95   \n",
       "555      opinion life time covid totally unprecedented          88   \n",
       "556  additionally scientists still dont know sure s...         237   \n",
       "557  depends unknown characteristics virus expresse...         278   \n",
       "558  last party last dance goodbye college students...         118   \n",
       "559  nursing home biggest cluster covid deaths date...         164   \n",
       "560  last party last dance goodbye college students...         118   \n",
       "561  federal vaccine development sites illsuited co...          99   \n",
       "562  analysis already recession could linger even c...         134   \n",
       "563  five states order schools closed effort preven...         108   \n",
       "564     number covid cases region doubling every hours         100   \n",
       "565  opinion quarantining cities isnt needed fast c...         209   \n",
       "566  done absolutely done test dont test dont care ...         175   \n",
       "567  confusion helped speed spread coronavirus near...         269   \n",
       "568  coronavirus arrives capitol hill first senate ...         107   \n",
       "569  opinion useful covid testing need think outsid...         117   \n",
       "570        declares pandemic coronavirus disease covid          81   \n",
       "571  crack companies selling products claim prevent...         121   \n",
       "572  princeton requires lectures seminars onlineonl...         125   \n",
       "573  university washington switches virtual classes...         125   \n",
       "574  lowlevel coronavirus infection dont panic covi...         126   \n",
       "575   people hospitalized covid york city live updates         101   \n",
       "576  south africa confirms first covid case souther...          98   \n",
       "577  covid spreads easily sars similar coronaviruse...         271   \n",
       "578  public health officials novel coronavirus less...         282   \n",
       "579  began wholesale food market central china city...         272   \n",
       "580  covid patient died washington hospital coming ...         120   \n",
       "581  analysis chinas early warning system didnt wor...         107   \n",
       "582                        epidemics like covid faster          86   \n",
       "\n",
       "                                             stopwords  \n",
       "0                   [of, the, and, these, do, not, or]  \n",
       "1                   [of, the, and, these, do, not, or]  \n",
       "2    [a, or, a, in, a, you, have, no, a, in, the, o...  \n",
       "3    [is, that, didn't, he, didn't, it, in, the, an...  \n",
       "4    [such, as, the, and, the, of, the, is, to, or,...  \n",
       "5    [it's, a, very, for, a, of, the, by, is, and, ...  \n",
       "6    [has, the, of, over, from, is, that, this, is,...  \n",
       "7    [has, more, than, the, have, more, than, the, ...  \n",
       "8    [of, and, is, it, is, not, all, the, is, it, o...  \n",
       "9    [are, some, of, the, how, do, you, for, is, be...  \n",
       "10   [and, the, their, the, same, but, they, have, ...  \n",
       "11   [he, who, the, had, and, then, only, which, he...  \n",
       "12   [am, not, this, have, that, is, against, and, ...  \n",
       "13   [while, the, is, over, or, the, of, the, and, ...  \n",
       "14   [is, that, we, will, in, the, from, you, to, a...  \n",
       "15   [now, this, the, all, to, the, not, the, or, t...  \n",
       "16              [a, or, for, of, and, in, the, or, at]  \n",
       "17   [of, of, and, or, can, be, for, a, or, more, t...  \n",
       "18   [the, here, for, a, it's, all, and, the, a, a,...  \n",
       "19   [a, or, a, in, a, you, have, no, a, in, the, o...  \n",
       "20   [it's, a, very, for, a, of, the, by, is, and, ...  \n",
       "21   [are, some, of, the, how, do, you, for, is, be...  \n",
       "22             [or, into, each, at, all, of, and, the]  \n",
       "23   [can, be, so, and, for, a, from, that, in, wit...  \n",
       "24   [about, so, am, about, in, and, who, have, no,...  \n",
       "25   [how, can, be, out, of, or, being, the, of, be...  \n",
       "26     [the, and, the, is, from, the, or, the, of, is]  \n",
       "27       [some, with, who, by, of, and, not, be, more]  \n",
       "28   [not, the, in, or, at, your, and, the, of, on,...  \n",
       "29   [a, or, a, in, a, you, have, no, a, in, the, o...  \n",
       "..                                                 ...  \n",
       "553                                       [them, from]  \n",
       "554                                    [the, are, the]  \n",
       "555                                  [in, the, of, is]  \n",
       "556  [for, if, a, you, if, for, how, is, about, thi...  \n",
       "557  [on, of, the, have, that, the, will, be, by, t...  \n",
       "558                                [then, in, the, of]  \n",
       "559       [with, the, of, to, in, the, it, was, an, a]  \n",
       "560                                [then, in, the, of]  \n",
       "561                                               [to]  \n",
       "562         [be, in, a, and, it, after, the, is, over]  \n",
       "563                                  [all, in, to, of]  \n",
       "564                                  [of, in, the, is]  \n",
       "565                                   [a, to, is, and]  \n",
       "566                           [am, she, had, after, a]  \n",
       "567  [the, of, the, to, a, at, the, of, the, as, th...  \n",
       "568                                         [on, with]  \n",
       "569                            [we, to, the, and, the]  \n",
       "570                                            [a, of]  \n",
       "571                           [down, on, that, to, or]  \n",
       "572                                       [and, to, a]  \n",
       "573                               [of, to, after, for]  \n",
       "574                                [has, a, about, in]  \n",
       "575                                   [more, with, in]  \n",
       "576                                          [in, the]  \n",
       "577  [more, than, and, is, to, other, that, to, be,...  \n",
       "578  [the, is, than, are, to, how, of, have, been, ...  \n",
       "579  [at, a, in, a, has, now, the, from, to, and, f...  \n",
       "580                              [at, after, in, with]  \n",
       "581                                          [on, the]  \n",
       "582                                    [how, to, them]  \n",
       "\n",
       "[8514 rows x 23 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.word_count(Master_Tweet_df,\"tweet\",'word_count')\n",
    "tf.avg_word_length(Master_Tweet_df,'tweet','avg_word_length')\n",
    "tf.stopwords_count(Master_Tweet_df,'tweet','stopwords_count')\n",
    "tf.char_count(Master_Tweet_df,'tweet','char_count')\n",
    "tf.stopwords(Master_Tweet_df,'tweet','stopwords')\n",
    "tf.clean(Master_Tweet_df,'tweet','clean_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and punctuation\n",
    "\n",
    "clean_tweet = Master_Tweet_df['clean_text']\n",
    "#Tweet Tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "#corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "#corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in clean_tweet:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis - utilize NTLK because it is better\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import PatternAnalyzer, NaiveBayesAnalyzer\n",
    "#from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "tweets = Master_Tweet_df['clean_text']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "    #Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "    #sentiment = Classifier.predict_proba(tweet)\n",
    "    blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "    rating = blob.sentiment.polarity\n",
    "    Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_df['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fit12P9FHnHD",
    "outputId": "1c50c4c5-7eef-4a42-9e67-35b71e045df6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poll</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sample</th>\n",
       "      <th>MoE</th>\n",
       "      <th>Biden (D)</th>\n",
       "      <th>Trump (R)</th>\n",
       "      <th>Spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBD/TIPPIBD/TIPP</td>\n",
       "      <td>1/3/20</td>\n",
       "      <td>1/11/20</td>\n",
       "      <td>1/7/20</td>\n",
       "      <td>846 RV</td>\n",
       "      <td>3.3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNCNN</td>\n",
       "      <td>1/16/20</td>\n",
       "      <td>1/19/20</td>\n",
       "      <td>1/17/20</td>\n",
       "      <td>1051 RV</td>\n",
       "      <td>3.6</td>\n",
       "      <td>53.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Biden +9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOX NewsFOX News</td>\n",
       "      <td>1/19/20</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1/20/20</td>\n",
       "      <td>1005 RV</td>\n",
       "      <td>3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Biden +9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC News/Wash PostABC/WP</td>\n",
       "      <td>1/20/20</td>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1/21/20</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LA Times/USCLA Times</td>\n",
       "      <td>1/15/20</td>\n",
       "      <td>1/28/20</td>\n",
       "      <td>1/21/20</td>\n",
       "      <td>4869 RV</td>\n",
       "      <td>2</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Biden +9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Poll Start Date End Date     Date   Sample  MoE  \\\n",
       "0          IBD/TIPPIBD/TIPP     1/3/20  1/11/20   1/7/20   846 RV  3.3   \n",
       "1                    CNNCNN    1/16/20  1/19/20  1/17/20  1051 RV  3.6   \n",
       "2          FOX NewsFOX News    1/19/20  1/22/20  1/20/20  1005 RV    3   \n",
       "3  ABC News/Wash PostABC/WP    1/20/20  1/23/20  1/21/20   880 RV    4   \n",
       "4      LA Times/USCLA Times    1/15/20  1/28/20  1/21/20  4869 RV    2   \n",
       "\n",
       "   Biden (D)  Trump (R)    Spread  \n",
       "0       48.0       46.0  Biden +2  \n",
       "1       53.0       44.0  Biden +9  \n",
       "2       50.0       41.0  Biden +9  \n",
       "3       50.0       46.0  Biden +4  \n",
       "4       49.0       40.0  Biden +9  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving as CSV for later uploads to different notebooks\n",
    "Master_Tweet_df.to_csv('data/Master_Tweet_df.csv')\n",
    "poll_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "Master_Tweet_df['Date'] = lambda x: M/D/Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "incompatible merge keys [0] datetime64[ns] and object, must be the same type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-eb884545a00b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoll_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpoll_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_asof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'10d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_exact_matches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    459\u001b[0m                     \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asof'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0mallow_exact_matches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_exact_matches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                     direction=direction)\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, axis, suffixes, copy, fill_method, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                                \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                                \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m                                fill_method=fill_method)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, axis, suffixes, copy, fill_method, how)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                                  \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                                  \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m                                  \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# factorize sorts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m                                  )\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    527\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    528\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1404\u001b[0m                                  \u001b[0;34m\"{rkdtype}, must be the same type\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m                                  .format(i=i, lkdtype=lk.dtype,\n\u001b[0;32m-> 1406\u001b[0;31m                                          rkdtype=rk.dtype))\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;31m# validate tolerance; must be a Timedelta if we have a DTI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMergeError\u001b[0m: incompatible merge keys [0] datetime64[ns] and object, must be the same type"
     ]
    }
   ],
   "source": [
    "#Merging with Poll Data\n",
    "\n",
    "poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "pd.to_datetime(poll_data['Date']) #converting to datetime object for merge purposes\n",
    "pd.to_datetime(Master_Tweet_df['Date']) #converting to datetime object for merge purposes\n",
    "\n",
    "left = Master_Tweet_df\n",
    "right = poll_data\n",
    "\n",
    "poll_df = pd.merge_asof(left,right,on='Date',tolerance=pd.Timedelta('10d'),allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
