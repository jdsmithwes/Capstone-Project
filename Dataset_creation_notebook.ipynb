{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import textfeatures as tf\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Creating Dataframe with Tweet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "Tweet data gathered in the notebook for Tweet data queries are put into dataframes from their original JSON format. This will assist with adding COVID and Poll Data later for full analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('tweets/Covid_tweets5.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('tweets/Trump_Covid_tweets5.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('tweets/Cuomo_Covid_tweets5.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('tweets/Nytimes_Covid_tweets5.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('tweets/Washpost_tweets5.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['date'] = pd.to_datetime(All_Covid_tweets['date'], format='%Y%m%d')\n",
    "Trump_Covid_tweets['date'] = pd.to_datetime(Trump_Covid_tweets['date'], format='%Y%m%d')\n",
    "Cuomo_Covid_tweets['date'] = pd.to_datetime(Cuomo_Covid_tweets['date'], format='%Y%m%d')\n",
    "Baseline_tweets['date'] = pd.to_datetime(Baseline_tweets['date'], format='%Y%m%d')\n",
    "\n",
    "#Saving DF for use in other notebooks\n",
    "pickle.dump(All_Covid_tweets,open('pickles/All_Covid_tweets.pickle','wb'))\n",
    "pickle.dump(Trump_Covid_tweets,open('pickles/Trump_Covid_tweets.pickle','wb'))\n",
    "pickle.dump(Cuomo_Covid_tweets,open('pickles/Cuomo_Covid_tweets.pickle','wb'))\n",
    "pickle.dump(Baseline_tweets,open('pickles/Baseline_tweets.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets in the dataset is: 27437\n"
     ]
    }
   ],
   "source": [
    "#Combining all Tweet DFs into one\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets,Trump_Covid_tweets,\n",
    "                             Cuomo_Covid_tweets,Baseline_tweets],axis=0)\n",
    "\n",
    "A = number_of_tweets = len(Master_Tweet_df)\n",
    "print('The number of tweets in the dataset is:',number_of_tweets)\n",
    "\n",
    "#Saving DF for use in other notebooks\n",
    "pickle.dump(Master_Tweet_df,open('pickles/Master_Tweet_df','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "COVID tracking data was pulled from [this repository](https://github.com/COVID19Tracking/covid-tracking-data/blob/master/data/us_daily.csv). I choose this resource because it is monitored daily and is maintained by a reputable organization - The Atlantic. While this data includes details around ICU populations and number of people on ventilators, I will be focused primarily on the number of positive cases and deathes in the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "covid_data = pd.read_csv('https://raw.githubusercontent.com/COVID19Tracking/covid-tracking-data/master/data/us_daily.csv')\n",
    "\n",
    "# formatting the date column to datetime\n",
    "covid_data['date'] = pd.to_datetime(covid_data['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>6518306</td>\n",
       "      <td>186548.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>6488453</td>\n",
       "      <td>186166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>6454000</td>\n",
       "      <td>185777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>6411913</td>\n",
       "      <td>184967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-10</td>\n",
       "      <td>6366986</td>\n",
       "      <td>183949.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  positive     death\n",
       "0 2020-09-14   6518306  186548.0\n",
       "1 2020-09-13   6488453  186166.0\n",
       "2 2020-09-12   6454000  185777.0\n",
       "3 2020-09-11   6411913  184967.0\n",
       "4 2020-09-10   6366986  183949.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#three columns for the Covid dataframe\n",
    "covid_data = covid_data[['date','positive','death']]\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228397478954795009</td>\n",
       "      <td>1228397478954795008</td>\n",
       "      <td>2020-02-14 19:15:56</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>14:15:56</td>\n",
       "      <td>EDT</td>\n",
       "      <td>143132365</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>NYC EMS Watch</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '143132365', 'username': 'NYCEMSw...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1228397478954795009</td>\n",
       "      <td>1228397478954795008</td>\n",
       "      <td>2020-02-14 19:15:56</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>14:15:56</td>\n",
       "      <td>EDT</td>\n",
       "      <td>143132365</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>NYC EMS Watch</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '143132365', 'username': 'NYCEMSw...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1228397478954795009</td>\n",
       "      <td>1228397478954795008</td>\n",
       "      <td>2020-02-14 19:15:56</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>14:15:56</td>\n",
       "      <td>EDT</td>\n",
       "      <td>143132365</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>NYC EMS Watch</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '143132365', 'username': 'NYCEMSw...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1228468353486008320</td>\n",
       "      <td>1228468353486008320</td>\n",
       "      <td>2020-02-14 23:57:33</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>18:57:33</td>\n",
       "      <td>EDT</td>\n",
       "      <td>25073877</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '25073877', 'username': 'realDona...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1228463577335554049</td>\n",
       "      <td>1228463577335554048</td>\n",
       "      <td>2020-02-14 23:38:35</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>18:38:35</td>\n",
       "      <td>EDT</td>\n",
       "      <td>25073877</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '25073877', 'username': 'realDona...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1228397478954795009  1228397478954795008 2020-02-14 19:15:56 2020-02-14   \n",
       "1  1228397478954795009  1228397478954795008 2020-02-14 19:15:56 2020-02-14   \n",
       "2  1228397478954795009  1228397478954795008 2020-02-14 19:15:56 2020-02-14   \n",
       "3  1228468353486008320  1228468353486008320 2020-02-14 23:57:33 2020-02-14   \n",
       "4  1228463577335554049  1228463577335554048 2020-02-14 23:38:35 2020-02-14   \n",
       "\n",
       "       time timezone    user_id         username             name place  ...  \\\n",
       "0  14:15:56      EDT  143132365      nycemswatch    NYC EMS Watch        ...   \n",
       "1  14:15:56      EDT  143132365      nycemswatch    NYC EMS Watch        ...   \n",
       "2  14:15:56      EDT  143132365      nycemswatch    NYC EMS Watch        ...   \n",
       "3  18:57:33      EDT   25073877  realdonaldtrump  Donald J. Trump        ...   \n",
       "4  18:38:35      EDT   25073877  realdonaldtrump  Donald J. Trump        ...   \n",
       "\n",
       "  user_rt_id user_rt retweet_id  \\\n",
       "0                                 \n",
       "1                                 \n",
       "2                                 \n",
       "3                                 \n",
       "4                                 \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0  [{'user_id': '143132365', 'username': 'NYCEMSw...                            \n",
       "1  [{'user_id': '143132365', 'username': 'NYCEMSw...                            \n",
       "2  [{'user_id': '143132365', 'username': 'NYCEMSw...                            \n",
       "3  [{'user_id': '25073877', 'username': 'realDona...                            \n",
       "4  [{'user_id': '25073877', 'username': 'realDona...                            \n",
       "\n",
       "   trans_src trans_dest positive death  \n",
       "0                              0   0.0  \n",
       "1                              0   0.0  \n",
       "2                              0   0.0  \n",
       "3                              0   0.0  \n",
       "4                              0   0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the two datasets for all Covid data in one place\n",
    "Master_Tweet_dataset = pd.merge(Master_Tweet_df,covid_data,on='date')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns were deleted from the dataframe because they were mainly metadata that wouldn't be used in the various models that will be utilized later in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['cashtags', 'conversation_id', 'hashtags',\n",
    "       'id','link', 'mentions', 'name', 'near', 'photos',\n",
    "       'place', 'quote_url','reply_to', 'retweet',\n",
    "       'retweet_date', 'retweet_id','source', 'time',\n",
    "       'timezone', 'trans_dest', 'trans_src', 'translate','urls',\n",
    "       'user_id', 'user_rt', 'user_rt_id',],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct most of the preprocessing of the tweet data, I utilized the Textfeatures library. This library assists with not only lowercase and remove punctuation and items such as hashtags, but provide useful data such as word count, average word length, stopwords count, and the character count of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'tweet', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'video', 'geo', 'positive', 'death'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install textfeatures\n",
    "#Getting ride of duplicative column\n",
    "Master_Tweet_dataset=Master_Tweet_dataset.drop('created_at',axis=1)\n",
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using textfeatures library text preprocessing\n",
    "tf.word_count(Master_Tweet_dataset,\"tweet\",'word_count')\n",
    "tf.avg_word_length(Master_Tweet_dataset,'tweet','avg_word_length')\n",
    "tf.stopwords_count(Master_Tweet_dataset,'tweet','stopwords_count')\n",
    "tf.char_count(Master_Tweet_dataset,'tweet','char_count')\n",
    "tf.stopwords(Master_Tweet_dataset,'tweet','stopwords')\n",
    "tf.clean(Master_Tweet_dataset,'tweet','clean_text')\n",
    "Master_Tweet_dataset.head()\n",
    "\n",
    "#Saving DF for use in other notebooks\n",
    "pickle.dump(Master_Tweet_dataset,open('pickles/Master_Tweet_datasetfull.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making sure all of the text data is uniform and all special characters have been removed, I utiilized the TweetTokenizer library to tokenize every tweet to form the larger corpus. Tokenizing the tweets is an important step to assist the computer make sense of the text that was gathered through the tweets. Tokenization will allow for us to ascertain the topics being discussed in the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the Corpus\n",
    "\n",
    "clean_tweet = Master_Tweet_dataset['clean_text']\n",
    "#Tweet Tokenizer \n",
    "\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "#corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "#corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in clean_tweet:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tok list or later use\n",
    "\n",
    "with open('tok_corp_8_8.pickle','wb') as f:\n",
    "    pickle.dump(tok_corp,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Sentiment Analysis, the TextBlob library was utilized. The output of this analyis will give each tweet a score between -1 and 1. Scores closer to -1 can be classified as negative and scores around zero can be thought of as being neutral in sentiment. Finally, items with a score closer to 1 can be defined as having a positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis - adding Sentiment rating to each tweet\n",
    "\n",
    "#from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "tweets = Master_Tweet_dataset['clean_text']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = list(analyzer.polarity_scores(tweet).values())\n",
    "    sentiment = vs[3]\n",
    "    Sentiment.append(sentiment)\n",
    "    \n",
    "    \n",
    "    #Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "    #sentiment = Classifier.predict_proba(tweet)\n",
    "    #blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "    #rating = blob.sentiment.polarity\n",
    "    #Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_dataset['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Poll Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polling data was collected from [RealClear Politics](https://www.realclearpolitics.com/epolls/2020/president/us/general_election_trump_vs_biden-6247.html). This source was chosen because they maintain a collection of polls for the US Presidential election and they do a good job of showing the overall momentum a candidate may have at a given time. To assist with the merge, I manipulated the date column in excel so that the merge would be successful as attempts to make the changes with Pandas were unsuccessful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Poll data\n",
    "poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "poll_data = poll_data.dropna()\n",
    "\n",
    "#Converting Date columns to integer so merge will work\n",
    "Master_Tweet_dataset['date'] = pd.to_datetime(Master_Tweet_dataset['date'])\n",
    "Master_Tweet_dataset['date'] = Master_Tweet_dataset['date'].astype(int)\n",
    "poll_data['date'] = pd.to_datetime(poll_data['date'])\n",
    "poll_data['date'] = poll_data['date'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging with Poll Data\n",
    "\n",
    "#poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "#pd.to_datetime(poll_data['Date']) #converting to datetime object for merge purposes\n",
    "#pd.to_datetime(Master_Tweet_df['Date']) #converting to datetime object for merge purposes\n",
    "\n",
    "left = Master_Tweet_dataset.sort_values(by='date')\n",
    "right = poll_data.sort_values(by='date')\n",
    "\n",
    "Master_Tweet_dataset = pd.merge_asof(left,right,on='date',allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, determining the public's perception of the Covid response in America was critical. To learn this based on tweets, Latent Dirichlet Allocation (LDA) was employed. LDA is an unsupervised machine-learning model that takes documents as input and finds topics as output. Further,as detailed on [Towards Data Science](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0), LDA is a generative probabilistic model that assumes each topic is a mixture over an underlying set of words, and each document is a mixture of over a set of topic probabilities.\n",
    "\n",
    "To generate these topics, count vectorization was used to convert the corpus of documents into a matrix of token counts which was later fed into the LDA model so that topics could be generated. As you will see, the ten topics will have the most common words for that topic and the associated percentage that word appears in that topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiging topics to each tweet  -code inspired by stackabuse\n",
    "\n",
    "\n",
    "#Vectorizing docs\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(clean_tweet)\n",
    "\n",
    "#fitting LDA Model\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA_model_8_22 = LDA.fit(doc_term_matrix)\n",
    "\n",
    "#saving model\n",
    "pickle.dump(LDA_model_8_22, open( 'pickles/LDA_modelsklearn.pickle', 'wb') )\n",
    "\n",
    "#transforming to get topic numbers\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape\n",
    "\n",
    "#creating column of Topics\n",
    "Master_Tweet_dataset['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['people', 'trump', 'countries', 'public', 'health', 'coronavirus', 'american', 'covid', 'response', 'pandemic']\n",
      "Top 10 words for topic #1:\n",
      "['trumps', 'americans', 'president', 'deaths', 'pandemic', 'people', 'trump', 'covid', 'american', 'response']\n",
      "Top 10 words for topic #2:\n",
      "['especially', 'gave', 'family', 'provide', 'america', 'relief', 'service', 'american', 'covid', 'response']\n",
      "Top 10 words for topic #3:\n",
      "['support', 'trumpdeathclock', 'delayed', 'cost', 'coronavirus', 'trumps', 'lives', 'american', 'response', 'covid']\n",
      "Top 10 words for topic #4:\n",
      "['national', 'support', 'health', 'pandemic', 'thank', 'people', 'great', 'covid', 'american', 'response']\n"
     ]
    }
   ],
   "source": [
    "# top words for each topic\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to create Target Column\n",
    "category_dict = {}\n",
    "for key in [0,2,4]:\n",
    "    category_dict[key] = 'Health Crisis Response'\n",
    "for key in [1,3]:\n",
    "    category_dict[key] = 'Political Blame Response'\n",
    "    \n",
    "#Creation of Target Column\n",
    "Master_Tweet_dataset['Target'] = Master_Tweet_dataset['Topic'].map(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>...</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Sample</th>\n",
       "      <th>MoE</th>\n",
       "      <th>Biden (D)</th>\n",
       "      <th>Trump (R)</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Target</th>\n",
       "      <th>spread_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Making great progress in @Davos. Tremendous nu...</td>\n",
       "      <td>9441</td>\n",
       "      <td>17423</td>\n",
       "      <td>87558</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Sorry, if you come you will be immediately sen...</td>\n",
       "      <td>8623</td>\n",
       "      <td>24341</td>\n",
       "      <td>98127</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>See you on Friday...Big Crowd! https://twitter...</td>\n",
       "      <td>7015</td>\n",
       "      <td>24051</td>\n",
       "      <td>96738</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>True! https://twitter.com/RandPaul/status/1220...</td>\n",
       "      <td>3433</td>\n",
       "      <td>11897</td>\n",
       "      <td>50187</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>“NO PRESSURE”</td>\n",
       "      <td>18037</td>\n",
       "      <td>19710</td>\n",
       "      <td>121464</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Will be Great! https://twitter.com/WhiteHouse/...</td>\n",
       "      <td>2224</td>\n",
       "      <td>8020</td>\n",
       "      <td>39211</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Great working with you Maria! https://twitter....</td>\n",
       "      <td>1770</td>\n",
       "      <td>7501</td>\n",
       "      <td>36189</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>One of the many great things about our just si...</td>\n",
       "      <td>8437</td>\n",
       "      <td>19279</td>\n",
       "      <td>101883</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Will be interviewed at 5:00 A.M. Eastern by @J...</td>\n",
       "      <td>2112</td>\n",
       "      <td>4762</td>\n",
       "      <td>23341</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>“Not the Senate’s job to mop up the mess made ...</td>\n",
       "      <td>10538</td>\n",
       "      <td>21646</td>\n",
       "      <td>89041</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>0</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>THANK YOU @WEF! pic.twitter.com/rQWBqJy7za</td>\n",
       "      <td>8149</td>\n",
       "      <td>19293</td>\n",
       "      <td>69572</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>They are taking the nomination away from Berni...</td>\n",
       "      <td>12311</td>\n",
       "      <td>21501</td>\n",
       "      <td>133000</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Steyer is a major loser. Just doesn’t get it. ...</td>\n",
       "      <td>2918</td>\n",
       "      <td>6720</td>\n",
       "      <td>31555</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Big story. Hope Fake News covers it! https://t...</td>\n",
       "      <td>2282</td>\n",
       "      <td>8774</td>\n",
       "      <td>31235</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Their case was so “overwhelming” in the House ...</td>\n",
       "      <td>4746</td>\n",
       "      <td>10260</td>\n",
       "      <td>39881</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>ENJOY! https://twitter.com/MariaBartiromo/stat...</td>\n",
       "      <td>2613</td>\n",
       "      <td>6162</td>\n",
       "      <td>26940</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Heading back to Washington from @Davos , Switz...</td>\n",
       "      <td>6247</td>\n",
       "      <td>11695</td>\n",
       "      <td>60857</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Close race in Kansas! pic.twitter.com/m2ExF9vHKU</td>\n",
       "      <td>995</td>\n",
       "      <td>5456</td>\n",
       "      <td>21084</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>1128 RV</td>\n",
       "      <td>2.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Tie</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Interesting poll in Texas-13! #TX13 pic.twitte...</td>\n",
       "      <td>1273</td>\n",
       "      <td>5789</td>\n",
       "      <td>22281</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>1128 RV</td>\n",
       "      <td>2.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Tie</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1579737600000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>I LOVE ALABAMA! pic.twitter.com/ZDlBDehhvN</td>\n",
       "      <td>3181</td>\n",
       "      <td>8349</td>\n",
       "      <td>35860</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>1128 RV</td>\n",
       "      <td>2.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Tie</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date         username  \\\n",
       "0   1579651200000000000  realdonaldtrump   \n",
       "1   1579651200000000000  realdonaldtrump   \n",
       "2   1579651200000000000  realdonaldtrump   \n",
       "3   1579651200000000000  realdonaldtrump   \n",
       "4   1579651200000000000  realdonaldtrump   \n",
       "5   1579651200000000000  realdonaldtrump   \n",
       "6   1579651200000000000  realdonaldtrump   \n",
       "7   1579651200000000000  realdonaldtrump   \n",
       "8   1579651200000000000  realdonaldtrump   \n",
       "9   1579651200000000000  realdonaldtrump   \n",
       "10  1579651200000000000  realdonaldtrump   \n",
       "11  1579651200000000000  realdonaldtrump   \n",
       "12  1579651200000000000  realdonaldtrump   \n",
       "13  1579651200000000000  realdonaldtrump   \n",
       "14  1579651200000000000  realdonaldtrump   \n",
       "15  1579651200000000000  realdonaldtrump   \n",
       "16  1579651200000000000  realdonaldtrump   \n",
       "17  1579737600000000000  realdonaldtrump   \n",
       "18  1579737600000000000  realdonaldtrump   \n",
       "19  1579737600000000000  realdonaldtrump   \n",
       "\n",
       "                                                tweet  replies_count  \\\n",
       "0   Making great progress in @Davos. Tremendous nu...           9441   \n",
       "1   Sorry, if you come you will be immediately sen...           8623   \n",
       "2   See you on Friday...Big Crowd! https://twitter...           7015   \n",
       "3   True! https://twitter.com/RandPaul/status/1220...           3433   \n",
       "4                                       “NO PRESSURE”          18037   \n",
       "5   Will be Great! https://twitter.com/WhiteHouse/...           2224   \n",
       "6   Great working with you Maria! https://twitter....           1770   \n",
       "7   One of the many great things about our just si...           8437   \n",
       "8   Will be interviewed at 5:00 A.M. Eastern by @J...           2112   \n",
       "9   “Not the Senate’s job to mop up the mess made ...          10538   \n",
       "10         THANK YOU @WEF! pic.twitter.com/rQWBqJy7za           8149   \n",
       "11  They are taking the nomination away from Berni...          12311   \n",
       "12  Steyer is a major loser. Just doesn’t get it. ...           2918   \n",
       "13  Big story. Hope Fake News covers it! https://t...           2282   \n",
       "14  Their case was so “overwhelming” in the House ...           4746   \n",
       "15  ENJOY! https://twitter.com/MariaBartiromo/stat...           2613   \n",
       "16  Heading back to Washington from @Davos , Switz...           6247   \n",
       "17   Close race in Kansas! pic.twitter.com/m2ExF9vHKU            995   \n",
       "18  Interesting poll in Texas-13! #TX13 pic.twitte...           1273   \n",
       "19         I LOVE ALABAMA! pic.twitter.com/ZDlBDehhvN           3181   \n",
       "\n",
       "    retweets_count  likes_count  video geo  positive  death  ...  Start Date  \\\n",
       "0            17423        87558      0             0    NaN  ...  2020-01-20   \n",
       "1            24341        98127      0             0    NaN  ...  2020-01-20   \n",
       "2            24051        96738      0             0    NaN  ...  2020-01-20   \n",
       "3            11897        50187      0             0    NaN  ...  2020-01-20   \n",
       "4            19710       121464      0             0    NaN  ...  2020-01-20   \n",
       "5             8020        39211      0             0    NaN  ...  2020-01-20   \n",
       "6             7501        36189      0             0    NaN  ...  2020-01-20   \n",
       "7            19279       101883      0             0    NaN  ...  2020-01-20   \n",
       "8             4762        23341      0             0    NaN  ...  2020-01-20   \n",
       "9            21646        89041      0             0    NaN  ...  2020-01-20   \n",
       "10           19293        69572      1             0    NaN  ...  2020-01-20   \n",
       "11           21501       133000      0             0    NaN  ...  2020-01-20   \n",
       "12            6720        31555      0             0    NaN  ...  2020-01-20   \n",
       "13            8774        31235      0             0    NaN  ...  2020-01-20   \n",
       "14           10260        39881      0             0    NaN  ...  2020-01-20   \n",
       "15            6162        26940      0             0    NaN  ...  2020-01-20   \n",
       "16           11695        60857      0             0    NaN  ...  2020-01-20   \n",
       "17            5456        21084      0             0    NaN  ...  2020-01-21   \n",
       "18            5789        22281      0             0    NaN  ...  2020-01-21   \n",
       "19            8349        35860      0             0    NaN  ...  2020-01-21   \n",
       "\n",
       "      End Date   Sample  MoE Biden (D) Trump (R)    Spread Topic  \\\n",
       "0   2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "1   2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "2   2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "3   2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "4   2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "5   2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "6   2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "7   2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "8   2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "9   2020-01-23   880 RV    4      50.0      46.0  Biden +4     0   \n",
       "10  2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "11  2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "12  2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "13  2020-01-23   880 RV    4      50.0      46.0  Biden +4     4   \n",
       "14  2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "15  2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "16  2020-01-23   880 RV    4      50.0      46.0  Biden +4     1   \n",
       "17  2020-01-23  1128 RV  2.8      50.0      50.0       Tie     1   \n",
       "18  2020-01-23  1128 RV  2.8      50.0      50.0       Tie     4   \n",
       "19  2020-01-23  1128 RV  2.8      50.0      50.0       Tie     1   \n",
       "\n",
       "                      Target spread_number  \n",
       "0   Political Blame Response           4.0  \n",
       "1   Political Blame Response           4.0  \n",
       "2   Political Blame Response           4.0  \n",
       "3     Health Crisis Response           4.0  \n",
       "4   Political Blame Response           4.0  \n",
       "5     Health Crisis Response           4.0  \n",
       "6   Political Blame Response           4.0  \n",
       "7     Health Crisis Response           4.0  \n",
       "8     Health Crisis Response           4.0  \n",
       "9     Health Crisis Response           4.0  \n",
       "10    Health Crisis Response           4.0  \n",
       "11    Health Crisis Response           4.0  \n",
       "12    Health Crisis Response           4.0  \n",
       "13    Health Crisis Response           4.0  \n",
       "14  Political Blame Response           4.0  \n",
       "15  Political Blame Response           4.0  \n",
       "16  Political Blame Response           4.0  \n",
       "17  Political Blame Response           0.0  \n",
       "18    Health Crisis Response           0.0  \n",
       "19  Political Blame Response           0.0  \n",
       "\n",
       "[20 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset['spread_number'] = Master_Tweet_dataset['Biden (D)'] - Master_Tweet_dataset['Trump (R)']\n",
    "Master_Tweet_dataset.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving DF for use in other notebooks\n",
    "pickle.dump(Master_Tweet_dataset,open('pickles/Master_Tweet_datasetfull.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ready DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that the data fed to our models is uniform, this last step just dropped columns that were either superflous or contained text that our number-driven models cannot make any use of. For portability, the final dataframe was pickled so that it could be recalled in the Models notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns not applicable for model\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['date','username','video','geo','clean_text','Start Date', \n",
    "                                                  'End Date','tweet','Sample','replies_count', 'retweets_count',\n",
    "                                                  'MoE','stopwords','Poll','MoE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes_count</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Biden (D)</th>\n",
       "      <th>Trump (R)</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Target</th>\n",
       "      <th>spread_number</th>\n",
       "      <th>Target_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87558</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>7</td>\n",
       "      <td>141</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96738</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>4</td>\n",
       "      <td>Health Crisis Response</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121464</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Biden +4</td>\n",
       "      <td>1</td>\n",
       "      <td>Political Blame Response</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likes_count  positive  death  word_count  avg_word_length  stopwords_count  \\\n",
       "0        87558         0    0.0          22         5.454545                7   \n",
       "1        98127         0    0.0          11         8.166667                5   \n",
       "2        96738         0    0.0           6        12.571429                2   \n",
       "3        50187         0    0.0           2        20.333333                0   \n",
       "4       121464         0    0.0           2         6.000000                0   \n",
       "\n",
       "   char_count  Sentiment  Biden (D)  Trump (R)    Spread  Topic  \\\n",
       "0         141     0.7845       50.0       46.0  Biden +4      1   \n",
       "1         109    -0.0772       50.0       46.0  Biden +4      1   \n",
       "2          94     0.0000       50.0       46.0  Biden +4      1   \n",
       "3          63     0.4215       50.0       46.0  Biden +4      4   \n",
       "4          13    -0.2960       50.0       46.0  Biden +4      1   \n",
       "\n",
       "                     Target  spread_number  Target_number  \n",
       "0  Political Blame Response            4.0              1  \n",
       "1  Political Blame Response            4.0              1  \n",
       "2  Political Blame Response            4.0              1  \n",
       "3    Health Crisis Response            4.0              0  \n",
       "4  Political Blame Response            4.0              1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deaths didn't start immediately...filling NAN with 0s for modeling purposes\n",
    "Master_Tweet_dataset['death'] = Master_Tweet_dataset['death'].fillna(0)\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving DF for use in other notebooks\n",
    "pickle.dump(Master_Tweet_dataset,open('pickles/Master_Tweet_dataset.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
