{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Obtaining Tweet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "For the notebooks that contain the queries for the tweets gathered on TWINT, please refer to the Covid Data Queries notebook in the repo. The JSON files for these queries were used to create DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('tweets/Covid_tweets4.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('tweets/Trump_Covid_tweets4.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('tweets/Cuomo_Covid_tweets4.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('tweets/Nytimes_Covid_tweets4.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('tweets/Washpost_tweets4.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['date'] = pd.to_datetime(All_Covid_tweets['date'], format='%Y%m%d')\n",
    "Trump_Covid_tweets['date'] = pd.to_datetime(Trump_Covid_tweets['date'], format='%Y%m%d')\n",
    "Cuomo_Covid_tweets['date'] = pd.to_datetime(Cuomo_Covid_tweets['date'], format='%Y%m%d')\n",
    "Baseline_tweets['date'] = pd.to_datetime(Baseline_tweets['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets in the dataset is: 17659\n"
     ]
    }
   ],
   "source": [
    "#Combining all Tweet DFs into one\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets,Trump_Covid_tweets,\n",
    "                             Cuomo_Covid_tweets,Baseline_tweets],axis=0)\n",
    "\n",
    "number_of_tweets = len(Master_Tweet_df)\n",
    "print('The number of tweets in the dataset is:',number_of_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "Data for Covid Cases and Deaths was collected from The COVID Tracking Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "covid_data = pd.read_excel('covid data/data.8.08.2020.xls')\n",
    "\n",
    "# formatting the date column to datetime\n",
    "covid_data['date'] = pd.to_datetime(covid_data['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>4913663</td>\n",
       "      <td>152816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-05</td>\n",
       "      <td>4797959</td>\n",
       "      <td>150232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>4745694</td>\n",
       "      <td>148807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-03</td>\n",
       "      <td>4694126</td>\n",
       "      <td>147631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  positive     death\n",
       "0 2020-08-07   4913663  152816.0\n",
       "1 2020-08-06   4852143  151483.0\n",
       "2 2020-08-05   4797959  150232.0\n",
       "3 2020-08-04   4745694  148807.0\n",
       "4 2020-08-03   4694126  147631.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data = covid_data[['date','positive','death']]\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>2020-08-06 23:56:20</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:56:20</td>\n",
       "      <td>EDT</td>\n",
       "      <td>228022886</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>Angelo Wijdh</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '228022886', 'username': 'ACAI_W'}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291522763233071105</td>\n",
       "      <td>1291451746724741120</td>\n",
       "      <td>2020-08-06 23:53:16</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:53:16</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1134860643528577026</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Britta Swenson</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1134860643528577026', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>2020-08-06 23:45:35</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:45:35</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1080245442732974081</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Sally Wong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1080245442732974081', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291520253357326338</td>\n",
       "      <td>1291520253357326336</td>\n",
       "      <td>2020-08-06 23:43:18</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:43:18</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2431027482</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>DENSMORE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2431027482', 'username': 'ultima...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291519814339629059</td>\n",
       "      <td>1291518619197874176</td>\n",
       "      <td>2020-08-06 23:41:33</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:41:33</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2974733727</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>Rob Chappell</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2974733727', 'username': 'taffyg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1291523532363636736  1291523532363636736 2020-08-06 23:56:20 2020-08-06   \n",
       "1  1291522763233071105  1291451746724741120 2020-08-06 23:53:16 2020-08-06   \n",
       "2  1291520828148871168  1291520828148871168 2020-08-06 23:45:35 2020-08-06   \n",
       "3  1291520253357326338  1291520253357326336 2020-08-06 23:43:18 2020-08-06   \n",
       "4  1291519814339629059  1291518619197874176 2020-08-06 23:41:33 2020-08-06   \n",
       "\n",
       "       time timezone              user_id         username            name  \\\n",
       "0  19:56:20      EDT            228022886           acai_w    Angelo Wijdh   \n",
       "1  19:53:16      EDT  1134860643528577026    brittaswenson  Britta Swenson   \n",
       "2  19:45:35      EDT  1080245442732974081  sallywo42411402      Sally Wong   \n",
       "3  19:43:18      EDT           2431027482      ultimate1us        DENSMORE   \n",
       "4  19:41:33      EDT           2974733727        taffygeek    Rob Chappell   \n",
       "\n",
       "  place  ... user_rt_id user_rt retweet_id  \\\n",
       "0        ...                                 \n",
       "1        ...                                 \n",
       "2        ...                                 \n",
       "3        ...                                 \n",
       "4        ...                                 \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0   [{'user_id': '228022886', 'username': 'ACAI_W'}]                            \n",
       "1  [{'user_id': '1134860643528577026', 'username'...                            \n",
       "2  [{'user_id': '1080245442732974081', 'username'...                            \n",
       "3  [{'user_id': '2431027482', 'username': 'ultima...                            \n",
       "4  [{'user_id': '2974733727', 'username': 'taffyg...                            \n",
       "\n",
       "   trans_src trans_dest positive     death  \n",
       "0                        4852143  151483.0  \n",
       "1                        4852143  151483.0  \n",
       "2                        4852143  151483.0  \n",
       "3                        4852143  151483.0  \n",
       "4                        4852143  151483.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the two datasets for all Covid data in one place\n",
    "Master_Tweet_dataset = pd.merge(Master_Tweet_df,covid_data,on='date')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['cashtags', 'conversation_id', 'hashtags',\n",
    "       'id','link', 'mentions', 'name', 'near', 'photos',\n",
    "       'place', 'quote_url','reply_to', 'retweet',\n",
    "       'retweet_date', 'retweet_id','source', 'time',\n",
    "       'timezone', 'trans_dest', 'trans_src', 'translate','urls',\n",
    "       'user_id', 'user_rt', 'user_rt_id',],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jamaalsmith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'date', 'username', 'tweet', 'replies_count',\n",
       "       'retweets_count', 'likes_count', 'video', 'geo', 'positive', 'death'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install textfeatures\n",
    "import textfeatures as tf\n",
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>1291523532363636736</td>\n",
       "      <td>2020-08-06 23:56:20</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:56:20</td>\n",
       "      <td>EDT</td>\n",
       "      <td>228022886</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>Angelo Wijdh</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '228022886', 'username': 'ACAI_W'}]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1291522763233071105</td>\n",
       "      <td>1291451746724741120</td>\n",
       "      <td>2020-08-06 23:53:16</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:53:16</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1134860643528577026</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Britta Swenson</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1134860643528577026', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>1291520828148871168</td>\n",
       "      <td>2020-08-06 23:45:35</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:45:35</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1080245442732974081</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Sally Wong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '1080245442732974081', 'username'...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1291520253357326338</td>\n",
       "      <td>1291520253357326336</td>\n",
       "      <td>2020-08-06 23:43:18</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:43:18</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2431027482</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>DENSMORE</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2431027482', 'username': 'ultima...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1291519814339629059</td>\n",
       "      <td>1291518619197874176</td>\n",
       "      <td>2020-08-06 23:41:33</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>19:41:33</td>\n",
       "      <td>EDT</td>\n",
       "      <td>2974733727</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>Rob Chappell</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[{'user_id': '2974733727', 'username': 'taffyg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1291523532363636736  1291523532363636736 2020-08-06 23:56:20 2020-08-06   \n",
       "1  1291522763233071105  1291451746724741120 2020-08-06 23:53:16 2020-08-06   \n",
       "2  1291520828148871168  1291520828148871168 2020-08-06 23:45:35 2020-08-06   \n",
       "3  1291520253357326338  1291520253357326336 2020-08-06 23:43:18 2020-08-06   \n",
       "4  1291519814339629059  1291518619197874176 2020-08-06 23:41:33 2020-08-06   \n",
       "\n",
       "       time timezone              user_id         username            name  \\\n",
       "0  19:56:20      EDT            228022886           acai_w    Angelo Wijdh   \n",
       "1  19:53:16      EDT  1134860643528577026    brittaswenson  Britta Swenson   \n",
       "2  19:45:35      EDT  1080245442732974081  sallywo42411402      Sally Wong   \n",
       "3  19:43:18      EDT           2431027482      ultimate1us        DENSMORE   \n",
       "4  19:41:33      EDT           2974733727        taffygeek    Rob Chappell   \n",
       "\n",
       "  place  ... geo source user_rt_id user_rt  retweet_id  \\\n",
       "0        ...                                             \n",
       "1        ...                                             \n",
       "2        ...                                             \n",
       "3        ...                                             \n",
       "4        ...                                             \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0   [{'user_id': '228022886', 'username': 'ACAI_W'}]                           \n",
       "1  [{'user_id': '1134860643528577026', 'username'...                           \n",
       "2  [{'user_id': '1080245442732974081', 'username'...                           \n",
       "3  [{'user_id': '2431027482', 'username': 'ultima...                           \n",
       "4  [{'user_id': '2974733727', 'username': 'taffyg...                           \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting ride of duplicative column\n",
    "Master_Tweet_dataset=Master_Tweet_dataset.drop('created_at',axis=1)\n",
    "Master_Tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>acai_w</td>\n",
       "      <td>WoW, such a bold and honest statement and brou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>55</td>\n",
       "      <td>4.781818</td>\n",
       "      <td>27</td>\n",
       "      <td>318</td>\n",
       "      <td>[such, a, and, and, to, you, with, a, of, an, ...</td>\n",
       "      <td>bold honest statement brought integrity please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>brittaswenson</td>\n",
       "      <td>Trump lift the ban so he won’t be to blame for...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>43</td>\n",
       "      <td>4.395349</td>\n",
       "      <td>23</td>\n",
       "      <td>231</td>\n",
       "      <td>[the, so, he, be, to, for, the, and, from, in,...</td>\n",
       "      <td>trump lift wont blame coming bankruptcies majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>sallywo42411402</td>\n",
       "      <td>Proves Narvarro right and Dr. Fauci wrong, rig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>46</td>\n",
       "      <td>5.854167</td>\n",
       "      <td>13</td>\n",
       "      <td>331</td>\n",
       "      <td>[and, was, in, had, with, in, the, of, on, wha...</td>\n",
       "      <td>proves narvarro right fauci wrong right fauci ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>ultimate1us</td>\n",
       "      <td>In 2017 the USA became the victim of a systemi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>53</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>17</td>\n",
       "      <td>296</td>\n",
       "      <td>[the, the, of, a, in, and, is, very, of, have,...</td>\n",
       "      <td>became victim systemic brain cancer cancer sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>taffygeek</td>\n",
       "      <td>How is the Dow still rising. Just looking at t...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>4852143</td>\n",
       "      <td>151483.0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>[is, the, at, that, and, only, of, the, with, ...</td>\n",
       "      <td>still rising looking screen covid deaths covid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date         username  \\\n",
       "0 2020-08-06           acai_w   \n",
       "1 2020-08-06    brittaswenson   \n",
       "2 2020-08-06  sallywo42411402   \n",
       "3 2020-08-06      ultimate1us   \n",
       "4 2020-08-06        taffygeek   \n",
       "\n",
       "                                               tweet  replies_count  \\\n",
       "0  WoW, such a bold and honest statement and brou...              0   \n",
       "1  Trump lift the ban so he won’t be to blame for...              0   \n",
       "2  Proves Narvarro right and Dr. Fauci wrong, rig...              0   \n",
       "3  In 2017 the USA became the victim of a systemi...              0   \n",
       "4  How is the Dow still rising. Just looking at t...              7   \n",
       "\n",
       "   retweets_count  likes_count  video geo  positive     death  word_count  \\\n",
       "0               0            0      0       4852143  151483.0          55   \n",
       "1               0            0      0       4852143  151483.0          43   \n",
       "2               0            1      0       4852143  151483.0          46   \n",
       "3               0            0      1       4852143  151483.0          53   \n",
       "4               0            1      0       4852143  151483.0          36   \n",
       "\n",
       "   avg_word_length  stopwords_count  char_count  \\\n",
       "0         4.781818               27         318   \n",
       "1         4.395349               23         231   \n",
       "2         5.854167               13         331   \n",
       "3         4.692308               17         296   \n",
       "4         4.583333               15         200   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  [such, a, and, and, to, you, with, a, of, an, ...   \n",
       "1  [the, so, he, be, to, for, the, and, from, in,...   \n",
       "2  [and, was, in, had, with, in, the, of, on, wha...   \n",
       "3  [the, the, of, a, in, and, is, very, of, have,...   \n",
       "4  [is, the, at, that, and, only, of, the, with, ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  bold honest statement brought integrity please...  \n",
       "1  trump lift wont blame coming bankruptcies majo...  \n",
       "2  proves narvarro right fauci wrong right fauci ...  \n",
       "3  became victim systemic brain cancer cancer sta...  \n",
       "4  still rising looking screen covid deaths covid...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using textfeatures library for some text preprocessing\n",
    "tf.word_count(Master_Tweet_dataset,\"tweet\",'word_count')\n",
    "tf.avg_word_length(Master_Tweet_dataset,'tweet','avg_word_length')\n",
    "tf.stopwords_count(Master_Tweet_dataset,'tweet','stopwords_count')\n",
    "tf.char_count(Master_Tweet_dataset,'tweet','char_count')\n",
    "tf.stopwords(Master_Tweet_dataset,'tweet','stopwords')\n",
    "tf.clean(Master_Tweet_dataset,'tweet','clean_text')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and punctuation\n",
    "\n",
    "clean_tweet = Master_Tweet_dataset['clean_text']\n",
    "#Tweet Tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "#corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "#corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in clean_tweet:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tok list or later use\n",
    "\n",
    "with open('tok_corp_8_8.pickle','wb') as f:\n",
    "    pickle.dump(tok_corp,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis \n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import PatternAnalyzer, NaiveBayesAnalyzer\n",
    "#from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "tweets = Master_Tweet_dataset['clean_text']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "    #Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "    #sentiment = Classifier.predict_proba(tweet)\n",
    "    blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "    rating = blob.sentiment.polarity\n",
    "    Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_dataset['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fit12P9FHnHD",
    "outputId": "1c50c4c5-7eef-4a42-9e67-35b71e045df6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1579651200000000000\n",
       "1    1579651200000000000\n",
       "2    1579651200000000000\n",
       "3    1579651200000000000\n",
       "4    1579651200000000000\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saving as CSV for later uploads to different notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_dataset_textprocessing.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Poll Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Poll data\n",
    "poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "poll_data = poll_data.dropna()\n",
    "\n",
    "#Converting Date columns to integer so merge will work\n",
    "Master_Tweet_dataset['date'] = pd.to_datetime(Master_Tweet_dataset['date'])\n",
    "Master_Tweet_dataset['date'] = Master_Tweet_dataset['date'].astype(int)\n",
    "poll_data['date'] = pd.to_datetime(poll_data['date'])\n",
    "poll_data['date'] = poll_data['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging with Poll Data\n",
    "\n",
    "#poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "#pd.to_datetime(poll_data['Date']) #converting to datetime object for merge purposes\n",
    "#pd.to_datetime(Master_Tweet_df['Date']) #converting to datetime object for merge purposes\n",
    "\n",
    "left = Master_Tweet_dataset.sort_values(by='date')\n",
    "right = poll_data.sort_values(by='date')\n",
    "\n",
    "Master_Tweet_dataset = pd.merge_asof(left,right,on='date',allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1579651200000000000\n",
       "1    1579651200000000000\n",
       "2    1579651200000000000\n",
       "3    1579651200000000000\n",
       "4    1579651200000000000\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Master_Tweet_df = Master_Tweet_df.drop('Date')\n",
    "#Master_Tweet_df = Master_Tweet_df.drop('Date',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Victory Spread dataframe is Trump poll figure subtracted from Biden poll figure. If spread is positive, that indicates how much Biden is leading by. Should it be negative, that represents how much Trump is ahead by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Victory Spread\n",
    "Master_Tweet_dataset['Spread'] = Master_Tweet_dataset['Biden (D)'] - Master_Tweet_dataset['Trump (R)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiging topics to each tweet  -code inspired by stackabuse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Vectorizing docs\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(clean_tweet)\n",
    "\n",
    "#fitting LDA Model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "#transforming to get topic numbers\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape\n",
    "\n",
    "#creating column of Topics\n",
    "Master_Tweet_dataset['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['countries', 'death', 'amazon', 'rate', 'country', 'world', 'brazil', 'cases', 'india', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['international', 'medical', 'rate', 'virus', 'pandemic', 'doctors', 'patients', 'economy', 'death', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['second', 'strong', 'france', 'endorsement', 'military', 'total', 'italy', 'spain', 'complete', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['death', 'like', 'need', 'dont', 'country', 'americans', 'trump', 'world', 'people', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['wear', 'mask', 'masks', 'businesses', 'today', 'home', 'stay', 'safe', 'vaccine', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #5:\n",
      "['countries', 'number', 'population', 'world', 'coronavirus', 'trump', 'million', 'cases', 'deaths', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #6:\n",
      "['biden', 'america', 'fake', 'people', 'president', 'news', 'thank', 'covid', 'trump', 'great']\n",
      "\n",
      "\n",
      "Top 10 words for topic #7:\n",
      "['doesnt', 'economy', 'pandemic', 'virus', 'distancing', 'wearing', 'mask', 'social', 'time', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #8:\n",
      "['control', 'president', 'dont', 'countries', 'people', 'like', 'virus', 'trump', 'china', 'covid']\n",
      "\n",
      "\n",
      "Top 10 words for topic #9:\n",
      "['china', 'peak', 'canada', 'like', 'country', 'dont', 'trump', 'people', 'cases', 'covid']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top words for each topic\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to create Target Column\n",
    "category_dict = {}\n",
    "for key in [0,4,5,8,1,3]:\n",
    "    category_dict[key] = 'Bad Response'\n",
    "for key in [10,6,2,7,9]:\n",
    "    category_dict[key] = 'Good Response'\n",
    "    \n",
    "#Creation of Target Column\n",
    "Master_Tweet_dataset['Target'] = Master_Tweet_dataset['Topic'].map(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>positive</th>\n",
       "      <th>death</th>\n",
       "      <th>...</th>\n",
       "      <th>Poll</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Sample</th>\n",
       "      <th>MoE</th>\n",
       "      <th>Biden (D)</th>\n",
       "      <th>Trump (R)</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Making great progress in @Davos. Tremendous nu...</td>\n",
       "      <td>9465</td>\n",
       "      <td>17624</td>\n",
       "      <td>88225</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ABC News/Wash PostABC/WP</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>Sorry, if you come you will be immediately sen...</td>\n",
       "      <td>8643</td>\n",
       "      <td>24619</td>\n",
       "      <td>98960</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ABC News/Wash PostABC/WP</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>See you on Friday...Big Crowd! https://twitter...</td>\n",
       "      <td>7035</td>\n",
       "      <td>24342</td>\n",
       "      <td>97513</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ABC News/Wash PostABC/WP</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>True! https://twitter.com/RandPaul/status/1220...</td>\n",
       "      <td>3436</td>\n",
       "      <td>12031</td>\n",
       "      <td>50605</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ABC News/Wash PostABC/WP</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Good Response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1579651200000000000</td>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>“NO PRESSURE”</td>\n",
       "      <td>18086</td>\n",
       "      <td>19899</td>\n",
       "      <td>122408</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>ABC News/Wash PostABC/WP</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>880 RV</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Bad Response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date         username  \\\n",
       "0  1579651200000000000  realdonaldtrump   \n",
       "1  1579651200000000000  realdonaldtrump   \n",
       "2  1579651200000000000  realdonaldtrump   \n",
       "3  1579651200000000000  realdonaldtrump   \n",
       "4  1579651200000000000  realdonaldtrump   \n",
       "\n",
       "                                               tweet  replies_count  \\\n",
       "0  Making great progress in @Davos. Tremendous nu...           9465   \n",
       "1  Sorry, if you come you will be immediately sen...           8643   \n",
       "2  See you on Friday...Big Crowd! https://twitter...           7035   \n",
       "3  True! https://twitter.com/RandPaul/status/1220...           3436   \n",
       "4                                      “NO PRESSURE”          18086   \n",
       "\n",
       "   retweets_count  likes_count  video geo  positive  death  ...  \\\n",
       "0           17624        88225      0             2    NaN  ...   \n",
       "1           24619        98960      0             2    NaN  ...   \n",
       "2           24342        97513      0             2    NaN  ...   \n",
       "3           12031        50605      0             2    NaN  ...   \n",
       "4           19899       122408      0             2    NaN  ...   \n",
       "\n",
       "                       Poll  Start Date    End Date  Sample MoE Biden (D)  \\\n",
       "0  ABC News/Wash PostABC/WP  2020-01-20  2020-01-23  880 RV   4      50.0   \n",
       "1  ABC News/Wash PostABC/WP  2020-01-20  2020-01-23  880 RV   4      50.0   \n",
       "2  ABC News/Wash PostABC/WP  2020-01-20  2020-01-23  880 RV   4      50.0   \n",
       "3  ABC News/Wash PostABC/WP  2020-01-20  2020-01-23  880 RV   4      50.0   \n",
       "4  ABC News/Wash PostABC/WP  2020-01-20  2020-01-23  880 RV   4      50.0   \n",
       "\n",
       "   Trump (R) Spread Topic         Target  \n",
       "0       46.0    4.0     0   Bad Response  \n",
       "1       46.0    4.0     3   Bad Response  \n",
       "2       46.0    4.0     0   Bad Response  \n",
       "3       46.0    4.0     9  Good Response  \n",
       "4       46.0    4.0     5   Bad Response  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DF Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'tweet', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'video', 'geo', 'positive', 'death', 'word_count',\n",
       "       'avg_word_length', 'stopwords_count', 'char_count', 'stopwords',\n",
       "       'clean_text', 'Sentiment', 'Poll', 'Start Date', 'End Date', 'Sample',\n",
       "       'MoE', 'Biden (D)', 'Trump (R)', 'Spread', 'Topic', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_df = Master_Tweet_dataset.copy()\n",
    "EDA_df.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe for just text data\n",
    "#Tweet_df = Master_Tweet_dataset[['date','tweet','stopwords','clean_text']]\n",
    "#creating dataframe for poll data \n",
    "#Poll_df = Master_Tweet_dataset[['Start Date','End Date','Sample','MoE','Poll','Biden (D)', 'Trump (R)']]\n",
    "\n",
    "\n",
    "# couldn't find any value from these columns\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['tweet','Poll',\n",
    "       'Start Date', 'End Date', 'Sample', 'MoE', 'Biden (D)', 'Trump (R)',\n",
    "       'Spread'],axis=1)\n",
    "\n",
    "#converting date column to integer for modeling purposes\n",
    "#def datetime_to_int(dt):\n",
    "    #return int(dt.strftime(\"%Y%m%d\"))\n",
    "\n",
    "#Master_Tweet_dataset['date'] = Master_Tweet_df['date'].apply(lambda x: datetime_to_int(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making sure datatype is ok for modeling\n",
    "Master_Tweet_dataset['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "Master_Tweet_dataset.isnull().sum()\n",
    "Master_Tweet_dataset['death'] = Master_Tweet_dataset['death'].fillna(method='backfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master_Tweet_dataset.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df to csv for upload in other notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_modelready.csv')\n",
    "#Tweet_df.to_csv('data/Tweet_text_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17481"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Master_Tweet_dataset['Target'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
