{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jamaalsmith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import textfeatures as tf\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import PatternAnalyzer, NaiveBayesAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Obtaining Tweet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "Creating DataFrames based on JSON files created in Twitter_dataqueries notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('tweets/Covid_tweets4.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('tweets/Trump_Covid_tweets4.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('tweets/Cuomo_Covid_tweets4.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('tweets/Nytimes_Covid_tweets4.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('tweets/Washpost_tweets4.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['date'] = pd.to_datetime(All_Covid_tweets['date'], format='%Y%m%d')\n",
    "Trump_Covid_tweets['date'] = pd.to_datetime(Trump_Covid_tweets['date'], format='%Y%m%d')\n",
    "Cuomo_Covid_tweets['date'] = pd.to_datetime(Cuomo_Covid_tweets['date'], format='%Y%m%d')\n",
    "Baseline_tweets['date'] = pd.to_datetime(Baseline_tweets['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets in the dataset is: 121600\n"
     ]
    }
   ],
   "source": [
    "#Combining all Tweet DFs into one\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets,Trump_Covid_tweets,\n",
    "                             Cuomo_Covid_tweets,Baseline_tweets],axis=0)\n",
    "\n",
    "number_of_tweets = len(Master_Tweet_df)\n",
    "print('The number of tweets in the dataset is:',number_of_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "Data for Covid Cases and Deaths was collected from The COVID Tracking Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "covid_data = pd.read_csv('https://raw.githubusercontent.com/COVID19Tracking/covid-tracking-data/master/data/us_daily.csv')\n",
    "\n",
    "# formatting the date column to datetime\n",
    "covid_data['date'] = pd.to_datetime(covid_data['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>states</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>...</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-12</td>\n",
       "      <td>56</td>\n",
       "      <td>5172216</td>\n",
       "      <td>58543332</td>\n",
       "      <td>4174.0</td>\n",
       "      <td>47919.0</td>\n",
       "      <td>340097.0</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>15524.0</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>63719722</td>\n",
       "      <td>63715548</td>\n",
       "      <td>63715548</td>\n",
       "      <td>1485</td>\n",
       "      <td>3035</td>\n",
       "      <td>407549</td>\n",
       "      <td>55742</td>\n",
       "      <td>463291</td>\n",
       "      <td>8b0e0ba647da128cf066056e3e1bcf4a94120c8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>56</td>\n",
       "      <td>5116474</td>\n",
       "      <td>58135783</td>\n",
       "      <td>4118.0</td>\n",
       "      <td>48500.0</td>\n",
       "      <td>337062.0</td>\n",
       "      <td>9136.0</td>\n",
       "      <td>15331.0</td>\n",
       "      <td>2415.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-11T00:00:00Z</td>\n",
       "      <td>63256375</td>\n",
       "      <td>63252257</td>\n",
       "      <td>63252257</td>\n",
       "      <td>1326</td>\n",
       "      <td>2715</td>\n",
       "      <td>683489</td>\n",
       "      <td>55594</td>\n",
       "      <td>739083</td>\n",
       "      <td>4b53c5c61a1b558e1b41cc8e6327f7359c17b4b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-10</td>\n",
       "      <td>56</td>\n",
       "      <td>5060880</td>\n",
       "      <td>57452294</td>\n",
       "      <td>3966.0</td>\n",
       "      <td>48612.0</td>\n",
       "      <td>334347.0</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>15158.0</td>\n",
       "      <td>2533.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-10T00:00:00Z</td>\n",
       "      <td>62517140</td>\n",
       "      <td>62513174</td>\n",
       "      <td>62513174</td>\n",
       "      <td>426</td>\n",
       "      <td>1654</td>\n",
       "      <td>674422</td>\n",
       "      <td>41807</td>\n",
       "      <td>716229</td>\n",
       "      <td>80e59c48dcdce8c0fa8760d93a4d1bf0c1a58c35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-09</td>\n",
       "      <td>56</td>\n",
       "      <td>5019073</td>\n",
       "      <td>56777872</td>\n",
       "      <td>3871.0</td>\n",
       "      <td>49048.0</td>\n",
       "      <td>332693.0</td>\n",
       "      <td>9303.0</td>\n",
       "      <td>15081.0</td>\n",
       "      <td>2507.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-09T00:00:00Z</td>\n",
       "      <td>61800816</td>\n",
       "      <td>61796945</td>\n",
       "      <td>61796945</td>\n",
       "      <td>616</td>\n",
       "      <td>838</td>\n",
       "      <td>661522</td>\n",
       "      <td>51319</td>\n",
       "      <td>712841</td>\n",
       "      <td>83d72910d9f712693eee3f8ca13182a53c81547a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>56</td>\n",
       "      <td>4967754</td>\n",
       "      <td>56116350</td>\n",
       "      <td>3888.0</td>\n",
       "      <td>50016.0</td>\n",
       "      <td>331855.0</td>\n",
       "      <td>9652.0</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-08T00:00:00Z</td>\n",
       "      <td>61087992</td>\n",
       "      <td>61084104</td>\n",
       "      <td>61084104</td>\n",
       "      <td>1089</td>\n",
       "      <td>1431</td>\n",
       "      <td>614455</td>\n",
       "      <td>54091</td>\n",
       "      <td>668546</td>\n",
       "      <td>b538b3af9fdc175ec448e61facfd4b323fa32452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  states  positive  negative  pending  hospitalizedCurrently  \\\n",
       "0 2020-08-12      56   5172216  58543332   4174.0                47919.0   \n",
       "1 2020-08-11      56   5116474  58135783   4118.0                48500.0   \n",
       "2 2020-08-10      56   5060880  57452294   3966.0                48612.0   \n",
       "3 2020-08-09      56   5019073  56777872   3871.0                49048.0   \n",
       "4 2020-08-08      56   4967754  56116350   3888.0                50016.0   \n",
       "\n",
       "   hospitalizedCumulative  inIcuCurrently  inIcuCumulative  \\\n",
       "0                340097.0          9559.0          15524.0   \n",
       "1                337062.0          9136.0          15331.0   \n",
       "2                334347.0          9216.0          15158.0   \n",
       "3                332693.0          9303.0          15081.0   \n",
       "4                331855.0          9652.0          15024.0   \n",
       "\n",
       "   onVentilatorCurrently  ...          lastModified     total  \\\n",
       "0                 2604.0  ...  2020-08-12T00:00:00Z  63719722   \n",
       "1                 2415.0  ...  2020-08-11T00:00:00Z  63256375   \n",
       "2                 2533.0  ...  2020-08-10T00:00:00Z  62517140   \n",
       "3                 2507.0  ...  2020-08-09T00:00:00Z  61800816   \n",
       "4                 2566.0  ...  2020-08-08T00:00:00Z  61087992   \n",
       "\n",
       "  totalTestResults    posNeg  deathIncrease hospitalizedIncrease  \\\n",
       "0         63715548  63715548           1485                 3035   \n",
       "1         63252257  63252257           1326                 2715   \n",
       "2         62513174  62513174            426                 1654   \n",
       "3         61796945  61796945            616                  838   \n",
       "4         61084104  61084104           1089                 1431   \n",
       "\n",
       "   negativeIncrease  positiveIncrease  totalTestResultsIncrease  \\\n",
       "0            407549             55742                    463291   \n",
       "1            683489             55594                    739083   \n",
       "2            674422             41807                    716229   \n",
       "3            661522             51319                    712841   \n",
       "4            614455             54091                    668546   \n",
       "\n",
       "                                       hash  \n",
       "0  8b0e0ba647da128cf066056e3e1bcf4a94120c8d  \n",
       "1  4b53c5c61a1b558e1b41cc8e6327f7359c17b4b1  \n",
       "2  80e59c48dcdce8c0fa8760d93a4d1bf0c1a58c35  \n",
       "3  83d72910d9f712693eee3f8ca13182a53c81547a  \n",
       "4  b538b3af9fdc175ec448e61facfd4b323fa32452  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#covid_data = covid_data[['date','positive','death']]\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1288979300402761729</td>\n",
       "      <td>1288973180745453568</td>\n",
       "      <td>2020-07-30 23:26:27</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>19:26:27</td>\n",
       "      <td>EDT</td>\n",
       "      <td>826617118833655809</td>\n",
       "      <td>the1triplej</td>\n",
       "      <td>Triple J</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-30T00:00:00Z</td>\n",
       "      <td>54650948</td>\n",
       "      <td>54647001</td>\n",
       "      <td>54647001</td>\n",
       "      <td>1259</td>\n",
       "      <td>3383</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1288978980435984386</td>\n",
       "      <td>1288880289532407808</td>\n",
       "      <td>2020-07-30 23:25:11</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>19:25:11</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1276535008094597121</td>\n",
       "      <td>oglesbykisha</td>\n",
       "      <td>Kisha Sharon Oglesby</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-30T00:00:00Z</td>\n",
       "      <td>54650948</td>\n",
       "      <td>54647001</td>\n",
       "      <td>54647001</td>\n",
       "      <td>1259</td>\n",
       "      <td>3383</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1288972333919633409</td>\n",
       "      <td>1288815049604292608</td>\n",
       "      <td>2020-07-30 22:58:47</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>18:58:47</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1233601848629698561</td>\n",
       "      <td>victors10855858</td>\n",
       "      <td>Little Wolf</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-30T00:00:00Z</td>\n",
       "      <td>54650948</td>\n",
       "      <td>54647001</td>\n",
       "      <td>54647001</td>\n",
       "      <td>1259</td>\n",
       "      <td>3383</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1288972076808888322</td>\n",
       "      <td>1288935893013876736</td>\n",
       "      <td>2020-07-30 22:57:45</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>18:57:45</td>\n",
       "      <td>EDT</td>\n",
       "      <td>1055623358719713280</td>\n",
       "      <td>jerryspiegler</td>\n",
       "      <td>Jerry Spiegler@üè°</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-30T00:00:00Z</td>\n",
       "      <td>54650948</td>\n",
       "      <td>54647001</td>\n",
       "      <td>54647001</td>\n",
       "      <td>1259</td>\n",
       "      <td>3383</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1288967146123464706</td>\n",
       "      <td>1288907916020461568</td>\n",
       "      <td>2020-07-30 22:38:10</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>18:38:10</td>\n",
       "      <td>EDT</td>\n",
       "      <td>340312944</td>\n",
       "      <td>phlphlyest</td>\n",
       "      <td>Joy</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-07-30T00:00:00Z</td>\n",
       "      <td>54650948</td>\n",
       "      <td>54647001</td>\n",
       "      <td>54647001</td>\n",
       "      <td>1259</td>\n",
       "      <td>3383</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1288979300402761729  1288973180745453568 2020-07-30 23:26:27 2020-07-30   \n",
       "1  1288978980435984386  1288880289532407808 2020-07-30 23:25:11 2020-07-30   \n",
       "2  1288972333919633409  1288815049604292608 2020-07-30 22:58:47 2020-07-30   \n",
       "3  1288972076808888322  1288935893013876736 2020-07-30 22:57:45 2020-07-30   \n",
       "4  1288967146123464706  1288907916020461568 2020-07-30 22:38:10 2020-07-30   \n",
       "\n",
       "       time timezone              user_id         username  \\\n",
       "0  19:26:27      EDT   826617118833655809      the1triplej   \n",
       "1  19:25:11      EDT  1276535008094597121     oglesbykisha   \n",
       "2  18:58:47      EDT  1233601848629698561  victors10855858   \n",
       "3  18:57:45      EDT  1055623358719713280    jerryspiegler   \n",
       "4  18:38:10      EDT            340312944       phlphlyest   \n",
       "\n",
       "                   name place  ...          lastModified     total  \\\n",
       "0              Triple J        ...  2020-07-30T00:00:00Z  54650948   \n",
       "1  Kisha Sharon Oglesby        ...  2020-07-30T00:00:00Z  54650948   \n",
       "2           Little Wolf        ...  2020-07-30T00:00:00Z  54650948   \n",
       "3      Jerry Spiegler@üè°        ...  2020-07-30T00:00:00Z  54650948   \n",
       "4                   Joy        ...  2020-07-30T00:00:00Z  54650948   \n",
       "\n",
       "  totalTestResults    posNeg  deathIncrease  hospitalizedIncrease  \\\n",
       "0         54647001  54647001           1259                  3383   \n",
       "1         54647001  54647001           1259                  3383   \n",
       "2         54647001  54647001           1259                  3383   \n",
       "3         54647001  54647001           1259                  3383   \n",
       "4         54647001  54647001           1259                  3383   \n",
       "\n",
       "   negativeIncrease positiveIncrease totalTestResultsIncrease  \\\n",
       "0            736388            69466                   805854   \n",
       "1            736388            69466                   805854   \n",
       "2            736388            69466                   805854   \n",
       "3            736388            69466                   805854   \n",
       "4            736388            69466                   805854   \n",
       "\n",
       "                                       hash  \n",
       "0  7be08ec9befba2afef926c3c2d79da3e1fe5022a  \n",
       "1  7be08ec9befba2afef926c3c2d79da3e1fe5022a  \n",
       "2  7be08ec9befba2afef926c3c2d79da3e1fe5022a  \n",
       "3  7be08ec9befba2afef926c3c2d79da3e1fe5022a  \n",
       "4  7be08ec9befba2afef926c3c2d79da3e1fe5022a  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the two datasets for all Covid data in one place\n",
    "Master_Tweet_dataset = pd.merge(Master_Tweet_df,covid_data,on='date')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['cashtags', 'conversation_id', 'hashtags',\n",
    "       'id','link', 'mentions', 'name', 'near', 'photos',\n",
    "       'place', 'quote_url','reply_to', 'retweet',\n",
    "       'retweet_date', 'retweet_id','source', 'time',\n",
    "       'timezone', 'trans_dest', 'trans_src', 'translate','urls',\n",
    "       'user_id', 'user_rt', 'user_rt_id',],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'tweet', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'video', 'geo', 'states', 'positive', 'negative',\n",
       "       'pending', 'hospitalizedCurrently', 'hospitalizedCumulative',\n",
       "       'inIcuCurrently', 'inIcuCumulative', 'onVentilatorCurrently',\n",
       "       'onVentilatorCumulative', 'recovered', 'dateChecked', 'death',\n",
       "       'hospitalized', 'lastModified', 'total', 'totalTestResults', 'posNeg',\n",
       "       'deathIncrease', 'hospitalizedIncrease', 'negativeIncrease',\n",
       "       'positiveIncrease', 'totalTestResultsIncrease', 'hash'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install textfeatures\n",
    "#Getting ride of duplicative column\n",
    "Master_Tweet_dataset=Master_Tweet_dataset.drop('created_at',axis=1)\n",
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>states</th>\n",
       "      <th>positive</th>\n",
       "      <th>...</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>the1triplej</td>\n",
       "      <td>You sure have; America 1st in the world for to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>4467852</td>\n",
       "      <td>...</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "      <td>36</td>\n",
       "      <td>4.638889</td>\n",
       "      <td>13</td>\n",
       "      <td>202</td>\n",
       "      <td>[in, the, for, between, or, and, the, will, be...</td>\n",
       "      <td>sure america world total covid cases making fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>oglesbykisha</td>\n",
       "      <td>Watching Fox news on the State of the 2020 rac...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>4467852</td>\n",
       "      <td>...</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "      <td>48</td>\n",
       "      <td>4.734694</td>\n",
       "      <td>22</td>\n",
       "      <td>280</td>\n",
       "      <td>[on, the, of, the, the, why, they, for, the, o...</td>\n",
       "      <td>watching news state race amid covidask voters ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>victors10855858</td>\n",
       "      <td>Do you mean Covid-19 or perhaps SARS-COV-2? Be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>4467852</td>\n",
       "      <td>...</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "      <td>48</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>271</td>\n",
       "      <td>[you, or, is, and, if, we, to, a, we, should, ...</td>\n",
       "      <td>mean covid perhaps sarscov china virus racist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>jerryspiegler</td>\n",
       "      <td>You think the Russians or the Chinese are just...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>4467852</td>\n",
       "      <td>...</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "      <td>41</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>17</td>\n",
       "      <td>227</td>\n",
       "      <td>[the, or, the, are, just, with, to, the, don't...</td>\n",
       "      <td>think russians chinese waiting baited breath a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>phlphlyest</td>\n",
       "      <td>He did not die of cancer. He was in remission....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>56</td>\n",
       "      <td>4467852</td>\n",
       "      <td>...</td>\n",
       "      <td>736388</td>\n",
       "      <td>69466</td>\n",
       "      <td>805854</td>\n",
       "      <td>7be08ec9befba2afef926c3c2d79da3e1fe5022a</td>\n",
       "      <td>43</td>\n",
       "      <td>4.720930</td>\n",
       "      <td>17</td>\n",
       "      <td>245</td>\n",
       "      <td>[did, not, of, was, in, had, a, and, an, or, a...</td>\n",
       "      <td>cancer remission compromised immune system att...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date         username  \\\n",
       "0 2020-07-30      the1triplej   \n",
       "1 2020-07-30     oglesbykisha   \n",
       "2 2020-07-30  victors10855858   \n",
       "3 2020-07-30    jerryspiegler   \n",
       "4 2020-07-30       phlphlyest   \n",
       "\n",
       "                                               tweet  replies_count  \\\n",
       "0  You sure have; America 1st in the world for to...              0   \n",
       "1  Watching Fox news on the State of the 2020 rac...              0   \n",
       "2  Do you mean Covid-19 or perhaps SARS-COV-2? Be...              0   \n",
       "3  You think the Russians or the Chinese are just...              0   \n",
       "4  He did not die of cancer. He was in remission....              0   \n",
       "\n",
       "   retweets_count  likes_count  video geo  states  positive  ...  \\\n",
       "0               0            1      0          56   4467852  ...   \n",
       "1               0            0      0          56   4467852  ...   \n",
       "2               0            0      0          56   4467852  ...   \n",
       "3               1            7      0          56   4467852  ...   \n",
       "4               0            5      0          56   4467852  ...   \n",
       "\n",
       "   negativeIncrease  positiveIncrease  totalTestResultsIncrease  \\\n",
       "0            736388             69466                    805854   \n",
       "1            736388             69466                    805854   \n",
       "2            736388             69466                    805854   \n",
       "3            736388             69466                    805854   \n",
       "4            736388             69466                    805854   \n",
       "\n",
       "                                       hash  word_count  avg_word_length  \\\n",
       "0  7be08ec9befba2afef926c3c2d79da3e1fe5022a          36         4.638889   \n",
       "1  7be08ec9befba2afef926c3c2d79da3e1fe5022a          48         4.734694   \n",
       "2  7be08ec9befba2afef926c3c2d79da3e1fe5022a          48         4.666667   \n",
       "3  7be08ec9befba2afef926c3c2d79da3e1fe5022a          41         4.560976   \n",
       "4  7be08ec9befba2afef926c3c2d79da3e1fe5022a          43         4.720930   \n",
       "\n",
       "   stopwords_count  char_count  \\\n",
       "0               13         202   \n",
       "1               22         280   \n",
       "2               22         271   \n",
       "3               17         227   \n",
       "4               17         245   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  [in, the, for, between, or, and, the, will, be...   \n",
       "1  [on, the, of, the, the, why, they, for, the, o...   \n",
       "2  [you, or, is, and, if, we, to, a, we, should, ...   \n",
       "3  [the, or, the, are, just, with, to, the, don't...   \n",
       "4  [did, not, of, was, in, had, a, and, an, or, a...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  sure america world total covid cases making fa...  \n",
       "1  watching news state race amid covidask voters ...  \n",
       "2  mean covid perhaps sarscov china virus racist ...  \n",
       "3  think russians chinese waiting baited breath a...  \n",
       "4  cancer remission compromised immune system att...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using textfeatures library text preprocessing\n",
    "tf.word_count(Master_Tweet_dataset,\"tweet\",'word_count')\n",
    "tf.avg_word_length(Master_Tweet_dataset,'tweet','avg_word_length')\n",
    "tf.stopwords_count(Master_Tweet_dataset,'tweet','stopwords_count')\n",
    "tf.char_count(Master_Tweet_dataset,'tweet','char_count')\n",
    "tf.stopwords(Master_Tweet_dataset,'tweet','stopwords')\n",
    "tf.clean(Master_Tweet_dataset,'tweet','clean_text')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the Corpus\n",
    "\n",
    "clean_tweet = Master_Tweet_dataset['clean_text']\n",
    "#Tweet Tokenizer \n",
    "\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "#corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "#corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in clean_tweet:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tok list or later use\n",
    "\n",
    "with open('tok_corp_8_8.pickle','wb') as f:\n",
    "    pickle.dump(tok_corp,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis - adding Sentiment rating to each tweet\n",
    "\n",
    "#from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "tweets = Master_Tweet_dataset['clean_text']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "    #Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "    #sentiment = Classifier.predict_proba(tweet)\n",
    "    blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "    rating = blob.sentiment.polarity\n",
    "    Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_dataset['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fit12P9FHnHD",
    "outputId": "1c50c4c5-7eef-4a42-9e67-35b71e045df6"
   },
   "outputs": [],
   "source": [
    "#Saving as CSV for later uploads to different notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_dataset_textprocessing.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Poll Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Poll data\n",
    "poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "poll_data = poll_data.dropna()\n",
    "\n",
    "#Converting Date columns to integer so merge will work\n",
    "Master_Tweet_dataset['date'] = pd.to_datetime(Master_Tweet_dataset['date'])\n",
    "Master_Tweet_dataset['date'] = Master_Tweet_dataset['date'].astype(int)\n",
    "poll_data['date'] = pd.to_datetime(poll_data['date'])\n",
    "poll_data['date'] = poll_data['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging with Poll Data\n",
    "\n",
    "#poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "#pd.to_datetime(poll_data['Date']) #converting to datetime object for merge purposes\n",
    "#pd.to_datetime(Master_Tweet_df['Date']) #converting to datetime object for merge purposes\n",
    "\n",
    "left = Master_Tweet_dataset.sort_values(by='date')\n",
    "right = poll_data.sort_values(by='date')\n",
    "\n",
    "Master_Tweet_dataset = pd.merge_asof(left,right,on='date',allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master_Tweet_df = Master_Tweet_df.drop('Date')\n",
    "#Master_Tweet_df = Master_Tweet_df.drop('Date',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this project, our goal is to see if we can classify how individuals view the response to the Covid pandemic in the United States. The below cells group the tweets into 10 topic with use of a Latent Dirichlet Allocation model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Victory Spread\n",
    "Master_Tweet_dataset['Spread'] = Master_Tweet_dataset['Biden (D)'] - Master_Tweet_dataset['Trump (R)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7420a458464f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mLDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#transforming to get topic numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0;31m# batch update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     self._em_step(X, total_samples=n_samples,\n\u001b[0;32m--> 580\u001b[0;31m                                   batch_update=True, parallel=parallel)\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;31m# check perplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[0;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# E-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[0;32m--> 448\u001b[0;31m                                      parallel=parallel)\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# M-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[1;32m    399\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_change_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_sstats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                                               random_state)\n\u001b[0;32m--> 401\u001b[0;31m             for idx_slice in gen_even_slices(X.shape[0], n_jobs))\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# merge result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/decomposition/_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[0;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             doc_topic_d = (exp_doc_topic_d *\n\u001b[0;32m--> 116\u001b[0;31m                            np.dot(cnts / norm_phi, exp_topic_word_d.T))\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# Note: adds doc_topic_prior to doc_topic_d, in-place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             _dirichlet_expectation_1d(doc_topic_d, doc_topic_prior,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Assiging topics to each tweet  -code inspired by stackabuse\n",
    "\n",
    "\n",
    "#Vectorizing docs\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(clean_tweet)\n",
    "\n",
    "#fitting LDA Model\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "#transforming to get topic numbers\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape\n",
    "\n",
    "#creating column of Topics\n",
    "Master_Tweet_dataset['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top words for each topic\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to create Target Column\n",
    "category_dict = {}\n",
    "for key in [0,4,5,8,1,3]:\n",
    "    category_dict[key] = 'Bad Response'\n",
    "for key in [10,6,2,7,9]:\n",
    "    category_dict[key] = 'Good Response'\n",
    "    \n",
    "#Creation of Target Column\n",
    "Master_Tweet_dataset['Target'] = Master_Tweet_dataset['Topic'].map(category_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DF Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_df = Master_Tweet_dataset.copy()\n",
    "EDA_df.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe for just text data\n",
    "#Tweet_df = Master_Tweet_dataset[['date','tweet','stopwords','clean_text']]\n",
    "#creating dataframe for poll data \n",
    "#Poll_df = Master_Tweet_dataset[['Start Date','End Date','Sample','MoE','Poll','Biden (D)', 'Trump (R)']]\n",
    "\n",
    "\n",
    "# couldn't find any value from these columns\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['tweet','Poll',\n",
    "       'Start Date', 'End Date', 'Sample', 'MoE',\n",
    "       ],axis=1)\n",
    "\n",
    "#converting date column to integer for modeling purposes\n",
    "#def datetime_to_int(dt):\n",
    "    #return int(dt.strftime(\"%Y%m%d\"))\n",
    "\n",
    "#Master_Tweet_dataset['date'] = Master_Tweet_df['date'].apply(lambda x: datetime_to_int(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making sure date is ok for modeling\n",
    "Master_Tweet_dataset['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "Master_Tweet_dataset.isnull().sum()\n",
    "Master_Tweet_dataset['death'] = Master_Tweet_dataset['death'].fillna(method='backfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master_Tweet_dataset.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df to csv for upload in other notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_modelready.csv')\n",
    "#Tweet_df.to_csv('data/Tweet_text_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Master_Tweet_dataset['Target'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
