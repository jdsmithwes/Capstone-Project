{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import textfeatures as tf\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import PatternAnalyzer, NaiveBayesAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Obtaining Tweet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "Creating DataFrames based on JSON files created in Twitter_dataqueries notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('tweets/Covid_tweets5.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('tweets/Trump_Covid_tweets4.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('tweets/Cuomo_Covid_tweets5.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('tweets/Nytimes_Covid_tweets5.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('tweets/Washpost_tweets5.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['date'] = pd.to_datetime(All_Covid_tweets['date'], format='%Y%m%d')\n",
    "Trump_Covid_tweets['date'] = pd.to_datetime(Trump_Covid_tweets['date'], format='%Y%m%d')\n",
    "Cuomo_Covid_tweets['date'] = pd.to_datetime(Cuomo_Covid_tweets['date'], format='%Y%m%d')\n",
    "Baseline_tweets['date'] = pd.to_datetime(Baseline_tweets['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets in the dataset is: 24681\n"
     ]
    }
   ],
   "source": [
    "#Combining all Tweet DFs into one\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets,Trump_Covid_tweets,\n",
    "                             Cuomo_Covid_tweets,Baseline_tweets],axis=0)\n",
    "\n",
    "number_of_tweets = len(Master_Tweet_df)\n",
    "print('The number of tweets in the dataset is:',number_of_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Covid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "Data for Covid Cases and Deaths was collected from The COVID Tracking Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "covid_data = pd.read_csv('data/daily.8.22.csv')\n",
    "\n",
    "# formatting the date column to datetime\n",
    "covid_data['date'] = pd.to_datetime(covid_data['date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>states</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>pending</th>\n",
       "      <th>hospitalizedCurrently</th>\n",
       "      <th>hospitalizedCumulative</th>\n",
       "      <th>inIcuCurrently</th>\n",
       "      <th>inIcuCumulative</th>\n",
       "      <th>onVentilatorCurrently</th>\n",
       "      <th>...</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>56</td>\n",
       "      <td>5639613</td>\n",
       "      <td>65442552</td>\n",
       "      <td>4154.0</td>\n",
       "      <td>39905.0</td>\n",
       "      <td>358613.0</td>\n",
       "      <td>8218.0</td>\n",
       "      <td>16657.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-22T00:00:00Z</td>\n",
       "      <td>71086319</td>\n",
       "      <td>71082165</td>\n",
       "      <td>71082165</td>\n",
       "      <td>1024</td>\n",
       "      <td>1520</td>\n",
       "      <td>699089</td>\n",
       "      <td>46295</td>\n",
       "      <td>745384</td>\n",
       "      <td>10f85ba760e3a61eb34ab55eb1ccc3ec21eed56f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>56</td>\n",
       "      <td>5593318</td>\n",
       "      <td>64743463</td>\n",
       "      <td>4199.0</td>\n",
       "      <td>40951.0</td>\n",
       "      <td>357093.0</td>\n",
       "      <td>8349.0</td>\n",
       "      <td>16563.0</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-21T00:00:00Z</td>\n",
       "      <td>70340980</td>\n",
       "      <td>70336781</td>\n",
       "      <td>70336781</td>\n",
       "      <td>1123</td>\n",
       "      <td>1817</td>\n",
       "      <td>685099</td>\n",
       "      <td>46821</td>\n",
       "      <td>731920</td>\n",
       "      <td>cd07637ded4b265fc45cb2c204784d5cb8c70085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>56</td>\n",
       "      <td>5546497</td>\n",
       "      <td>64058364</td>\n",
       "      <td>4170.0</td>\n",
       "      <td>41988.0</td>\n",
       "      <td>355276.0</td>\n",
       "      <td>8483.0</td>\n",
       "      <td>16487.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-20T00:00:00Z</td>\n",
       "      <td>69609031</td>\n",
       "      <td>69604861</td>\n",
       "      <td>69604861</td>\n",
       "      <td>1134</td>\n",
       "      <td>2010</td>\n",
       "      <td>621696</td>\n",
       "      <td>43740</td>\n",
       "      <td>665436</td>\n",
       "      <td>5e7ec5926f868e83e4fd901d5b6b7e3c0c9f161b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>56</td>\n",
       "      <td>5502757</td>\n",
       "      <td>63436668</td>\n",
       "      <td>4374.0</td>\n",
       "      <td>43330.0</td>\n",
       "      <td>353266.0</td>\n",
       "      <td>8744.0</td>\n",
       "      <td>16377.0</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-19T00:00:00Z</td>\n",
       "      <td>68943799</td>\n",
       "      <td>68939425</td>\n",
       "      <td>68939425</td>\n",
       "      <td>1420</td>\n",
       "      <td>2032</td>\n",
       "      <td>630559</td>\n",
       "      <td>44933</td>\n",
       "      <td>675492</td>\n",
       "      <td>64c8b61e3c52baa7b1bcb0a6bbaa8dee87f3e71c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>56</td>\n",
       "      <td>5457824</td>\n",
       "      <td>62806109</td>\n",
       "      <td>4412.0</td>\n",
       "      <td>43747.0</td>\n",
       "      <td>351234.0</td>\n",
       "      <td>8866.0</td>\n",
       "      <td>16123.0</td>\n",
       "      <td>2468.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-08-18T00:00:00Z</td>\n",
       "      <td>68268345</td>\n",
       "      <td>68263933</td>\n",
       "      <td>68263933</td>\n",
       "      <td>1195</td>\n",
       "      <td>2273</td>\n",
       "      <td>602356</td>\n",
       "      <td>40458</td>\n",
       "      <td>642814</td>\n",
       "      <td>e41905ca050e7958f710b87063f436f7e8f1a9aa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  states  positive  negative  pending  hospitalizedCurrently  \\\n",
       "0 2020-08-22      56   5639613  65442552   4154.0                39905.0   \n",
       "1 2020-08-21      56   5593318  64743463   4199.0                40951.0   \n",
       "2 2020-08-20      56   5546497  64058364   4170.0                41988.0   \n",
       "3 2020-08-19      56   5502757  63436668   4374.0                43330.0   \n",
       "4 2020-08-18      56   5457824  62806109   4412.0                43747.0   \n",
       "\n",
       "   hospitalizedCumulative  inIcuCurrently  inIcuCumulative  \\\n",
       "0                358613.0          8218.0          16657.0   \n",
       "1                357093.0          8349.0          16563.0   \n",
       "2                355276.0          8483.0          16487.0   \n",
       "3                353266.0          8744.0          16377.0   \n",
       "4                351234.0          8866.0          16123.0   \n",
       "\n",
       "   onVentilatorCurrently  ...          lastModified     total  \\\n",
       "0                 2205.0  ...  2020-08-22T00:00:00Z  71086319   \n",
       "1                 2286.0  ...  2020-08-21T00:00:00Z  70340980   \n",
       "2                 2335.0  ...  2020-08-20T00:00:00Z  69609031   \n",
       "3                 2371.0  ...  2020-08-19T00:00:00Z  68943799   \n",
       "4                 2468.0  ...  2020-08-18T00:00:00Z  68268345   \n",
       "\n",
       "  totalTestResults    posNeg  deathIncrease hospitalizedIncrease  \\\n",
       "0         71082165  71082165           1024                 1520   \n",
       "1         70336781  70336781           1123                 1817   \n",
       "2         69604861  69604861           1134                 2010   \n",
       "3         68939425  68939425           1420                 2032   \n",
       "4         68263933  68263933           1195                 2273   \n",
       "\n",
       "   negativeIncrease  positiveIncrease  totalTestResultsIncrease  \\\n",
       "0            699089             46295                    745384   \n",
       "1            685099             46821                    731920   \n",
       "2            621696             43740                    665436   \n",
       "3            630559             44933                    675492   \n",
       "4            602356             40458                    642814   \n",
       "\n",
       "                                       hash  \n",
       "0  10f85ba760e3a61eb34ab55eb1ccc3ec21eed56f  \n",
       "1  cd07637ded4b265fc45cb2c204784d5cb8c70085  \n",
       "2  5e7ec5926f868e83e4fd901d5b6b7e3c0c9f161b  \n",
       "3  64c8b61e3c52baa7b1bcb0a6bbaa8dee87f3e71c  \n",
       "4  e41905ca050e7958f710b87063f436f7e8f1a9aa  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#covid_data = covid_data[['date','positive','death']]\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>total</th>\n",
       "      <th>totalTestResults</th>\n",
       "      <th>posNeg</th>\n",
       "      <th>deathIncrease</th>\n",
       "      <th>hospitalizedIncrease</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1228397478954795009</td>\n",
       "      <td>1228397478954795008</td>\n",
       "      <td>2020-02-14 19:15:56</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>14:15:56</td>\n",
       "      <td>EDT</td>\n",
       "      <td>143132365</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>NYC EMS Watch</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-14T00:00:00Z</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>28ded527706588122c2398a311e818b7473f77c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1228397478954795009</td>\n",
       "      <td>1228397478954795008</td>\n",
       "      <td>2020-02-14 19:15:56</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>14:15:56</td>\n",
       "      <td>EDT</td>\n",
       "      <td>143132365</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>NYC EMS Watch</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-14T00:00:00Z</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>28ded527706588122c2398a311e818b7473f77c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1228397478954795009</td>\n",
       "      <td>1228397478954795008</td>\n",
       "      <td>2020-02-14 19:15:56</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>14:15:56</td>\n",
       "      <td>EDT</td>\n",
       "      <td>143132365</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>NYC EMS Watch</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-14T00:00:00Z</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>28ded527706588122c2398a311e818b7473f77c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1231683951896383488</td>\n",
       "      <td>1231683951896383488</td>\n",
       "      <td>2020-02-23 20:55:12</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>15:55:12</td>\n",
       "      <td>EDT</td>\n",
       "      <td>44984619</td>\n",
       "      <td>bobfoolery</td>\n",
       "      <td>Bob Cooper</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-23T00:00:00Z</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1231683951896383488</td>\n",
       "      <td>1231683951896383488</td>\n",
       "      <td>2020-02-23 20:55:12</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>15:55:12</td>\n",
       "      <td>EDT</td>\n",
       "      <td>44984619</td>\n",
       "      <td>bobfoolery</td>\n",
       "      <td>Bob Cooper</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>2020-02-23T00:00:00Z</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id          created_at       date  \\\n",
       "0  1228397478954795009  1228397478954795008 2020-02-14 19:15:56 2020-02-14   \n",
       "1  1228397478954795009  1228397478954795008 2020-02-14 19:15:56 2020-02-14   \n",
       "2  1228397478954795009  1228397478954795008 2020-02-14 19:15:56 2020-02-14   \n",
       "3  1231683951896383488  1231683951896383488 2020-02-23 20:55:12 2020-02-23   \n",
       "4  1231683951896383488  1231683951896383488 2020-02-23 20:55:12 2020-02-23   \n",
       "\n",
       "       time timezone    user_id     username           name place  ...  \\\n",
       "0  14:15:56      EDT  143132365  nycemswatch  NYC EMS Watch        ...   \n",
       "1  14:15:56      EDT  143132365  nycemswatch  NYC EMS Watch        ...   \n",
       "2  14:15:56      EDT  143132365  nycemswatch  NYC EMS Watch        ...   \n",
       "3  15:55:12      EDT   44984619   bobfoolery     Bob Cooper        ...   \n",
       "4  15:55:12      EDT   44984619   bobfoolery     Bob Cooper        ...   \n",
       "\n",
       "           lastModified total totalTestResults posNeg  deathIncrease  \\\n",
       "0  2020-02-14T00:00:00Z    21               21     21              0   \n",
       "1  2020-02-14T00:00:00Z    21               21     21              0   \n",
       "2  2020-02-14T00:00:00Z    21               21     21              0   \n",
       "3  2020-02-23T00:00:00Z   122              122    122              0   \n",
       "4  2020-02-23T00:00:00Z   122              122    122              0   \n",
       "\n",
       "   hospitalizedIncrease  negativeIncrease positiveIncrease  \\\n",
       "0                     0                 0                3   \n",
       "1                     0                 0                3   \n",
       "2                     0                 0                3   \n",
       "3                     0                 0               16   \n",
       "4                     0                 0               16   \n",
       "\n",
       "  totalTestResultsIncrease                                      hash  \n",
       "0                        3  28ded527706588122c2398a311e818b7473f77c9  \n",
       "1                        3  28ded527706588122c2398a311e818b7473f77c9  \n",
       "2                        3  28ded527706588122c2398a311e818b7473f77c9  \n",
       "3                       16  bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7  \n",
       "4                       16  bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the two datasets for all Covid data in one place\n",
    "Master_Tweet_dataset = pd.merge(Master_Tweet_df,covid_data,on='date')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Unneeded Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnecessary columns\n",
    "\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['cashtags', 'conversation_id', 'hashtags',\n",
    "       'id','link', 'mentions', 'name', 'near', 'photos',\n",
    "       'place', 'quote_url','reply_to', 'retweet',\n",
    "       'retweet_date', 'retweet_id','source', 'time',\n",
    "       'timezone', 'trans_dest', 'trans_src', 'translate','urls',\n",
    "       'user_id', 'user_rt', 'user_rt_id',],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'tweet', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'video', 'geo', 'states', 'positive', 'negative',\n",
       "       'pending', 'hospitalizedCurrently', 'hospitalizedCumulative',\n",
       "       'inIcuCurrently', 'inIcuCumulative', 'onVentilatorCurrently',\n",
       "       'onVentilatorCumulative', 'recovered', 'dateChecked', 'death',\n",
       "       'hospitalized', 'lastModified', 'total', 'totalTestResults', 'posNeg',\n",
       "       'deathIncrease', 'hospitalizedIncrease', 'negativeIncrease',\n",
       "       'positiveIncrease', 'totalTestResultsIncrease', 'hash'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install textfeatures\n",
    "#Getting ride of duplicative column\n",
    "Master_Tweet_dataset=Master_Tweet_dataset.drop('created_at',axis=1)\n",
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>video</th>\n",
       "      <th>geo</th>\n",
       "      <th>states</th>\n",
       "      <th>positive</th>\n",
       "      <th>...</th>\n",
       "      <th>negativeIncrease</th>\n",
       "      <th>positiveIncrease</th>\n",
       "      <th>totalTestResultsIncrease</th>\n",
       "      <th>hash</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>Everything you need to know about AMR right he...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>28ded527706588122c2398a311e818b7473f77c9</td>\n",
       "      <td>37</td>\n",
       "      <td>9.780488</td>\n",
       "      <td>12</td>\n",
       "      <td>442</td>\n",
       "      <td>[you, to, about, who, for, have, after, a, wit...</td>\n",
       "      <td>everything need know right emts work american ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>Everything you need to know about AMR right he...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>28ded527706588122c2398a311e818b7473f77c9</td>\n",
       "      <td>37</td>\n",
       "      <td>9.780488</td>\n",
       "      <td>12</td>\n",
       "      <td>442</td>\n",
       "      <td>[you, to, about, who, for, have, after, a, wit...</td>\n",
       "      <td>everything need know right emts work american ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>nycemswatch</td>\n",
       "      <td>Everything you need to know about AMR right he...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>28ded527706588122c2398a311e818b7473f77c9</td>\n",
       "      <td>37</td>\n",
       "      <td>9.780488</td>\n",
       "      <td>12</td>\n",
       "      <td>442</td>\n",
       "      <td>[you, to, about, who, for, have, after, a, wit...</td>\n",
       "      <td>everything need know right emts work american ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>bobfoolery</td>\n",
       "      <td>If/when COVID-19 becomes epidemic in the Unite...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7</td>\n",
       "      <td>46</td>\n",
       "      <td>5.021739</td>\n",
       "      <td>15</td>\n",
       "      <td>276</td>\n",
       "      <td>[in, the, will, down, as, has, been, in, and, ...</td>\n",
       "      <td>ifwhen covid becomes epidemic united states am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>bobfoolery</td>\n",
       "      <td>If/when COVID-19 becomes epidemic in the Unite...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7</td>\n",
       "      <td>46</td>\n",
       "      <td>5.021739</td>\n",
       "      <td>15</td>\n",
       "      <td>276</td>\n",
       "      <td>[in, the, will, down, as, has, been, in, and, ...</td>\n",
       "      <td>ifwhen covid becomes epidemic united states am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     username                                              tweet  \\\n",
       "0 2020-02-14  nycemswatch  Everything you need to know about AMR right he...   \n",
       "1 2020-02-14  nycemswatch  Everything you need to know about AMR right he...   \n",
       "2 2020-02-14  nycemswatch  Everything you need to know about AMR right he...   \n",
       "3 2020-02-23   bobfoolery  If/when COVID-19 becomes epidemic in the Unite...   \n",
       "4 2020-02-23   bobfoolery  If/when COVID-19 becomes epidemic in the Unite...   \n",
       "\n",
       "   replies_count  retweets_count  likes_count  video geo  states  positive  \\\n",
       "0              3              12           15      0           2        21   \n",
       "1              3              12           15      0           2        21   \n",
       "2              3              12           15      0           2        21   \n",
       "3              0               0            0      0           2       122   \n",
       "4              0               0            0      0           2       122   \n",
       "\n",
       "   ...  negativeIncrease  positiveIncrease  totalTestResultsIncrease  \\\n",
       "0  ...                 0                 3                         3   \n",
       "1  ...                 0                 3                         3   \n",
       "2  ...                 0                 3                         3   \n",
       "3  ...                 0                16                        16   \n",
       "4  ...                 0                16                        16   \n",
       "\n",
       "                                       hash  word_count  avg_word_length  \\\n",
       "0  28ded527706588122c2398a311e818b7473f77c9          37         9.780488   \n",
       "1  28ded527706588122c2398a311e818b7473f77c9          37         9.780488   \n",
       "2  28ded527706588122c2398a311e818b7473f77c9          37         9.780488   \n",
       "3  bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7          46         5.021739   \n",
       "4  bbd18b10d469b0a14ea8b7eb24edf43527c8fbb7          46         5.021739   \n",
       "\n",
       "   stopwords_count  char_count  \\\n",
       "0               12         442   \n",
       "1               12         442   \n",
       "2               12         442   \n",
       "3               15         276   \n",
       "4               15         276   \n",
       "\n",
       "                                           stopwords  \\\n",
       "0  [you, to, about, who, for, have, after, a, wit...   \n",
       "1  [you, to, about, who, for, have, after, a, wit...   \n",
       "2  [you, to, about, who, for, have, after, a, wit...   \n",
       "3  [in, the, will, down, as, has, been, in, and, ...   \n",
       "4  [in, the, will, down, as, has, been, in, and, ...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  everything need know right emts work american ...  \n",
       "1  everything need know right emts work american ...  \n",
       "2  everything need know right emts work american ...  \n",
       "3  ifwhen covid becomes epidemic united states am...  \n",
       "4  ifwhen covid becomes epidemic united states am...  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using textfeatures library text preprocessing\n",
    "tf.word_count(Master_Tweet_dataset,\"tweet\",'word_count')\n",
    "tf.avg_word_length(Master_Tweet_dataset,'tweet','avg_word_length')\n",
    "tf.stopwords_count(Master_Tweet_dataset,'tweet','stopwords_count')\n",
    "tf.char_count(Master_Tweet_dataset,'tweet','char_count')\n",
    "tf.stopwords(Master_Tweet_dataset,'tweet','stopwords')\n",
    "tf.clean(Master_Tweet_dataset,'tweet','clean_text')\n",
    "Master_Tweet_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the Corpus\n",
    "\n",
    "clean_tweet = Master_Tweet_dataset['clean_text']\n",
    "#Tweet Tokenizer \n",
    "\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "#corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "#corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in clean_tweet:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tok list or later use\n",
    "\n",
    "with open('tok_corp_8_8.pickle','wb') as f:\n",
    "    pickle.dump(tok_corp,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis - adding Sentiment rating to each tweet\n",
    "\n",
    "#from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "tweets = Master_Tweet_dataset['clean_text']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "    #Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "    #sentiment = Classifier.predict_proba(tweet)\n",
    "    blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "    rating = blob.sentiment.polarity\n",
    "    Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_dataset['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fit12P9FHnHD",
    "outputId": "1c50c4c5-7eef-4a42-9e67-35b71e045df6"
   },
   "outputs": [],
   "source": [
    "#Saving as CSV for later uploads to different notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_dataset_textprocessing.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Poll Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading Poll data\n",
    "poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "poll_data = poll_data.dropna()\n",
    "\n",
    "#Converting Date columns to integer so merge will work\n",
    "Master_Tweet_dataset['date'] = pd.to_datetime(Master_Tweet_dataset['date'])\n",
    "Master_Tweet_dataset['date'] = Master_Tweet_dataset['date'].astype(int)\n",
    "poll_data['date'] = pd.to_datetime(poll_data['date'])\n",
    "poll_data['date'] = poll_data['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging with Poll Data\n",
    "\n",
    "#poll_data = pd.read_csv('data/poll_data_dates.csv')\n",
    "#pd.to_datetime(poll_data['Date']) #converting to datetime object for merge purposes\n",
    "#pd.to_datetime(Master_Tweet_df['Date']) #converting to datetime object for merge purposes\n",
    "\n",
    "left = Master_Tweet_dataset.sort_values(by='date')\n",
    "right = poll_data.sort_values(by='date')\n",
    "\n",
    "Master_Tweet_dataset = pd.merge_asof(left,right,on='date',allow_exact_matches=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master_Tweet_df = Master_Tweet_df.drop('Date')\n",
    "#Master_Tweet_df = Master_Tweet_df.drop('Date',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Target Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this project, our goal is to see if we can classify how individuals view the response to the Covid pandemic in the United States. The below cells group the tweets into 10 topic with use of a Latent Dirichlet Allocation model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Victory Spread\n",
    "Master_Tweet_dataset['Spread'] = Master_Tweet_dataset['Biden (D)'] - Master_Tweet_dataset['Trump (R)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assiging topics to each tweet  -code inspired by stackabuse\n",
    "\n",
    "\n",
    "#Vectorizing docs\n",
    "#count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "#doc_term_matrix = count_vect.fit_transform(clean_tweet)\n",
    "\n",
    "#fitting LDA Model\n",
    "\n",
    "#LDA = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "tweet_lda_model = pickle.load(open('LDA_model.pickle','rb'))\n",
    "\n",
    "#saving LDA Model\n",
    "#pickle.dump(LDA_model_8_22, open( 'LDA_model_8_22.pickle', 'wb') )\n",
    "\n",
    "\n",
    "#transforming to get topic numbers\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape\n",
    "\n",
    "#creating column of Topics\n",
    "Master_Tweet_dataset['Topic'] = topic_values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.030*\"great\" + 0.020*\"complete\" + 0.019*\"total\" + 0.018*\"endorsement\" + 0.017*\"russia\" + 0.017*\"strong\" + 0.016*\"military\" + 0.016*\"south\" + 0.015*\"india\" + 0.013*\"need\"\n",
      "\n",
      "1: 0.023*\"great\" + 0.014*\"border\" + 0.011*\"foxnews\" + 0.009*\"canada\" + 0.009*\"york\" + 0.008*\"testing\" + 0.008*\"today\" + 0.008*\"closed\" + 0.007*\"keep\" + 0.007*\"borders\"\n",
      "\n",
      "2: 0.034*\"trump\" + 0.017*\"president\" + 0.016*\"people\" + 0.015*\"great\" + 0.010*\"would\" + 0.010*\"americans\" + 0.009*\"nothing\" + 0.009*\"america\" + 0.009*\"good\" + 0.008*\"like\"\n",
      "\n",
      "3: 0.036*\"news\" + 0.032*\"fake\" + 0.017*\"world\" + 0.016*\"media\" + 0.014*\"country\" + 0.014*\"people\" + 0.014*\"like\" + 0.012*\"dont\" + 0.009*\"please\" + 0.008*\"trump\"\n",
      "\n",
      "4: 0.029*\"countries\" + 0.023*\"death\" + 0.020*\"rate\" + 0.009*\"italy\" + 0.009*\"brazil\" + 0.009*\"virus\" + 0.009*\"deaths\" + 0.009*\"perspective\" + 0.009*\"much\" + 0.008*\"germany\"\n",
      "\n",
      "5: 0.033*\"thank\" + 0.020*\"house\" + 0.017*\"white\" + 0.014*\"people\" + 0.012*\"coronavirus\" + 0.011*\"party\" + 0.010*\"workers\" + 0.010*\"country\" + 0.010*\"democrats\" + 0.009*\"care\"\n",
      "\n",
      "6: 0.014*\"pandemic\" + 0.013*\"coronavirus\" + 0.009*\"schools\" + 0.009*\"hospital\" + 0.009*\"news\" + 0.008*\"days\" + 0.008*\"health\" + 0.008*\"conference\" + 0.007*\"positive\" + 0.006*\"students\"\n",
      "\n",
      "7: 0.031*\"china\" + 0.021*\"virus\" + 0.016*\"people\" + 0.013*\"many\" + 0.011*\"mike\" + 0.009*\"patients\" + 0.008*\"still\" + 0.007*\"know\" + 0.007*\"dont\" + 0.006*\"world\"\n",
      "\n",
      "8: 0.086*\"cases\" + 0.062*\"deaths\" + 0.023*\"world\" + 0.020*\"number\" + 0.020*\"million\" + 0.015*\"states\" + 0.014*\"trump\" + 0.011*\"population\" + 0.011*\"people\" + 0.011*\"coronavirus\"\n",
      "\n",
      "9: 0.024*\"time\" + 0.015*\"mask\" + 0.015*\"democrats\" + 0.014*\"social\" + 0.011*\"full\" + 0.011*\"ever\" + 0.011*\"want\" + 0.011*\"people\" + 0.010*\"opinion\" + 0.010*\"economy\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Getting topics\n",
    "num_topics = 10\n",
    "for i,topic in tweet_lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to create Target Column\n",
    "category_dict = {}\n",
    "for key in [0,4,5,8,1,3]:\n",
    "    category_dict[key] = 'Bad Response'\n",
    "for key in [10,6,2,7,9]:\n",
    "    category_dict[key] = 'Good Response'\n",
    "    \n",
    "#Creation of Target Column\n",
    "Master_Tweet_dataset['Target'] = Master_Tweet_dataset['Topic'].map(category_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final DF Housekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'username', 'tweet', 'replies_count', 'retweets_count',\n",
       "       'likes_count', 'video', 'geo', 'states', 'positive', 'negative',\n",
       "       'pending', 'hospitalizedCurrently', 'hospitalizedCumulative',\n",
       "       'inIcuCurrently', 'inIcuCumulative', 'onVentilatorCurrently',\n",
       "       'onVentilatorCumulative', 'recovered', 'dateChecked', 'death',\n",
       "       'hospitalized', 'lastModified', 'total', 'totalTestResults', 'posNeg',\n",
       "       'deathIncrease', 'hospitalizedIncrease', 'negativeIncrease',\n",
       "       'positiveIncrease', 'totalTestResultsIncrease', 'hash', 'word_count',\n",
       "       'avg_word_length', 'stopwords_count', 'char_count', 'stopwords',\n",
       "       'clean_text', 'Sentiment', 'Poll', 'Start Date', 'End Date', 'Sample',\n",
       "       'MoE', 'Biden (D)', 'Trump (R)', 'Spread', 'Topic', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_df = Master_Tweet_dataset.copy()\n",
    "EDA_df.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe for just text data\n",
    "#Tweet_df = Master_Tweet_dataset[['date','tweet','stopwords','clean_text']]\n",
    "#creating dataframe for poll data \n",
    "#Poll_df = Master_Tweet_dataset[['Start Date','End Date','Sample','MoE','Poll','Biden (D)', 'Trump (R)']]\n",
    "\n",
    "\n",
    "# couldn't find any value from these columns\n",
    "Master_Tweet_dataset = Master_Tweet_dataset.drop(['tweet','Poll',\n",
    "       'Start Date', 'End Date', 'Sample', 'MoE',\n",
    "       ],axis=1)\n",
    "\n",
    "#converting date column to integer for modeling purposes\n",
    "#def datetime_to_int(dt):\n",
    "    #return int(dt.strftime(\"%Y%m%d\"))\n",
    "\n",
    "#Master_Tweet_dataset['date'] = Master_Tweet_df['date'].apply(lambda x: datetime_to_int(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1580601600000000000\n",
       "1        1580601600000000000\n",
       "2        1580688000000000000\n",
       "3        1580688000000000000\n",
       "4        1581638400000000000\n",
       "                ...         \n",
       "24676    1597881600000000000\n",
       "24677    1597881600000000000\n",
       "24678    1597881600000000000\n",
       "24679    1597881600000000000\n",
       "24680    1597881600000000000\n",
       "Name: date, Length: 24681, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making sure date is ok for modeling\n",
    "Master_Tweet_dataset['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "Master_Tweet_dataset.isnull().sum()\n",
    "Master_Tweet_dataset['death'] = Master_Tweet_dataset['death'].fillna(method='backfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Master_Tweet_dataset.to_csv('data/data_8_08.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving df to csv for upload in other notebooks\n",
    "Master_Tweet_dataset.to_csv('data/Master_Tweet_modelready.csv')\n",
    "#Tweet_df.to_csv('data/Tweet_text_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24681"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Master_Tweet_dataset['Target'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
