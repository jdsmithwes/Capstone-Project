{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaLJG7wss5zY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8idLC0ams5zc"
   },
   "source": [
    "## Objective\n",
    "\n",
    "For the purpose of this analysis, I will attempt to measure the sentiment of tweets to learn whether tweets impact the number of Covid-19 cases and deaths in the United States. This study is important as the reopening of our society, from going to get an ice cream cone to being able to earn a living, hinges on our ability to lower the rate of infection in our country. With so many individuals receiving their news and information through social media, being able to predict how COVID cases will either increase or decrease based on tweets can inform public policy. Should we be able to predict the future number of COVID cases based on the text of tweets; public officials, business leaders and concerned citizens can alter their tweeting practices to promote improved COVID outcomes.\n",
    "\n",
    "To create the dataset, I utilized the TWINT library to collect all tweets from January 1,2020 until July 10th. I then made various subsets of the tweets. For example, to measure the impact of tweets by public leaders viewed as polar opposites regarding their response to the pandemic, I collected tweets by President Trump and the Governor of New York, Andrew Cuomo. Another subset of tweets that I labeled as baseline consists of tweets by the New York Times and Washington Post - two of America's leading journalism outlets.\n",
    "\n",
    "The purpose of creating these subsets is that the baseline tweets can be considered to be those that communicate mainly fact. While they might have op-ed columnists, we can assume that most tweets from the news reporting divisions will provide factual updates on the Covid response. By considering the two polar opposites, Trump and Cuomo, we can measure Covid outcomes, in terms of cases, after the tweets have been consumed by the public. Finally, the main Covid collection will allow us to see whether more individuals subscribed to the Trump/Cuomo tweets and how Covid cases changed, for the positive or negative, in their region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDKGyLuus5zd"
   },
   "source": [
    "## Obtaining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTTYzZqes5zd"
   },
   "source": [
    "For the notebooks that contain the queries for the tweets gathered on TWINT, please refer to the Covid Data Queries notebook in the repo. The JSON files for these queries were used to create DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXOlmeqns5ze"
   },
   "outputs": [],
   "source": [
    "#All Covid tweets\n",
    "All_Covid_tweets = pd.read_json('Covid_tweets3.json',lines=True)\n",
    "\n",
    "#All Trump tweets\n",
    "Trump_Covid_tweets = pd.read_json('Trump_Covid_tweets3.json', lines=True)\n",
    "\n",
    "#All Cuomo tweets\n",
    "Cuomo_Covid_tweets = pd.read_json('Cuomo_Covid_tweets3.json',lines=True)\n",
    "\n",
    "#Baseline Tweets\n",
    "NYTimes_tweets = pd.read_json('Nytimes_Covid_tweets3.json',lines=True)\n",
    "#print( len(NYTimes_tweets))\n",
    "WashingtonPost_tweets = pd.read_json('Washpost_tweets3.json',lines=True)\n",
    "#print( len(Washpost_tweets3.json))\n",
    "\n",
    "#combining NYTimes and Washington Post to get Baseline Tweets\n",
    "Baseline_tweets = pd.concat([NYTimes_tweets,WashingtonPost_tweets],axis=0)\n",
    "\n",
    "#Reformatting Date columns for later merge\n",
    "All_Covid_tweets['Date'] = All_Covid_tweets['date']\n",
    "Trump_Covid_tweets['Date'] = Trump_Covid_tweets['date']\n",
    "Cuomo_Covid_tweets['Date'] = Cuomo_Covid_tweets['date']\n",
    "Baseline_tweets['Date'] = Baseline_tweets['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNW39ui7s5zh"
   },
   "source": [
    "Data for Covid Cases and Deaths was collected from The COVID Tracking Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jtAcw-ss5zi"
   },
   "outputs": [],
   "source": [
    "# Covid data set\n",
    "\n",
    "covid_cases = pd.read_csv('time_series_covid_19_confirmed.csv')\n",
    "\n",
    "#Getting US data - confirmed cases\n",
    "covid_cases = covid_cases[covid_cases['Country/Region'] == 'US']\n",
    "#covid_cases = covid_cases.transpose()\n",
    "\n",
    "# Covid death data set\n",
    "\n",
    "covid_deaths = pd.read_csv('time_series_covid_19_deaths.csv')\n",
    "\n",
    "\n",
    "#Getting US data - confirmed cases\n",
    "\n",
    "#covid_deaths = covid_deaths.transpose()\n",
    "covid_deaths = covid_deaths[covid_deaths['Country/Region'] == 'US']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oRKml9Cs5zl"
   },
   "outputs": [],
   "source": [
    "#Covid cases and deaths (still need to rename columns, from left to right = cases then deaths)\n",
    "covid_data = pd.concat([covid_cases,covid_deaths],axis=0)\n",
    "covid_data = covid_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vb5bh9Gs5zq"
   },
   "outputs": [],
   "source": [
    "covid_data = covid_data.drop(['Province/State','Country/Region','Lat','Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4AKkXwKPs5zu",
    "outputId": "d3bde4d5-bd0f-4d73-98e5-d2a634a36133"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>225</th>\n",
       "      <th>225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/22/20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/23/20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/24/20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/25/20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/26/20</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        225 225\n",
       "1/22/20   1   0\n",
       "1/23/20   1   0\n",
       "1/24/20   2   0\n",
       "1/25/20   2   0\n",
       "1/26/20   5   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbbEt4Ijs5zy"
   },
   "source": [
    "### Adding Case/Death Data on Day of the Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "tLy93bv3s5zy",
    "outputId": "730324d9-1f09-48f7-dc54-a0e29b917be0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date  Cases  Deaths\n",
       "0  1/22/20      1       0\n",
       "1  1/23/20      1       0\n",
       "2  1/24/20      2       0\n",
       "3  1/25/20      2       0\n",
       "4  1/26/20      5       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Edited column names in Excel for Merge\n",
    "covid_data_formatted = pd.read_excel('covid_data_date.xlsx')\n",
    "covid_data_formatted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKVwUotFs5z2"
   },
   "outputs": [],
   "source": [
    "#Converting all Date columns to datetime for Merge\n",
    "covid_data_formatted['Date'] = pd.to_datetime(covid_data_formatted['Date'])\n",
    "All_Covid_tweets['Date'] = pd.to_datetime(All_Covid_tweets['Date'])\n",
    "Trump_Covid_tweets['Date'] = pd.to_datetime(Trump_Covid_tweets['Date'])\n",
    "Cuomo_Covid_tweets['Date'] = pd.to_datetime(Cuomo_Covid_tweets['Date'])\n",
    "Baseline_tweets['Date'] = pd.to_datetime(Baseline_tweets['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zt7s9ym9s5z4"
   },
   "outputs": [],
   "source": [
    "#All Tweet Data with corresponding case/death information\n",
    "All_Covid_tweets_case_data = pd.merge(All_Covid_tweets,covid_data_formatted,on='Date')\n",
    "#Trump Tweet Data with corresponding case/death information\n",
    "Trump_Covid_tweets_case_data = pd.merge(Trump_Covid_tweets,covid_data_formatted,on='Date')\n",
    "#Cuomo Tweet Data with corresponding case/death information\n",
    "Cuomo_Covid_tweets_case_data = pd.merge(Cuomo_Covid_tweets,covid_data_formatted, on='Date')\n",
    "#Baseline Tweet Data with corresponding case/death information\n",
    "Baseline_tweets_case_data = pd.merge(Baseline_tweets,covid_data_formatted,on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VU19K6Bss5z7"
   },
   "source": [
    "### Adding case/death data for two weeks after original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DgQEpVVQs5z7"
   },
   "outputs": [],
   "source": [
    "#Getting date two weeks from now for Covid case/death reaction to Tweets\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "N = 14\n",
    "days_N_from_now = All_Covid_tweets['Date'] + timedelta(days=N)\n",
    "\n",
    "All_Covid_tweets_case_data['14 days'] = (All_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Trump_Covid_tweets_case_data['14 days'] = (Trump_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Cuomo_Covid_tweets_case_data['14 days'] = (Cuomo_Covid_tweets_case_data['Date'] +timedelta(days=N))\n",
    "Baseline_tweets_case_data['14 days'] = (Baseline_tweets_case_data['Date'] + timedelta(days=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dtrDv-Z3s5z-",
    "outputId": "c848bcd8-253c-4769-f52a-a66f65599725"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   14 days  Cases  Deaths\n",
       "0  1/22/20      1       0\n",
       "1  1/23/20      1       0\n",
       "2  1/24/20      2       0\n",
       "3  1/25/20      2       0\n",
       "4  1/26/20      5       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data_two_week = pd.read_excel('covid_data_14days.xlsx')\n",
    "covid_data_two_week.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt7wqyBDs50B"
   },
   "outputs": [],
   "source": [
    "#Converting all Date columns to datetime for Merge\n",
    "covid_data_two_week['14 days'] = pd.to_datetime(covid_data_two_week['14 days'])\n",
    "All_Covid_tweets_case_data['14 days'] = pd.to_datetime(All_Covid_tweets_case_data['14 days'])\n",
    "Trump_Covid_tweets_case_data['14 days'] = pd.to_datetime(Trump_Covid_tweets_case_data['14 days'])\n",
    "Cuomo_Covid_tweets_case_data['14 days'] = pd.to_datetime(Cuomo_Covid_tweets_case_data['14 days'])\n",
    "Baseline_tweets_case_data['14 days'] = pd.to_datetime(Baseline_tweets_case_data['14 days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZg-y80ks50D"
   },
   "outputs": [],
   "source": [
    "#All Tweet Data with corresponding case/death information\n",
    "All_Covid_tweets_case_data = pd.merge(All_Covid_tweets_case_data,covid_data_two_week,on='14 days')\n",
    "#Trump Tweet Data with corresponding case/death information\n",
    "Trump_Covid_tweets_case_data = pd.merge(Trump_Covid_tweets_case_data,covid_data_two_week,on='14 days')\n",
    "#Cuomo Tweet Data with corresponding case/death information\n",
    "Cuomo_Covid_tweets_case_data = pd.merge(Cuomo_Covid_tweets_case_data,covid_data_two_week, on='14 days')\n",
    "#Baseline Tweet Data with corresponding case/death information\n",
    "Baseline_tweets_case_data = pd.merge(Baseline_tweets_case_data,covid_data_two_week,on='14 days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZYqxwBBs50F"
   },
   "source": [
    "### Adding Case/Death Data for four weeks after original tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lR8d_K6Vs50G",
    "outputId": "103cedb8-28bf-4f74-bf8b-c7235558a44c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/22/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/23/20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/24/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/25/20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/26/20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   28 days  Cases  Deaths\n",
       "0  1/22/20      1       0\n",
       "1  1/23/20      1       0\n",
       "2  1/24/20      2       0\n",
       "3  1/25/20      2       0\n",
       "4  1/26/20      5       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_data_four_week = pd.read_excel('covid_data_28days.xlsx')\n",
    "covid_data_four_week.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Dates and COVID Data for two weeks after Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDBDBj6is50K"
   },
   "outputs": [],
   "source": [
    "#Getting date two weeks from now for Covid case/death reaction to Tweets\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "N = 28\n",
    "days_N_from_now = All_Covid_tweets['Date'] + timedelta(days=N)\n",
    "\n",
    "All_Covid_tweets_case_data['28 days'] = (All_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Trump_Covid_tweets_case_data['28 days'] = (Trump_Covid_tweets_case_data['Date'] + timedelta(days=N))\n",
    "Cuomo_Covid_tweets_case_data['28 days'] = (Cuomo_Covid_tweets_case_data['Date'] +timedelta(days=N))\n",
    "Baseline_tweets_case_data['28 days'] = (Baseline_tweets_case_data['Date'] + timedelta(days=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gJcO0yP3s50M"
   },
   "outputs": [],
   "source": [
    "#Converting all Date columns to datetime for Merge\n",
    "covid_data_four_week['28 days'] = pd.to_datetime(covid_data_four_week['28 days'])\n",
    "All_Covid_tweets_case_data['28 days'] = pd.to_datetime(All_Covid_tweets_case_data['28 days'])\n",
    "Trump_Covid_tweets_case_data['28 days'] = pd.to_datetime(Trump_Covid_tweets_case_data['28 days'])\n",
    "Cuomo_Covid_tweets_case_data['28 days'] = pd.to_datetime(Cuomo_Covid_tweets_case_data['28 days'])\n",
    "Baseline_tweets_case_data['28 days'] = pd.to_datetime(Baseline_tweets_case_data['28 days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nz5ts71ws50O"
   },
   "outputs": [],
   "source": [
    "#All Tweet Data with corresponding case/death information\n",
    "All_Covid_tweets_case_data = pd.merge(All_Covid_tweets_case_data,covid_data_four_week,on='28 days')\n",
    "#Trump Tweet Data with corresponding case/death information\n",
    "Trump_Covid_tweets_case_data = pd.merge(Trump_Covid_tweets_case_data,covid_data_four_week,on='28 days')\n",
    "#Cuomo Tweet Data with corresponding case/death information\n",
    "Cuomo_Covid_tweets_case_data = pd.merge(Cuomo_Covid_tweets_case_data,covid_data_four_week, on='28 days')\n",
    "#Baseline Tweet Data with corresponding case/death information\n",
    "Baseline_tweets_case_data = pd.merge(Baseline_tweets_case_data,covid_data_four_week,on='28 days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "id": "EwN_4RC8s50R",
    "outputId": "e7ef582c-cbac-4f2f-bfc1-01f3171ac4af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cashtags</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>geo</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>link</th>\n",
       "      <th>mentions</th>\n",
       "      <th>...</th>\n",
       "      <th>video</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cases_x</th>\n",
       "      <th>Deaths_x</th>\n",
       "      <th>14 days</th>\n",
       "      <th>Cases_y</th>\n",
       "      <th>Deaths_y</th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270707306578264064</td>\n",
       "      <td>2020-06-10 13:20:05</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270707306578264065</td>\n",
       "      <td>209</td>\n",
       "      <td>https://twitter.com/nytimes/status/12707073065...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2000702</td>\n",
       "      <td>113631</td>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>2382426</td>\n",
       "      <td>122604</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>3054699</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270636833555308544</td>\n",
       "      <td>2020-06-10 08:40:03</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270636833555308544</td>\n",
       "      <td>857</td>\n",
       "      <td>https://twitter.com/nytimes/status/12706368335...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2000702</td>\n",
       "      <td>113631</td>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>2382426</td>\n",
       "      <td>122604</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>3054699</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270815442173603840</td>\n",
       "      <td>2020-06-10 20:29:46</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270815442173603841</td>\n",
       "      <td>159</td>\n",
       "      <td>https://twitter.com/washingtonpost/status/1270...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>2000702</td>\n",
       "      <td>113631</td>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>2382426</td>\n",
       "      <td>122604</td>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>3054699</td>\n",
       "      <td>132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270541216308957184</td>\n",
       "      <td>2020-06-10 02:20:06</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270541216308957184</td>\n",
       "      <td>382</td>\n",
       "      <td>https://twitter.com/nytimes/status/12705412163...</td>\n",
       "      <td>[nytmag]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2996098</td>\n",
       "      <td>131480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>1270470755889840128</td>\n",
       "      <td>2020-06-09 21:40:07</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1270470755889840134</td>\n",
       "      <td>404</td>\n",
       "      <td>https://twitter.com/nytimes/status/12704707558...</td>\n",
       "      <td>[nytmag]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>2996098</td>\n",
       "      <td>131480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cashtags      conversation_id          created_at       date geo hashtags  \\\n",
       "0       []  1270707306578264064 2020-06-10 13:20:05 2020-06-10           []   \n",
       "1       []  1270636833555308544 2020-06-10 08:40:03 2020-06-10           []   \n",
       "2       []  1270815442173603840 2020-06-10 20:29:46 2020-06-10           []   \n",
       "3       []  1270541216308957184 2020-06-10 02:20:06 2020-06-09           []   \n",
       "4       []  1270470755889840128 2020-06-09 21:40:07 2020-06-09           []   \n",
       "\n",
       "                    id  likes_count  \\\n",
       "0  1270707306578264065          209   \n",
       "1  1270636833555308544          857   \n",
       "2  1270815442173603841          159   \n",
       "3  1270541216308957184          382   \n",
       "4  1270470755889840134          404   \n",
       "\n",
       "                                                link  mentions  ... video  \\\n",
       "0  https://twitter.com/nytimes/status/12707073065...        []  ...     0   \n",
       "1  https://twitter.com/nytimes/status/12706368335...        []  ...     0   \n",
       "2  https://twitter.com/washingtonpost/status/1270...        []  ...     0   \n",
       "3  https://twitter.com/nytimes/status/12705412163...  [nytmag]  ...     0   \n",
       "4  https://twitter.com/nytimes/status/12704707558...  [nytmag]  ...     0   \n",
       "\n",
       "        Date  Cases_x Deaths_x    14 days  Cases_y Deaths_y    28 days  \\\n",
       "0 2020-06-10  2000702   113631 2020-06-24  2382426   122604 2020-07-08   \n",
       "1 2020-06-10  2000702   113631 2020-06-24  2382426   122604 2020-07-08   \n",
       "2 2020-06-10  2000702   113631 2020-06-24  2382426   122604 2020-07-08   \n",
       "3 2020-06-09  1979908   112714 2020-06-23  2347491   121847 2020-07-07   \n",
       "4 2020-06-09  1979908   112714 2020-06-23  2347491   121847 2020-07-07   \n",
       "\n",
       "     Cases  Deaths  \n",
       "0  3054699  132300  \n",
       "1  3054699  132300  \n",
       "2  3054699  132300  \n",
       "3  2996098  131480  \n",
       "4  2996098  131480  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baseline_tweets_case_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7M1Xrmj6s50T"
   },
   "source": [
    "### Combined Tweet DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSKxZ74ys50T"
   },
   "outputs": [],
   "source": [
    "#Tweet dataframes combined\n",
    "\n",
    "Master_Tweet_df = pd.concat([All_Covid_tweets_case_data,Trump_Covid_tweets_case_data,Cuomo_Covid_tweets_case_data,Baseline_tweets_case_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing US State Data from NYTimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NYTimes manages a github repo that tracks state by state COVID Data. This data can be useful later in the analysis when we track how certain localities have fared dealing with the COVID pandemic. Tracking state COVID details will allow for examination of whether states that are classified as subscribing to the tenets of the Trump administrtion respond better/worse than states that might align more with the politics of NY governor Andrew Cuomo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data from CSV\n",
    "state_case_df = pd.read_csv('us-states.csv')\n",
    "\n",
    "#Groupby to get states by state\n",
    "state_case_df.groupby('state')\n",
    "\n",
    "state_case_df = state_case_df.sort_values(['state','date'],ascending=[True,True])\n",
    "#state_case_df = state_case_df.sort_values('date',ascending=True)\n",
    "state_case_df.reset_index(drop=True,inplace=True)\n",
    "#state_case_df = state_case_df.sort_values('date',ascending=True)\n",
    "#state_case_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGw1vL04BvRP"
   },
   "source": [
    "### SCRUBBING OF TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "j59_qMrRvdsd",
    "outputId": "66e8b2e4-4886-47a6-a562-ad29c97301c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jamaalsmith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Tweet scrubbing I used for Mod 4 project\n",
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "tweets = Master_Tweet_df['tweet']\n",
    "corpus = []\n",
    "twitter_list = ['mention','rt','link','sxsw','quot','downtown','austin']\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list = stopword_list + twitter_list\n",
    "for tweet in tweets:\n",
    "    tweet = re.sub('[^a-zA-Z]', ' ', tweet)\n",
    "    tweet = tweet.join([c for c in tweet if c not in punctuation])\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "    ps = PorterStemmer()\n",
    "    tweet = [word for word in tweet if not word in stopword_list]\n",
    "    tweet = ' '.join(tweet)\n",
    "    corpus.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6sV0YP6GQLt"
   },
   "outputs": [],
   "source": [
    "#additional scrubbing with assistance of preprocessor library\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import preprocess_documents\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.EMOJI, p.OPT.RESERVED, p.OPT.SMILEY, p.OPT.MENTION, p.OPT.HASHTAG, p.OPT.NUMBER)\n",
    "\n",
    "#Using preprocessor library to scrub tweets\n",
    "tweets = corpus\n",
    "\n",
    "clean_tweets = []\n",
    "for tweet in tweets:\n",
    "  clean = p.clean(tweet)\n",
    "  clean_tweets.append(clean)\n",
    "\n",
    "Master_Tweet_df['clean_tweets'] = clean_tweets\n",
    "\n",
    "#tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "#clean_tweets_stopwords_punc_lowercase = []\n",
    "\n",
    "#for tweet in tweets:\n",
    " #   clean = remove_stopwords(tweet)\n",
    " #   clean_tweets_stopwords_punc_lowercase.append(clean)\n",
    "\n",
    "#Master_Tweet_df['clean_tweets'] = clean_tweets_stopwords_punc_lowercase\n",
    "    \n",
    "#Removing white spaces, punctuation and apply lowercasing\n",
    "#Master_Tweet_df['clean_tweets'] = Master_Tweet_df['clean_tweets'].str.lower().str.replace('[^\\w\\s]',' ').str.replace('\\s\\s+', ' ')\n",
    "#tweets = Master_Tweet_df['clean_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ttwo united states leading news sources time u...\n",
       "1    ttwo united states leading news sources time u...\n",
       "2    unless u physician nurse surgical room busines...\n",
       "3    tthe reality andy beshear create covid spread ...\n",
       "4    iin large countries united states russia brazi...\n",
       "Name: clean_tweets, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Master_Tweet_df['clean_tweets'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords and punctuation\n",
    "\n",
    "#Tweet Tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "corpus = Master_Tweet_df['clean_tweets'].astype(str)\n",
    "corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in corpus:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "#from nltk.tokenize import word_tokenize \n",
    "  \n",
    "#example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "#stop_words = (stopwords.words('english'))\n",
    "  \n",
    "#word_tokens = (tok_corp) \n",
    "  \n",
    "#filtered_sentence = [token for token in word_tokens if not w in stop_words] \n",
    "  \n",
    "#filtered_sentence = [] \n",
    "  \n",
    "#for token in word_tokens: \n",
    " #   if token not in stop_words: \n",
    "  #      filtered_sentence.append(w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpAWXJlFHlGJ"
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis - utilize NTLK because it is better\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import PatternAnalyzer, NaiveBayesAnalyzer\n",
    "\n",
    "tweets = Master_Tweet_df['clean_tweets']\n",
    "\n",
    "Sentiment = []\n",
    "for tweet in tweets:\n",
    "  blob = TextBlob(tweet,analyzer=PatternAnalyzer())\n",
    "  rating = blob.sentiment\n",
    "  Sentiment.append(rating)\n",
    "\n",
    "Master_Tweet_df['Sentiment'] = Sentiment\n",
    "#Master_Tweet_df['Sentiment'] = Master_Tweet_df['Sentiment'].astype(int)\n",
    "#Master_Tweet_df['Sentiment'].round(decimals = 4)\n",
    "\n",
    "#Master_Tweet_df['Sentiment'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fit12P9FHnHD",
    "outputId": "1c50c4c5-7eef-4a42-9e67-35b71e045df6"
   },
   "outputs": [],
   "source": [
    "#Master_Tweet_df['clean_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame with less metadata and additional details on COVID case data after tweet date\n",
    "Sentiment_Tweet_df = Master_Tweet_df[['created_at','date','username','likes_count','retweet_date','clean_tweets','Cases_x','Deaths_x','14 days','Cases_y','Deaths_y','28 days','Cases','Deaths','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>Cases_x</th>\n",
       "      <th>Deaths_Tweet</th>\n",
       "      <th>14 days</th>\n",
       "      <th>Cases_14</th>\n",
       "      <th>Deaths_14</th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases_48</th>\n",
       "      <th>Deaths_48</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ttwo united states leading news sources time u...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ttwo united states leading news sources time u...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>unless u physician nurse surgical room busines...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-26 23:00:14</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>nealhead</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>tthe reality andy beshear create covid spread ...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.3458333333333324)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-26 22:34:09</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>6121el</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>iin large countries united states russia brazi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.026984126984127076, 0.36507936507936345)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-26 22:22:16</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>roswell32</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>rright good look president united states leadi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.23668098818474678, 0.6895005370569313)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-26 21:57:10</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>gary_lyman</td>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>uunited states officially surpassed grim miles...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.332727272727271, 0.6409090909090938)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-26 21:13:57</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>oldnavy1968</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>tthe united states confirmed covid cases next ...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.10000000000000034, 0.375)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-05-26 20:45:24</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>dablazinjr</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>tthe average age deceased covid positive patie...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.09242424242424296, 0.38181818181817945)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-05-26 18:15:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>smartpe53402672</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>yyou stupidest people get paid stupidity one c...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.5666666666666745, 0.7666666666666659)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-05-26 16:32:14</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>craving_filled</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>hhow come south korea united states saw first ...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.27500000000000013, 0.666666666666665)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-05-26 12:45:53</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>hsquared_studio</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ssays said united states one fifteen covid cas...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.5999999999999965, 0.5999999999999965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-05-26 12:41:10</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>jimmyfalco2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ii making political studies shown hcq effectiv...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.17499999999999838, 0.5000000000000066)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-05-26 12:28:42</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>ralfstein3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>wwhile united states still puzzling whether ma...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-05-26 12:00:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>crawfordstuff</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>iit likely today reach deaths united states co...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.25, 0.75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-05-26 10:54:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>sallybeatty6</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>aand guy running world health organization wan...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.20000000000000082, 0.10000000000000041)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-05-26 10:54:05</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>outbreaksci</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>ccontribute rapid review request one geographi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-05-26 06:58:42</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>natsumugikezine</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>japan part regions tokyo osaka accepts ems del...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.041666666666666664, 0.375)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-05-26 04:06:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>wadetheleopard</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>llet assume worst moment covid hits time worst...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.17499999999999963, 0.8125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>unless u physician nurse surgical room busines...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-05-26 22:22:16</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>roswell32</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>rright good look president united states leadi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.23668098818474678, 0.6895005370569313)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-05-26 18:15:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>smartpe53402672</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>yyou stupidest people get paid stupidity one c...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.5666666666666745, 0.7666666666666659)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-05-27 03:27:48</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>parkerrobertda1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>wwell covid people still behaving badly newyor...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.549999999999997, 0.6333333333333361)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-05-27 02:23:48</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>gregggraison</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>hhow people ignorant rude nasty knowing fact m...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.20571428571428674, 0.5057142857142859)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-05-27 02:01:55</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>dianepaul</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>ii heartbroken america much racism much exploi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.010714285714285796, 0.3559523809523809)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-05-27 01:58:29</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>art_muela</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ii understand people biased towards russia bai...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.625, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-05-27 01:05:41</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>jfdorville</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>en covid tcgnrg map despite confirmed covid ca...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.07142857142857163, 0.9523809523809527)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-05-26 23:44:03</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>thesteveholzer</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>sspent today joebiden talked covid response la...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.06372141372141397, 0.26891891891891906)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-05-26 23:32:53</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>b1louder</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ddo desert navajonation america covid times an...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.3499999999999986, 0.6500000000000034)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>unless u physician nurse surgical room busines...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2020-03-19 10:28:18</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>1431</td>\n",
       "      <td></td>\n",
       "      <td>get corona get corona miami spring breakers sa...</td>\n",
       "      <td>14157</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>669272</td>\n",
       "      <td>35442</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>2020-03-18 17:21:07</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>212</td>\n",
       "      <td></td>\n",
       "      <td>hhow world political artists depicting covid p...</td>\n",
       "      <td>8917</td>\n",
       "      <td>188</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>214205</td>\n",
       "      <td>6846</td>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>637974</td>\n",
       "      <td>33329</td>\n",
       "      <td>(0.0, 0.09999999999999981)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>2020-03-17 03:25:59</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>183</td>\n",
       "      <td></td>\n",
       "      <td>oopinion life time covid totally unprecedented...</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>(0.600000000000001, 0.9000000000000001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>2020-03-16 17:51:04</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>525</td>\n",
       "      <td></td>\n",
       "      <td>aadditionally scientists still know sure survi...</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>(0.08333333333333465, 0.41481481481481497)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>2020-03-16 17:44:10</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>189</td>\n",
       "      <td></td>\n",
       "      <td>iit depends unknown characteristics virus expr...</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>(-0.08596491228070205, 0.5943859649122778)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>2020-03-16 15:22:37</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>133</td>\n",
       "      <td></td>\n",
       "      <td>oone last party one last dance goodbye college...</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>(0.0, 0.06666666666666651)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2020-03-16 14:07:56</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>213</td>\n",
       "      <td></td>\n",
       "      <td>nnursing home biggest cluster covid deaths dat...</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>581813</td>\n",
       "      <td>28376</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>2020-03-15 20:11:01</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>166</td>\n",
       "      <td></td>\n",
       "      <td>oone last party one last dance goodbye college...</td>\n",
       "      <td>2968</td>\n",
       "      <td>70</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>141205</td>\n",
       "      <td>3561</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>556522</td>\n",
       "      <td>26548</td>\n",
       "      <td>(0.0, 0.06666666666666651)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2020-03-15 14:53:50</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>89</td>\n",
       "      <td></td>\n",
       "      <td>ffederal vaccine development sites ill suited ...</td>\n",
       "      <td>2968</td>\n",
       "      <td>70</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>141205</td>\n",
       "      <td>3561</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>556522</td>\n",
       "      <td>26548</td>\n",
       "      <td>(-0.5, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2020-03-13 17:45:06</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>294</td>\n",
       "      <td></td>\n",
       "      <td>aanalysis u may already recession could linger...</td>\n",
       "      <td>2157</td>\n",
       "      <td>52</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>102276</td>\n",
       "      <td>2300</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>497943</td>\n",
       "      <td>22731</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2020-03-13 15:09:02</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>221</td>\n",
       "      <td></td>\n",
       "      <td>ffive states c order schools closed effort pre...</td>\n",
       "      <td>2157</td>\n",
       "      <td>52</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>102276</td>\n",
       "      <td>2300</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>497943</td>\n",
       "      <td>22731</td>\n",
       "      <td>(-0.0999999999999998, 0.0999999999999998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2020-03-13 15:03:03</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>1254</td>\n",
       "      <td></td>\n",
       "      <td>tthe number covid cases c region doubling ever...</td>\n",
       "      <td>2157</td>\n",
       "      <td>52</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>102276</td>\n",
       "      <td>2300</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>497943</td>\n",
       "      <td>22731</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2020-03-12 23:31:03</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>153</td>\n",
       "      <td></td>\n",
       "      <td>oopinion quarantining cities needed fast coord...</td>\n",
       "      <td>1561</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>84091</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>(0.06666666666666675, 0.2999999999999996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>2020-03-12 15:41:45</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>384</td>\n",
       "      <td></td>\n",
       "      <td>done absolutely done test test care doctor sai...</td>\n",
       "      <td>1561</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>84091</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>(0.09999999999999987, 0.9499999999999991)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2020-03-12 14:49:37</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>112</td>\n",
       "      <td></td>\n",
       "      <td>cconfusion helped speed spread coronavirus nea...</td>\n",
       "      <td>1561</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>84091</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>(0.024999999999999783, 0.4000000000000037)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2020-03-12 11:07:32</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>616</td>\n",
       "      <td></td>\n",
       "      <td>ccoronavirus arrives capitol hill first senate...</td>\n",
       "      <td>1561</td>\n",
       "      <td>43</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>84091</td>\n",
       "      <td>1746</td>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>464442</td>\n",
       "      <td>20638</td>\n",
       "      <td>(0.25, 0.3333333333333331)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2020-03-12 03:28:04</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>195</td>\n",
       "      <td></td>\n",
       "      <td>oopinion useful covid testing need think outsi...</td>\n",
       "      <td>1109</td>\n",
       "      <td>33</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>66055</td>\n",
       "      <td>1333</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>429686</td>\n",
       "      <td>18563</td>\n",
       "      <td>(0.10000000000000007, 0.033333333333333416)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2020-03-11 17:55:35</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>308</td>\n",
       "      <td></td>\n",
       "      <td>wwho declares pandemic coronavirus disease cov...</td>\n",
       "      <td>1109</td>\n",
       "      <td>33</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>66055</td>\n",
       "      <td>1333</td>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>429686</td>\n",
       "      <td>18563</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2020-03-09 17:10:35</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>257</td>\n",
       "      <td></td>\n",
       "      <td>ffda ftc crack companies selling products clai...</td>\n",
       "      <td>519</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>43850</td>\n",
       "      <td>784</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>367215</td>\n",
       "      <td>14138</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2020-03-09 15:12:56</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>205</td>\n",
       "      <td></td>\n",
       "      <td>pprinceton requires lectures seminars go onlin...</td>\n",
       "      <td>519</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>43850</td>\n",
       "      <td>784</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>367215</td>\n",
       "      <td>14138</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2020-03-06 20:10:03</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>654</td>\n",
       "      <td></td>\n",
       "      <td>uuniversity washington switches virtual classe...</td>\n",
       "      <td>222</td>\n",
       "      <td>14</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>19479</td>\n",
       "      <td>362</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>276547</td>\n",
       "      <td>9747</td>\n",
       "      <td>(0.22727272727272682, 0.5454545454545463)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2020-03-05 16:44:03</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>122</td>\n",
       "      <td></td>\n",
       "      <td>aa dog low level coronavirus infection panic c...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>14157</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>(0.0, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2020-03-05 15:54:01</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>93</td>\n",
       "      <td></td>\n",
       "      <td>ttwo people hospitalized covid new york city l...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>14157</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>(0.1363636363636366, 0.4772727272727268)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2020-03-05 13:52:03</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>140</td>\n",
       "      <td></td>\n",
       "      <td>ssouth africa confirms first covid case southe...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>14157</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>244610</td>\n",
       "      <td>8432</td>\n",
       "      <td>(0.08333333333333333, 0.11111111111111095)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2020-03-02 22:17:51</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>92</td>\n",
       "      <td></td>\n",
       "      <td>ccovid spreads easily sars similar coronavirus...</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>(0.054444444444444115, 0.6122222222222171)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2020-03-02 22:13:28</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "      <td>ppublic health officials say novel coronavirus...</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>(-0.1767295597484272, 0.27458379578246545)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2020-03-02 22:04:54</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>628</td>\n",
       "      <td></td>\n",
       "      <td>wwhat began wholesale food market central chin...</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>4360</td>\n",
       "      <td>97</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>162707</td>\n",
       "      <td>4381</td>\n",
       "      <td>(0.03333333333333347, 0.4166666666666667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2020-02-29 21:01:04</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>169</td>\n",
       "      <td></td>\n",
       "      <td>ccovid patient died washington hospital coming...</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>2870</td>\n",
       "      <td>58</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>122069</td>\n",
       "      <td>2934</td>\n",
       "      <td>(-0.33333333333333337, 0.6666666666666667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2020-02-24 17:26:12</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>75</td>\n",
       "      <td></td>\n",
       "      <td>aanalysis china early warning system work covi...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>519</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>43850</td>\n",
       "      <td>784</td>\n",
       "      <td>(0.0999999999999998, 0.3000000000000005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2020-02-20 01:37:02</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>washingtonpost</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "      <td>hhow epidemics like covid end end faster https...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>8917</td>\n",
       "      <td>188</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8514 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             created_at       date         username  likes_count retweet_date  \\\n",
       "0   2020-05-27 01:57:20 2020-05-26  whitewindlandon            0                \n",
       "1   2020-05-27 01:57:20 2020-05-26  whitewindlandon            0                \n",
       "2   2020-05-26 23:18:19 2020-05-26          rescon1            0                \n",
       "3   2020-05-26 23:00:14 2020-05-26         nealhead            0                \n",
       "4   2020-05-26 22:34:09 2020-05-26           6121el            1                \n",
       "5   2020-05-26 22:22:16 2020-05-26        roswell32            0                \n",
       "6   2020-05-26 21:57:10 2020-05-26       gary_lyman           13                \n",
       "7   2020-05-26 21:13:57 2020-05-26      oldnavy1968            0                \n",
       "8   2020-05-26 20:45:24 2020-05-26       dablazinjr            0                \n",
       "9   2020-05-26 18:15:33 2020-05-26  smartpe53402672            0                \n",
       "10  2020-05-26 16:32:14 2020-05-26   craving_filled            1                \n",
       "11  2020-05-26 12:45:53 2020-05-26  hsquared_studio            0                \n",
       "12  2020-05-26 12:41:10 2020-05-26      jimmyfalco2            0                \n",
       "13  2020-05-26 12:28:42 2020-05-26       ralfstein3            0                \n",
       "14  2020-05-26 12:00:19 2020-05-26    crawfordstuff            2                \n",
       "15  2020-05-26 10:54:19 2020-05-26     sallybeatty6            1                \n",
       "16  2020-05-26 10:54:05 2020-05-26      outbreaksci            1                \n",
       "17  2020-05-26 06:58:42 2020-05-26  natsumugikezine            0                \n",
       "18  2020-05-26 04:06:33 2020-05-26   wadetheleopard            2                \n",
       "19  2020-05-26 23:18:19 2020-05-26          rescon1            0                \n",
       "20  2020-05-26 22:22:16 2020-05-26        roswell32            0                \n",
       "21  2020-05-26 18:15:33 2020-05-26  smartpe53402672            0                \n",
       "22  2020-05-27 03:27:48 2020-05-26  parkerrobertda1            0                \n",
       "23  2020-05-27 02:23:48 2020-05-26     gregggraison            1                \n",
       "24  2020-05-27 02:01:55 2020-05-26        dianepaul            1                \n",
       "25  2020-05-27 01:58:29 2020-05-26        art_muela            0                \n",
       "26  2020-05-27 01:05:41 2020-05-26       jfdorville            0                \n",
       "27  2020-05-26 23:44:03 2020-05-26   thesteveholzer            5                \n",
       "28  2020-05-26 23:32:53 2020-05-26         b1louder            0                \n",
       "29  2020-05-26 23:18:19 2020-05-26          rescon1            0                \n",
       "..                  ...        ...              ...          ...          ...   \n",
       "553 2020-03-19 10:28:18 2020-03-19   washingtonpost         1431                \n",
       "554 2020-03-18 17:21:07 2020-03-18   washingtonpost          212                \n",
       "555 2020-03-17 03:25:59 2020-03-16   washingtonpost          183                \n",
       "556 2020-03-16 17:51:04 2020-03-16   washingtonpost          525                \n",
       "557 2020-03-16 17:44:10 2020-03-16   washingtonpost          189                \n",
       "558 2020-03-16 15:22:37 2020-03-16   washingtonpost          133                \n",
       "559 2020-03-16 14:07:56 2020-03-16   washingtonpost          213                \n",
       "560 2020-03-15 20:11:01 2020-03-15   washingtonpost          166                \n",
       "561 2020-03-15 14:53:50 2020-03-15   washingtonpost           89                \n",
       "562 2020-03-13 17:45:06 2020-03-13   washingtonpost          294                \n",
       "563 2020-03-13 15:09:02 2020-03-13   washingtonpost          221                \n",
       "564 2020-03-13 15:03:03 2020-03-13   washingtonpost         1254                \n",
       "565 2020-03-12 23:31:03 2020-03-12   washingtonpost          153                \n",
       "566 2020-03-12 15:41:45 2020-03-12   washingtonpost          384                \n",
       "567 2020-03-12 14:49:37 2020-03-12   washingtonpost          112                \n",
       "568 2020-03-12 11:07:32 2020-03-12   washingtonpost          616                \n",
       "569 2020-03-12 03:28:04 2020-03-11   washingtonpost          195                \n",
       "570 2020-03-11 17:55:35 2020-03-11   washingtonpost          308                \n",
       "571 2020-03-09 17:10:35 2020-03-09   washingtonpost          257                \n",
       "572 2020-03-09 15:12:56 2020-03-09   washingtonpost          205                \n",
       "573 2020-03-06 20:10:03 2020-03-06   washingtonpost          654                \n",
       "574 2020-03-05 16:44:03 2020-03-05   washingtonpost          122                \n",
       "575 2020-03-05 15:54:01 2020-03-05   washingtonpost           93                \n",
       "576 2020-03-05 13:52:03 2020-03-05   washingtonpost          140                \n",
       "577 2020-03-02 22:17:51 2020-03-02   washingtonpost           92                \n",
       "578 2020-03-02 22:13:28 2020-03-02   washingtonpost          100                \n",
       "579 2020-03-02 22:04:54 2020-03-02   washingtonpost          628                \n",
       "580 2020-02-29 21:01:04 2020-02-29   washingtonpost          169                \n",
       "581 2020-02-24 17:26:12 2020-02-24   washingtonpost           75                \n",
       "582 2020-02-20 01:37:02 2020-02-19   washingtonpost           88                \n",
       "\n",
       "                                          clean_tweets  Cases_x  Deaths_Tweet  \\\n",
       "0    ttwo united states leading news sources time u...  1689162         99952   \n",
       "1    ttwo united states leading news sources time u...  1689162         99952   \n",
       "2    unless u physician nurse surgical room busines...  1689162         99952   \n",
       "3    tthe reality andy beshear create covid spread ...  1689162         99952   \n",
       "4    iin large countries united states russia brazi...  1689162         99952   \n",
       "5    rright good look president united states leadi...  1689162         99952   \n",
       "6    uunited states officially surpassed grim miles...  1689162         99952   \n",
       "7    tthe united states confirmed covid cases next ...  1689162         99952   \n",
       "8    tthe average age deceased covid positive patie...  1689162         99952   \n",
       "9    yyou stupidest people get paid stupidity one c...  1689162         99952   \n",
       "10   hhow come south korea united states saw first ...  1689162         99952   \n",
       "11   ssays said united states one fifteen covid cas...  1689162         99952   \n",
       "12   ii making political studies shown hcq effectiv...  1689162         99952   \n",
       "13   wwhile united states still puzzling whether ma...  1689162         99952   \n",
       "14   iit likely today reach deaths united states co...  1689162         99952   \n",
       "15   aand guy running world health organization wan...  1689162         99952   \n",
       "16   ccontribute rapid review request one geographi...  1689162         99952   \n",
       "17   japan part regions tokyo osaka accepts ems del...  1689162         99952   \n",
       "18   llet assume worst moment covid hits time worst...  1689162         99952   \n",
       "19   unless u physician nurse surgical room busines...  1689162         99952   \n",
       "20   rright good look president united states leadi...  1689162         99952   \n",
       "21   yyou stupidest people get paid stupidity one c...  1689162         99952   \n",
       "22   wwell covid people still behaving badly newyor...  1689162         99952   \n",
       "23   hhow people ignorant rude nasty knowing fact m...  1689162         99952   \n",
       "24   ii heartbroken america much racism much exploi...  1689162         99952   \n",
       "25   ii understand people biased towards russia bai...  1689162         99952   \n",
       "26   en covid tcgnrg map despite confirmed covid ca...  1689162         99952   \n",
       "27   sspent today joebiden talked covid response la...  1689162         99952   \n",
       "28   ddo desert navajonation america covid times an...  1689162         99952   \n",
       "29   unless u physician nurse surgical room busines...  1689162         99952   \n",
       "..                                                 ...      ...           ...   \n",
       "553  get corona get corona miami spring breakers sa...    14157           265   \n",
       "554  hhow world political artists depicting covid p...     8917           188   \n",
       "555  oopinion life time covid totally unprecedented...     4360            97   \n",
       "556  aadditionally scientists still know sure survi...     4360            97   \n",
       "557  iit depends unknown characteristics virus expr...     4360            97   \n",
       "558  oone last party one last dance goodbye college...     4360            97   \n",
       "559  nnursing home biggest cluster covid deaths dat...     4360            97   \n",
       "560  oone last party one last dance goodbye college...     2968            70   \n",
       "561  ffederal vaccine development sites ill suited ...     2968            70   \n",
       "562  aanalysis u may already recession could linger...     2157            52   \n",
       "563  ffive states c order schools closed effort pre...     2157            52   \n",
       "564  tthe number covid cases c region doubling ever...     2157            52   \n",
       "565  oopinion quarantining cities needed fast coord...     1561            43   \n",
       "566  done absolutely done test test care doctor sai...     1561            43   \n",
       "567  cconfusion helped speed spread coronavirus nea...     1561            43   \n",
       "568  ccoronavirus arrives capitol hill first senate...     1561            43   \n",
       "569  oopinion useful covid testing need think outsi...     1109            33   \n",
       "570  wwho declares pandemic coronavirus disease cov...     1109            33   \n",
       "571  ffda ftc crack companies selling products clai...      519            22   \n",
       "572  pprinceton requires lectures seminars go onlin...      519            22   \n",
       "573  uuniversity washington switches virtual classe...      222            14   \n",
       "574  aa dog low level coronavirus infection panic c...      174            12   \n",
       "575  ttwo people hospitalized covid new york city l...      174            12   \n",
       "576  ssouth africa confirms first covid case southe...      174            12   \n",
       "577  ccovid spreads easily sars similar coronavirus...       53             6   \n",
       "578  ppublic health officials say novel coronavirus...       53             6   \n",
       "579  wwhat began wholesale food market central chin...       53             6   \n",
       "580  ccovid patient died washington hospital coming...       24             1   \n",
       "581  aanalysis china early warning system work covi...       15             0   \n",
       "582  hhow epidemics like covid end end faster https...       13             0   \n",
       "\n",
       "       14 days  Cases_14  Deaths_14    28 days  Cases_48  Deaths_48  \\\n",
       "0   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "1   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "2   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "3   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "4   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "5   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "6   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "7   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "8   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "9   2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "10  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "11  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "12  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "13  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "14  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "15  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "16  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "17  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "18  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "19  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "20  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "21  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "22  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "23  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "24  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "25  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "26  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "27  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "28  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "29  2020-06-09   1979908     112714 2020-06-23   2347491     121847   \n",
       "..         ...       ...        ...        ...       ...        ...   \n",
       "553 2020-04-02    244610       8432 2020-04-16    669272      35442   \n",
       "554 2020-04-01    214205       6846 2020-04-15    637974      33329   \n",
       "555 2020-03-30    162707       4381 2020-04-13    581813      28376   \n",
       "556 2020-03-30    162707       4381 2020-04-13    581813      28376   \n",
       "557 2020-03-30    162707       4381 2020-04-13    581813      28376   \n",
       "558 2020-03-30    162707       4381 2020-04-13    581813      28376   \n",
       "559 2020-03-30    162707       4381 2020-04-13    581813      28376   \n",
       "560 2020-03-29    141205       3561 2020-04-12    556522      26548   \n",
       "561 2020-03-29    141205       3561 2020-04-12    556522      26548   \n",
       "562 2020-03-27    102276       2300 2020-04-10    497943      22731   \n",
       "563 2020-03-27    102276       2300 2020-04-10    497943      22731   \n",
       "564 2020-03-27    102276       2300 2020-04-10    497943      22731   \n",
       "565 2020-03-26     84091       1746 2020-04-09    464442      20638   \n",
       "566 2020-03-26     84091       1746 2020-04-09    464442      20638   \n",
       "567 2020-03-26     84091       1746 2020-04-09    464442      20638   \n",
       "568 2020-03-26     84091       1746 2020-04-09    464442      20638   \n",
       "569 2020-03-25     66055       1333 2020-04-08    429686      18563   \n",
       "570 2020-03-25     66055       1333 2020-04-08    429686      18563   \n",
       "571 2020-03-23     43850        784 2020-04-06    367215      14138   \n",
       "572 2020-03-23     43850        784 2020-04-06    367215      14138   \n",
       "573 2020-03-20     19479        362 2020-04-03    276547       9747   \n",
       "574 2020-03-19     14157        265 2020-04-02    244610       8432   \n",
       "575 2020-03-19     14157        265 2020-04-02    244610       8432   \n",
       "576 2020-03-19     14157        265 2020-04-02    244610       8432   \n",
       "577 2020-03-16      4360         97 2020-03-30    162707       4381   \n",
       "578 2020-03-16      4360         97 2020-03-30    162707       4381   \n",
       "579 2020-03-16      4360         97 2020-03-30    162707       4381   \n",
       "580 2020-03-14      2870         58 2020-03-28    122069       2934   \n",
       "581 2020-03-09       519         22 2020-03-23     43850        784   \n",
       "582 2020-03-04       104         11 2020-03-18      8917        188   \n",
       "\n",
       "                                       Sentiment  \n",
       "0                                     (0.0, 0.0)  \n",
       "1                                     (0.0, 0.0)  \n",
       "2                                     (0.0, 0.0)  \n",
       "3                      (0.0, 0.3458333333333324)  \n",
       "4    (0.026984126984127076, 0.36507936507936345)  \n",
       "5      (0.23668098818474678, 0.6895005370569313)  \n",
       "6       (-0.332727272727271, 0.6409090909090938)  \n",
       "7                   (0.10000000000000034, 0.375)  \n",
       "8     (0.09242424242424296, 0.38181818181817945)  \n",
       "9      (-0.5666666666666745, 0.7666666666666659)  \n",
       "10     (-0.27500000000000013, 0.666666666666665)  \n",
       "11      (0.5999999999999965, 0.5999999999999965)  \n",
       "12     (0.17499999999999838, 0.5000000000000066)  \n",
       "13                                    (0.0, 0.0)  \n",
       "14                                  (0.25, 0.75)  \n",
       "15    (0.20000000000000082, 0.10000000000000041)  \n",
       "16                                    (0.0, 0.0)  \n",
       "17                 (0.041666666666666664, 0.375)  \n",
       "18                (-0.17499999999999963, 0.8125)  \n",
       "19                                    (0.0, 0.0)  \n",
       "20     (0.23668098818474678, 0.6895005370569313)  \n",
       "21     (-0.5666666666666745, 0.7666666666666659)  \n",
       "22      (-0.549999999999997, 0.6333333333333361)  \n",
       "23    (-0.20571428571428674, 0.5057142857142859)  \n",
       "24   (-0.010714285714285796, 0.3559523809523809)  \n",
       "25                                 (-0.625, 1.0)  \n",
       "26    (-0.07142857142857163, 0.9523809523809527)  \n",
       "27    (0.06372141372141397, 0.26891891891891906)  \n",
       "28      (0.3499999999999986, 0.6500000000000034)  \n",
       "29                                    (0.0, 0.0)  \n",
       "..                                           ...  \n",
       "553                                   (0.0, 0.0)  \n",
       "554                   (0.0, 0.09999999999999981)  \n",
       "555      (0.600000000000001, 0.9000000000000001)  \n",
       "556   (0.08333333333333465, 0.41481481481481497)  \n",
       "557   (-0.08596491228070205, 0.5943859649122778)  \n",
       "558                   (0.0, 0.06666666666666651)  \n",
       "559                                   (0.0, 0.0)  \n",
       "560                   (0.0, 0.06666666666666651)  \n",
       "561                                  (-0.5, 1.0)  \n",
       "562                                   (0.0, 0.0)  \n",
       "563    (-0.0999999999999998, 0.0999999999999998)  \n",
       "564                                   (0.0, 0.0)  \n",
       "565    (0.06666666666666675, 0.2999999999999996)  \n",
       "566    (0.09999999999999987, 0.9499999999999991)  \n",
       "567   (0.024999999999999783, 0.4000000000000037)  \n",
       "568                   (0.25, 0.3333333333333331)  \n",
       "569  (0.10000000000000007, 0.033333333333333416)  \n",
       "570                                   (0.0, 0.0)  \n",
       "571                                   (0.0, 0.0)  \n",
       "572                                   (0.0, 0.0)  \n",
       "573    (0.22727272727272682, 0.5454545454545463)  \n",
       "574                                   (0.0, 0.3)  \n",
       "575     (0.1363636363636366, 0.4772727272727268)  \n",
       "576   (0.08333333333333333, 0.11111111111111095)  \n",
       "577   (0.054444444444444115, 0.6122222222222171)  \n",
       "578   (-0.1767295597484272, 0.27458379578246545)  \n",
       "579    (0.03333333333333347, 0.4166666666666667)  \n",
       "580   (-0.33333333333333337, 0.6666666666666667)  \n",
       "581     (0.0999999999999998, 0.3000000000000005)  \n",
       "582                                   (0.0, 0.0)  \n",
       "\n",
       "[8514 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renaming case and death columns to reflect timeframes from tweet more transpaently\n",
    "Sentiment_Tweet_df.rename(columns={'Cases_Tweet':'Cases_x','Deaths_x':'Deaths_Tweet','Cases_y':'Cases_14','Deaths_y':'Deaths_14','Cases':'Cases_48','Deaths':'Deaths_48'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'date', 'username', 'likes_count', 'retweet_date',\n",
       "       'clean_tweets', 'Cases_x', 'Deaths_x', '14 days', 'Cases_y', 'Deaths_y',\n",
       "       '28 days', 'Cases', 'Deaths', 'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment_Tweet_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# adding columns for Case & Death growth rates\n",
    "\n",
    "#Sentiment_Tweet_df.columns\n",
    "\n",
    "\n",
    "#Growth rate for case and death for tweet date to 48 days\n",
    "Sentiment_Tweet_df['Total Case Growth'] = (Sentiment_Tweet_df['Cases']-Sentiment_Tweet_df['Cases_x'])/Sentiment_Tweet_df['Cases_x']\n",
    "Sentiment_Tweet_df['Total Death Growth'] = (Sentiment_Tweet_df['Deaths']-Sentiment_Tweet_df['Deaths_x'])/Sentiment_Tweet_df['Deaths_y']\n",
    "\n",
    "#Lethality measure: how many deaths as proportion of cases\n",
    "Sentiment_Tweet_df['Lethality_48'] = (Sentiment_Tweet_df['Deaths']/Sentiment_Tweet_df['Cases'])\n",
    "Sentiment_Tweet_df['Lethality_14'] = (Sentiment_Tweet_df['Deaths_y']/Sentiment_Tweet_df['Cases_y'])\n",
    "Sentiment_Tweet_df['Lethality_dayof'] = (Sentiment_Tweet_df['Deaths_x']/Sentiment_Tweet_df['Cases_x'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>Cases_x</th>\n",
       "      <th>Deaths_x</th>\n",
       "      <th>14 days</th>\n",
       "      <th>Cases_y</th>\n",
       "      <th>Deaths_y</th>\n",
       "      <th>28 days</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Total Case Growth</th>\n",
       "      <th>Total Death Growth</th>\n",
       "      <th>Lethality_48</th>\n",
       "      <th>Lethality_14</th>\n",
       "      <th>Lethality_dayof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ttwo united states leading news sources time u...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-27 01:57:20</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>whitewindlandon</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>ttwo united states leading news sources time u...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-26 23:18:19</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>rescon1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>unless u physician nurse surgical room busines...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-26 23:00:14</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>nealhead</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>tthe reality andy beshear create covid spread ...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.0, 0.3458333333333324)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-26 22:34:09</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>6121el</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>iin large countries united states russia brazi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.026984126984127076, 0.36507936507936345)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-26 22:22:16</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>roswell32</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>rright good look president united states leadi...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.23668098818474678, 0.6895005370569313)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-26 21:57:10</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>gary_lyman</td>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>uunited states officially surpassed grim miles...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.332727272727271, 0.6409090909090938)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-05-26 21:13:57</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>oldnavy1968</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>tthe united states confirmed covid cases next ...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.10000000000000034, 0.375)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-05-26 20:45:24</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>dablazinjr</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>tthe average age deceased covid positive patie...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(0.09242424242424296, 0.38181818181817945)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-05-26 18:15:33</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>smartpe53402672</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>yyou stupidest people get paid stupidity one c...</td>\n",
       "      <td>1689162</td>\n",
       "      <td>99952</td>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>1979908</td>\n",
       "      <td>112714</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2347491</td>\n",
       "      <td>121847</td>\n",
       "      <td>(-0.5666666666666745, 0.7666666666666659)</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           created_at       date         username  likes_count retweet_date  \\\n",
       "0 2020-05-27 01:57:20 2020-05-26  whitewindlandon            0                \n",
       "1 2020-05-27 01:57:20 2020-05-26  whitewindlandon            0                \n",
       "2 2020-05-26 23:18:19 2020-05-26          rescon1            0                \n",
       "3 2020-05-26 23:00:14 2020-05-26         nealhead            0                \n",
       "4 2020-05-26 22:34:09 2020-05-26           6121el            1                \n",
       "5 2020-05-26 22:22:16 2020-05-26        roswell32            0                \n",
       "6 2020-05-26 21:57:10 2020-05-26       gary_lyman           13                \n",
       "7 2020-05-26 21:13:57 2020-05-26      oldnavy1968            0                \n",
       "8 2020-05-26 20:45:24 2020-05-26       dablazinjr            0                \n",
       "9 2020-05-26 18:15:33 2020-05-26  smartpe53402672            0                \n",
       "\n",
       "                                        clean_tweets  Cases_x  Deaths_x  \\\n",
       "0  ttwo united states leading news sources time u...  1689162     99952   \n",
       "1  ttwo united states leading news sources time u...  1689162     99952   \n",
       "2  unless u physician nurse surgical room busines...  1689162     99952   \n",
       "3  tthe reality andy beshear create covid spread ...  1689162     99952   \n",
       "4  iin large countries united states russia brazi...  1689162     99952   \n",
       "5  rright good look president united states leadi...  1689162     99952   \n",
       "6  uunited states officially surpassed grim miles...  1689162     99952   \n",
       "7  tthe united states confirmed covid cases next ...  1689162     99952   \n",
       "8  tthe average age deceased covid positive patie...  1689162     99952   \n",
       "9  yyou stupidest people get paid stupidity one c...  1689162     99952   \n",
       "\n",
       "     14 days  Cases_y  Deaths_y    28 days    Cases  Deaths  \\\n",
       "0 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "1 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "2 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "3 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "4 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "5 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "6 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "7 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "8 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "9 2020-06-09  1979908    112714 2020-06-23  2347491  121847   \n",
       "\n",
       "                                     Sentiment  Total Case Growth  \\\n",
       "0                                   (0.0, 0.0)               0.39   \n",
       "1                                   (0.0, 0.0)               0.39   \n",
       "2                                   (0.0, 0.0)               0.39   \n",
       "3                    (0.0, 0.3458333333333324)               0.39   \n",
       "4  (0.026984126984127076, 0.36507936507936345)               0.39   \n",
       "5    (0.23668098818474678, 0.6895005370569313)               0.39   \n",
       "6     (-0.332727272727271, 0.6409090909090938)               0.39   \n",
       "7                 (0.10000000000000034, 0.375)               0.39   \n",
       "8   (0.09242424242424296, 0.38181818181817945)               0.39   \n",
       "9    (-0.5666666666666745, 0.7666666666666659)               0.39   \n",
       "\n",
       "   Total Death Growth  Lethality_48  Lethality_14  Lethality_dayof  \n",
       "0               0.194         0.052         0.057            0.059  \n",
       "1               0.194         0.052         0.057            0.059  \n",
       "2               0.194         0.052         0.057            0.059  \n",
       "3               0.194         0.052         0.057            0.059  \n",
       "4               0.194         0.052         0.057            0.059  \n",
       "5               0.194         0.052         0.057            0.059  \n",
       "6               0.194         0.052         0.057            0.059  \n",
       "7               0.194         0.052         0.057            0.059  \n",
       "8               0.194         0.052         0.057            0.059  \n",
       "9               0.194         0.052         0.057            0.059  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sorting Dataframe by date\n",
    "Sentiment_Tweet_df.sort_values(by= 'date', ascending=True)\n",
    "Sentiment_Tweet_df = Sentiment_Tweet_df.round(decimals=3)\n",
    "Sentiment_Tweet_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweet Tokenizer \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "ttknz = TweetTokenizer()\n",
    "\n",
    "#creation of the corpus\n",
    "corpus = Sentiment_Tweet_df['clean_tweets'].astype(str)\n",
    "corpus.dtypes\n",
    "\n",
    "#tokenizing corpus\n",
    "tok_corp = []\n",
    "for sent in corpus:\n",
    "    toked = ttknz.tokenize(sent)\n",
    "    tok_corp.append(toked)\n",
    "\n",
    "#tok_corp = [nltk.word_tokenize(sent.decod('utf-8')) for sent in corpus]\n",
    "\n",
    "#Word2Vec model with Skip-Gram\n",
    "Covidtweet_model = gensim.models.Word2Vec(tok_corp, sg=1,min_count=1)\n",
    "\n",
    "#Saving model\n",
    "#model.save('Covidtweet_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covidtweet_model.most_similar('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSNE plot of Word2Vec\n",
    "import sys\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    \"Creates and TSNE model and plots it. This function was originally found on Kaggle\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    tsne_model = TSNE(perplexity=50, n_components=3, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covidtweet_selective_model = word2vec.Word2Vec(tok_corp, size=100, window=25, min_count=125, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(Covidtweet_selective_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word, size):\n",
    "    \n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.similar_by_word(word)\n",
    "    arr = np.append(arr, np.array([model[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    tsne = TSNE(n_components=3, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "        plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "        plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_closestwords_tsnescatterplot(Covidtweet_selective_model,'virus',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "common_dictionary = Dictionary(tok_corp)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in tok_corp]\n",
    "\n",
    "lda = LdaModel(common_corpus, num_topics=20, alpha='auto', eval_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "list_of_list_of_tokens = list(tok_corp)\n",
    "dictionary_LDA = corpora.Dictionary(list_of_list_of_tokens)\n",
    "dictionary_LDA.filter_extremes(no_below=3)\n",
    "corpus = [dictionary_LDA.doc2bow(list_of_tokens) for list_of_tokens in list_of_list_of_tokens]\n",
    "\n",
    "num_topics = 20\n",
    "%time lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
    "                                  id2word=dictionary_LDA, \\\n",
    "                                  passes=4, alpha=[0.01]*num_topics, \\\n",
    "                                  eta=[0.01]*len(dictionary_LDA.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "for i,topic in lda_model.show_topics(formatted=True, num_topics=num_topics, num_words=10):\n",
    "    print(str(i)+\": \"+ topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=corpus, dictionary=dictionary_LDA)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_notebook_7.14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
